{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Overview","text":"<p> Features \u2022     Installation \u2022     Tutorials \u2022     Docs </p>"},{"location":"#dctmd","title":"dcTMD","text":"<p>This package aids in the analysis of dissipation-corrected targeted molecular dynamics (dcTMD) simulations. The method enforces rare unbinding events of ligands from proteins via a constraint pulling bias. Subsequently, free energy profiles and friction factors are estimated along the unbinding coordinate. For a methodological overview, see our article.</p> <p>S. Wolf, and G. Stock, Targeted molecular dynamics calculations of free energy profiles using a nonequilibrium friction correction., J. Chem. Theory Comput. 2018 14 (12), 6175-6182, doi: 10.1021/acs.jctc.8b00835</p> <p>This package will be published soon:</p> <p>M. J\u00e4ger, V. T\u00e4nzel, D. Nagel, and S. Wolf, Dissipation Corrected Targeted Molecular Dynamics,   in preparation 2025</p> <p>We kindly ask you to cite these articles in case you use this software package for published works.</p>"},{"location":"#features","title":"Features","text":"<ul> <li>Intuitive usage via module and CI</li> <li>Sklearn-style API for fast integration into your Python workflow</li> <li>Supports Python 3.9-3.14</li> <li>Multitude of publications with dcTMD</li> </ul>"},{"location":"#implemented-key-functionalities","title":"Implemented Key Functionalities","text":"<ul> <li>Estimation of free energy profiles and friction factors along the unbinding coordinate of ligands as described by Wolf and Stock 2018.</li> <li>Analysis of separate unbinding pathways as described by Wolf et al. 2023.</li> </ul>"},{"location":"#installation","title":"Installation","text":"<p><code>dcTMD</code> is available on PyPI and conda-forge.</p>"},{"location":"#install-with-pip","title":"Install with pip","text":"<p><pre><code>pip install dcTMD\n</code></pre> PyPI project page: https://pypi.org/project/dcTMD/</p>"},{"location":"#install-with-conda","title":"Install with conda","text":"<p><pre><code>conda install conda-forge::dctmd\n</code></pre> Conda-forge package page: https://anaconda.org/conda-forge/dcTMD</p>"},{"location":"#install-from-github","title":"Install from GitHub","text":"<pre><code>python3 -m pip install git+ssh://git@github.com/moldyn/dcTMD.git\n</code></pre>"},{"location":"#usage","title":"Usage","text":"<p>Check out the documentation for an overview over all modules as well as the tutorials.</p>"},{"location":"changelog/","title":"Changelog","text":"<p>All notable changes to this project will be documented in this file.</p> <p>The format is inspired by Keep a Changelog, and Element and this project adheres to Semantic Versioning.</p>"},{"location":"changelog/#unreleased","title":"Unreleased","text":""},{"location":"changelog/#041-2025-11-24","title":"0.4.1 - 2025-11-24","text":""},{"location":"changelog/#bugfix","title":"Bugfix \ud83d\udc1b:","text":"<ul> <li>Remove unused deps to fix publishing to conda, #32</li> <li>Fix unreachable code in input method</li> </ul>"},{"location":"changelog/#040-2025-11-19","title":"0.4.0 - 2025-11-19","text":""},{"location":"changelog/#added-features","title":"Added Features:","text":"<ul> <li>New <code>FeatureSet</code> class for loading multidimensional trajectory features.</li> <li>added <code>ForceEstimator.memory_kernel</code> to analyse force correlations at a fixed reference time point.</li> <li>Added tutorials for both new features</li> </ul>"},{"location":"changelog/#api-changes-warning","title":"API changes warning \u26a0\ufe0f:","text":"<ul> <li>Drop python 3.8 support</li> </ul>"},{"location":"changelog/#added-features-and-improvements","title":"Added Features and Improvements \ud83d\ude4c:","text":"<ul> <li>Add python 3.11-3.14 support\ud83c\udf89</li> <li>Add tutorial explaining the theory</li> </ul>"},{"location":"changelog/#other-changes","title":"Other changes:","text":"<ul> <li>Fix newlines in docs</li> <li>Add generalized smoothing of estimators</li> <li>Many minor bugfixes and improvements in the docs</li> <li>Changed syntax of plotting functions</li> </ul>"},{"location":"changelog/#030-2023-03-28","title":"0.3.0 - 2023-03-28","text":""},{"location":"changelog/#added-features-and-improvements_1","title":"Added Features and Improvements \ud83d\ude4c:","text":"<ul> <li>Initial public release \ud83c\udf89</li> <li>Added documentation, including tutorials \ud83c\udf89</li> <li>Cleaned-up source code</li> </ul>"},{"location":"changelog/#021-2022-12-12","title":"0.2.1 - 2022-12-12","text":""},{"location":"changelog/#added-features-and-improvements_2","title":"Added Features and Improvements \ud83d\ude4c:","text":"<ul> <li>Beta candidate</li> </ul>"},{"location":"changelog/#020-2022-05-23","title":"0.2.0 - 2022-05-23","text":""},{"location":"changelog/#added-features-and-improvements_3","title":"Added Features and Improvements \ud83d\ude4c:","text":"<ul> <li>Alpha candidate</li> </ul> <p>add force correlation to navigation</p>"},{"location":"contributing/","title":"Welcome to the <code>dcTMD</code> Contributing Guide","text":"<p>This guide will give you an overview of the contribution workflow from opening an issue and creating a PR. To get an overview of the project, read the module overview.</p>"},{"location":"contributing/#issues","title":"Issues","text":""},{"location":"contributing/#create-a-new-issue","title":"Create a new issue","text":"<p>If you spot a bug, want to request a new functionality, or have a question on how to use the module, please search if an issue already exists. If a related issue does not exist, feel free to open a new issue.</p>"},{"location":"contributing/#solve-an-issue","title":"Solve an issue","text":"<p>If you want to contribute and do not how, feel free to scan through the existing issues.</p>"},{"location":"contributing/#create-a-new-pull-request","title":"Create a new pull request","text":""},{"location":"contributing/#create-a-fork","title":"Create a fork","text":"<p>If you want to request a change, you first have to fork the repository.</p>"},{"location":"contributing/#setup-a-development-environment","title":"Setup a development environment","text":"bash + condabash + venvzsh + condazsh + venv <pre><code>conda create -n dcTMD -c conda-forge python\nconda activate dcTMD\npython -m pip install -e .[all]\n</code></pre> <pre><code>python -m venv ./dcTMD\nsource ./dcTMD/bin/activate\npython -m pip install -e .[all]\n</code></pre> <pre><code>conda create -n dcTMD -c conda-forge python\nconda activate dcTMD\npython -m pip install -e .\\[all]\n</code></pre> <pre><code>python -m venv ./dcTMD\nsource ./dcTMD/bin/activate\npython -m pip install -e .\\[all]\n</code></pre>"},{"location":"contributing/#make-changes-and-run-tests","title":"Make changes and run tests","text":"<p>Apply your changes and check if you followed the coding style (PEP8) by running <pre><code>python -m flake8 --config flake8-CI.cfg\n</code></pre> All errors pointing to <code>./build/</code> can be neglected.</p> <p>If you add a new function/method/class please ensure that you add a test function, as well. Running the test simply by <pre><code>pytest\n</code></pre> Ensure that the coverage does not decrease.</p>"},{"location":"contributing/#open-a-pull-request","title":"Open a pull request","text":"<p>Now you are ready to open a pull request and please do not forget to add a description.</p>"},{"location":"dcTMD/","title":"dcTMD","text":"<p>Analysis tools for dissipation-corrected targeted molecular dynamics, which is an enhanced sampling method to enforce rare events in biomolecular systems.</p> <p>The module is structured into the following submodules:</p> <ul> <li> <p>io: This submodule contains all methods related to reading data from text files and writing data to text files, including helpful header comments.</p> </li> <li> <p>storing: This submodule creates force or work sets from .pullf files (force time traces generated by gromacs) which are needed for further analysis. It provides two classes, WorkSet and ForceSet, that store constraint force data as work or force time traces, respectively.</p> </li> <li> <p>dcTMD: This submodule contains two classes, <code>WorkEstimator</code> and <code>ForceEstimator</code>, which are used for the dcTMD analysis of constraint force time traces. Both classes can be used to calculate the mean work, dissipative work, free energy and friction estimate of a set of constraint force time traces.</p> </li> <li> <p>featureset: This class loads, and stores trajectory-specific feature data into a consistent NumPy array format for downstream analyses such as trajectory similarity calculations. It supports direct filename input as well as filename generation via wildcard patterns.</p> </li> <li> <p>utils: This submodule provides utility functions such as smoothing, plotting and error estimation via bootstrapping. The functions in this submodule can be used in conjunction with other parts of the software.</p> </li> </ul>"},{"location":"faq/","title":"Frequently Asked Questions","text":""},{"location":"faq/#is-there-a-command-line-interface","title":"Is there a command line interface?","text":"<p>Yes, indeed. Some basic analysis can be used directly from the command line. Please check out the short tutorial CLI.</p>"},{"location":"faq/#is-there-a-shell-completion","title":"Is there a shell completion","text":"<p>Using the <code>bash</code>, <code>zsh</code> or <code>fish</code> shell click provides an easy way to provide shell completion, checkout the docs.  In the case of bash you need to add following line to your <code>~/.bashrc</code> <pre><code>eval \"$(_DCTMD_COMPLETE=bash_source dcTMD)\"\n</code></pre> In general one can call the module directly by its entry point <code>$ dcTMD</code> or by calling the module <code>$ python -m dcTMD</code>. For enabling the shell completion, the entry point needs to be used.</p>"},{"location":"faq/#feature-x-is-missing","title":"Feature X is missing","text":"<p>If you believe that a crucial functionality/method is missing, feel free to open an issue and describe the missing functionality and why it should be added. Alternatively, you can implement it yourself and create a PR to add it to this package, see contributing guide.</p>"},{"location":"faq/#i-found-a-bug-what-to-do-next","title":"I found a bug. What to do next?","text":"<p>If you find a bug in this package, it is very kind of you to open an issue/bug report. This allows us to identify and fix the problem, thus improving the overall quality of the software for all users. By providing a clear and concise description of the problem, including steps to reproduce it, and relevant information such as device, operating system, and software version, you will help us resolve the problem quickly and effectively. Submitting a bug report is a valuable contribution to the software and its community, and is greatly appreciated by the development team.</p>"},{"location":"getting_started/","title":"Getting Started","text":""},{"location":"getting_started/#introduction","title":"Introduction","text":"<p>This python package aids with the analysis of targeted molecular dynamics (TMD) trajectories according to the dissipation-corrected TMD method. TMD simulations enforce rare unbinding events of ligands from proteins via a constraint pulling bias. With dcTMD, free energy profiles and friction factors are estimated along the unbinding coordinate. For a methodological overview, see our article</p>"},{"location":"getting_started/#disclaimer","title":"Disclaimer","text":"<p>Warning This package is still in beta stage. Please open an issue if you encounter any bug/error.</p> <p>S. Wolf, and G. Stock, Targeted molecular dynamics calculations of free energy profiles using a nonequilibrium friction correction., Journal of chemical theory and computation (2018)</p> <p>This package will be published soon:</p> <p>M. J\u00e4ger, V. T\u00e4nzel, D. Nagel, and S. Wolf, Dissipation Corrected Targeted Molecular Dynamics,   in preparation 2025</p> <p>We kindly ask you to cite these articles in case you use this software package for published works.</p>"},{"location":"getting_started/#installation","title":"Installation","text":"<p><code>dcTMD</code> is available on PyPI and conda-forge.</p>"},{"location":"getting_started/#install-with-pip","title":"Install with pip","text":"<pre><code>pip install dcTMD\n</code></pre> <p>PyPI project page: https://pypi.org/project/dcTMD/</p>"},{"location":"getting_started/#install-with-conda","title":"Install with conda","text":"<pre><code>conda install conda-forge::dctmd\n</code></pre> <p>Conda-forge package page: https://anaconda.org/conda-forge/dcTMD</p>"},{"location":"getting_started/#install-from-github","title":"Install from GitHub","text":"<pre><code>python3 -m pip install git+ssh://git@github.com/moldyn/dcTMD.git\n</code></pre>"},{"location":"getting_started/#sections","title":"Sections:","text":"<ul> <li> <p>Theoretical Background:: Here, you will learn the basic theory behind dcTMD. Including Jarzinskys equality, the derivation of the free energy and friction estimate as well as the main assumptions made on the way.</p> </li> <li> <p>Create pulling trajectories with Gromacs:: Here, you will learn how you can set up constraint targeted MD simulations using the pull code implemented in Gromacs. </p> </li> <li> <p>dcTMD Analysis: In section dcTMD via Work and dcTMD via Force you will learn how to analyse the constraint pulling trajectories with dcTMD as described in Theory. In section Force correlation analysis you will learn how to analyse force force correlation functions at specified time points. And in section Cluster trajectories you find a quick guide on reading in features and clustering trajectories.</p> </li> <li> <p>Command Line Interface: In this section, we will provide a short guide to the command line interface of <code>dcTMD</code>, which provides some common analysis and visualization functionality.</p> </li> </ul>"},{"location":"license/","title":"License","text":"<p>MIT License</p> <p>Copyright \u00a9 2022 Biomolecular Dynamics</p> <p>Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:</p> <p>The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.</p> <p>THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.</p>"},{"location":"maintenance/","title":"Welcome to the <code>dcTMD</code> Maintenance Guideline","text":"<p>This guide will give you an overview of how to publish a new version of dcTMD. In the following we will refer to the new version as <code>v0.*.*</code>. This needs to be substituted to the current version, e.g. <code>v0.1.3</code>.</p>"},{"location":"maintenance/#prepare-new-release","title":"Prepare New Release","text":"<p>Please ensure that,</p> <ol> <li>the version number in <code>setup.py</code> and <code>src/dcTMD/__init__.py</code> are bumped,</li> <li>a new tag is created via <code>git tag v0.*.*</code> and pushed <code>git push --tags</code>, and </li> <li>the changelog includes the new tag and all changes of the release.</li> </ol>"},{"location":"maintenance/#upload-to-pypi","title":"Upload to PyPI","text":"<p>There is an CI to publish new versions automatically. Therefore, a new release needs to be published. Please ensure that each release is based on a tag.</p>"},{"location":"maintenance/#build-and-upload-to-pypi-admin-only","title":"Build and Upload to PyPI (admin only)","text":"<p>For an introduction, please take a look at the PyPI manual.</p> <p>First ensure that all needed dependencies are installed <pre><code>python -m pip install --upgrade pip\npython -m pip install --upgrade build\npython -m pip install --upgrade twine\n</code></pre></p> <p>To create the build, please ensure first that the directory <code>dist</code> does not exist. Otherwise delete it, <pre><code>rm dist\n</code></pre> Then, execute <pre><code>python3 -m build\n</code></pre> which will create the directory <code>dist</code> including the source distributions: <pre><code>dist/\n\u251c\u2500\u2500 dcTMD-0.*.*-py3-none-any.whl\n\u2514\u2500\u2500 dcTMD-0.*.*.tar.gz\n</code></pre> To upload the new files, run <pre><code>python3 -m twine upload dist/*\n</code></pre></p>"},{"location":"maintenance/#update-on-conda-forge","title":"Update on Conda-Forge","text":"<p>Once a new version is published on PyPI, the conda-forge bot will automatically create a pull request on dcTMD-feedstock.</p>"},{"location":"reference/","title":"dcTMD","text":"<p>Analysis tools for dissipation-corrected targeted molecular dynamics, which is an enhanced sampling method to enforce rare events in biomolecular systems.</p> <p>The module is structured into the following submodules:</p> <ul> <li> <p>io: This submodule contains all methods related to reading data from text files and writing data to text files, including helpful header comments.</p> </li> <li> <p>storing: This submodule creates force or work sets from .pullf files (force time traces generated by gromacs) which are needed for further analysis. It provides two classes, WorkSet and ForceSet, that store constraint force data as work or force time traces, respectively.</p> </li> <li> <p>dcTMD: This submodule contains two classes, <code>WorkEstimator</code> and <code>ForceEstimator</code>, which are used for the dcTMD analysis of constraint force time traces. Both classes can be used to calculate the mean work, dissipative work, free energy and friction estimate of a set of constraint force time traces.</p> </li> <li> <p>featureset: This class loads, and stores trajectory-specific feature data into a consistent NumPy array format for downstream analyses such as trajectory similarity calculations. It supports direct filename input as well as filename generation via wildcard patterns.</p> </li> <li> <p>utils: This submodule provides utility functions such as smoothing, plotting and error estimation via bootstrapping. The functions in this submodule can be used in conjunction with other parts of the software.</p> </li> </ul>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>dcTMD<ul> <li>dcTMD</li> <li>featureset</li> <li>io</li> <li>storing</li> <li>utils<ul> <li>plotting</li> </ul> </li> </ul> </li> <li>cli</li> </ul>"},{"location":"reference/cli/","title":"dcTMD","text":"<p>Calculate free energy and friction for given constraint force files.</p>"},{"location":"reference/cli/#dctmd_1","title":"|         dcTMD         |","text":"<p>Analysis tools for dissipation-corrected targeted molecular dynamics, which is an enhanced sampling method to enforce rare events in biomolecular systems. When publishing results gained with this python package, please cite the following publications: (1) T\u00e4nzel, Victor and J\u00e4ger, Miriam and Wolf, Steffen in preparation. (2) Wolf, Steffen, and Gerhard Stock. 'Targeted molecular dynamics calculations of free energy profiles using a nonequilibrium friction correction.' Journal of chemical theory and computation 14.12 (2018): 6175- 6182.</p> <p>Usage:</p> <pre><code>dcTMD [OPTIONS]\n</code></pre> <p>Options:</p> <pre><code>  -m, --mode [work|force]  Use either work or force autocovariance function to\n                           calculate dcTMD quantities.  [default: work;\n                           required]\n  -f, --file TEXT          Input: File containing list of all constraint force\n                           file names or glob pattern e.g.\"*.xvg\" to generate\n                           a list of all constraint force files using\n                           glob.glob()  [required]\n  -o, --outname PATH       Output: Path/prefix of output names.\n  -T, --temperature FLOAT  Simulation temperature in K.  [required]\n  -vel, --velocity FLOAT   Pulling velocity in nm/ps.  [required]\n  --res INTEGER            Striding to reduce size of returned free energy and\n                           friction.  [default: 1]\n  -s, --sigma FLOAT        Standard deviation of gaussian filter in nm.\n  -v, --verbose            Enable verbose mode.\n  -p, --plot               Plots free energy and smoothed friction.\n  -sd, --save_dataset      Save the Work/ForceSet instance to file.\n  --help                   Show this message and exit.\n</code></pre>"},{"location":"reference/dcTMD/","title":"dcTMD","text":"<p>Classes <code>WorkEstimator</code>, <code>ForceEstimator</code> calculating the dcTMD quantities.</p> <p>This submodule contains two classes, WorkEstimator and ForceEstimator, which are used for the dcTMD analysis of constraint force time traces. Both class can be used to calculate the mean work, dissipative work, free energy and friction estimate of a set of constraint force time traces.</p>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.WorkEstimator","title":"<code>WorkEstimator(temperature, verbose=False)</code>","text":"<p>               Bases: <code>_SmoothBasisEstimator</code>, <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Class for performing dcTMD analysis on a work set.</p> <p>Parameters:</p> <ul> <li> <code>temperature</code>               (<code>Union[Float, Int]</code>)           \u2013            <p>Temperature at which the simulations were carried out, in K.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Enables verbose mode.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>position_</code>           \u2013            <p>Positions time trace, product of time trace and velocity, in nm.</p> </li> <li> <code>W_mean_</code>           \u2013            <p>Mean work, in kJ/mol.</p> </li> <li> <code>W_diss_</code>           \u2013            <p>Dissipative work, in kJ/mol.</p> </li> <li> <code>dG_</code>           \u2013            <p>Free energy estimate, in kJ/mol.</p> </li> <li> <code>friction_</code>           \u2013            <p>Friction factor in kJ/mol/(nm^2/ps).</p> </li> <li> <code>mode_</code>           \u2013            <p>Parameter of WorkEstimator.estimate_free_energy_errors. Decides how the bootstrapping errors are calculated.</p> </li> <li> <code>s_W_mean_</code>           \u2013            <p>Bootstrapping error of the mean work. Calculated via WorkEstimator.estimate_free_energy_errors.</p> </li> <li> <code>s_W_diss_</code>           \u2013            <p>Bootstrapping error of the dissipative work. Calculated via WorkEstimator.estimate_free_energy_errors.</p> </li> <li> <code>s_dG_</code>           \u2013            <p>Bootstrapping error of the free energy estimate. Calculated via WorkEstimator.estimate_free_energy_errors.</p> </li> <li> <code>W_mean_resampled_</code>           \u2013            <p>Resampled mean work, needed to inspect its distribution. Calculated via WorkEstimator.estimate_free_energy_errors.</p> </li> <li> <code>W_diss_resampled_</code>           \u2013            <p>Resampled dissipative work, needed to inspect its distribution. Calculated via WorkEstimator.estimate_free_energy_errors.</p> </li> <li> <code>dG_resampled_</code>           \u2013            <p>Resampled free energy estimate, needed to inspect its distribution. Calculated via WorkEstimator.estimate_free_energy_errors.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n&gt;&gt;&gt; from dcTMD.storing import load\n&gt;&gt;&gt; work = load('my_work_set')\n&gt;&gt;&gt; # Instantiate a WorkEstimator instance and fit it with the WorkSet\n&gt;&gt;&gt; # instance work\n&gt;&gt;&gt; work_estimator = WorkEstimator(temperature=290.15)\n&gt;&gt;&gt; work_estimator.fit(work)\n&gt;&gt;&gt; work_estimator.dG_\narray([..., ])\n</code></pre> <p>Initialize class.</p> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef __init__(\n    self,\n    temperature: Union[Float, Int],\n    verbose: bool = False,\n) -&gt; None:\n    \"\"\"Initialize class.\"\"\"\n    self.temperature = temperature\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.WorkEstimator.fit","title":"<code>fit(work_set)</code>","text":"<p>Estimate free energy and friction.</p> <p>Parameters:</p> <ul> <li> <code>work_set</code>           \u2013            <p>Instance of WorkSet containing constraint force work time traces, for which the free energy and friction are estimated.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code>          \u2013            <p>Fitted estimator.</p> </li> </ul> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef fit(\n    self,\n    work_set,\n):\n    \"\"\"\n    Estimate free energy and friction.\n\n    Parameters\n    ----------\n    work_set :\n        Instance of WorkSet containing constraint force work time traces,\n        for which the free energy and friction are estimated.\n\n    Returns\n    -------\n    self :\n        Fitted estimator.\n    \"\"\"\n    self._reset()\n    self.work_set = work_set\n    self.position_ = work_set.position_\n    self.names_ = work_set.names_\n    self.estimate_free_energy()\n    self.estimate_friction()\n    return self\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.WorkEstimator.transform","title":"<code>transform(X, y=None)</code>","text":"<p>Return free energy and friction estimates.</p> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef transform(\n    self, X, y=None,\n) -&gt; Tuple[Float1DArray, Float1DArray]:  # noqa: WPS111\n    \"\"\"Return free energy and friction estimates.\"\"\"\n    return self.dG_, self.friction_\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.WorkEstimator.estimate_free_energy","title":"<code>estimate_free_energy(work_set=None)</code>","text":"<p>Estimate free energy.</p> <p>Parameters:</p> <ul> <li> <code>work_set</code>               (<code>optional</code>, default:                   <code>None</code> )           \u2013            <p>Instance of a WorkSet containing constraint forces, for which the free energy and friction are estimated.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>W_mean</code> (              <code>1D np.array</code> )          \u2013            <p>Mean work, in kJ/mol.</p> </li> <li> <code>W_diss</code> (              <code>1D np.array</code> )          \u2013            <p>Dissipative work, in kJ/mol.</p> </li> <li> <code>dG_</code> (              <code>1D np.array</code> )          \u2013            <p>Free energy estimate, in kJ/mol.</p> </li> </ul> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef estimate_free_energy(\n    self,\n    work_set=None,\n) -&gt; Tuple[Float1DArray, Float1DArray, Float1DArray]:\n    \"\"\"\n    Estimate free energy.\n\n    Parameters\n    ----------\n    work_set : optional\n        Instance of a WorkSet containing constraint forces, for which the\n        free energy and friction are estimated.\n\n    Returns\n    -------\n    W_mean : 1D np.array\n        Mean work, in kJ/mol.\n    W_diss : 1D np.array\n        Dissipative work, in kJ/mol.\n    dG_ : 1D np.array\n        Free energy estimate, in kJ/mol.\n    \"\"\"\n    # Besides calculating dcTMD quantitites for the class, this function\n    # is also called from the bootstrapping routine. In the latter case,\n    # which comes with a passed work_set parameter, attributes should not\n    # be overwritten.\n    if work_set is None:\n        work_set = self.work_set.work_\n        is_bootstrapping = False\n    else:\n        is_bootstrapping = True\n\n    from scipy.constants import R  # noqa: WPS347\n    RT = R * self.temperature / 1e3\n\n    W_mean = np.mean(work_set, axis=0)\n    W_var = np.var(work_set, axis=0)\n    W_diss = 1 / (2 * RT) * W_var\n    dG = W_mean - W_diss\n\n    if not is_bootstrapping:\n        self.W_mean_ = W_mean\n        self.W_diss_ = W_diss\n        self.dG_ = dG\n    return W_mean, W_diss, dG\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.WorkEstimator.estimate_free_energy_errors","title":"<code>estimate_free_energy_errors(n_resamples, mode, seed=None)</code>","text":"<p>Estimate bootstrapping errors for the free energy estimate.</p> <p>Bootstrapping errors are calculated for the free energy estimate and the related quantities mean and dissipative work. Return matches the one of WorkEstimator.estimate_free_energy.</p> <p>Parameters:</p> <ul> <li> <code>n_resamples</code>               (<code>Int</code>)           \u2013            <p>Number of drawn resamples for bootstrapping error analysis.</p> </li> <li> <code>mode</code>               (<code>Union[StrStd, NumInRange0to1]</code>)           \u2013            <p>Chooses between reducing the resampled statistic via (1) 'std' the element-wise calculation of standard deviations or (2) confidence intervals if <code>mode</code> is a float in [0, 1).</p> </li> <li> <code>seed</code>               (<code>Optional[Int]</code>, default:                   <code>None</code> )           \u2013            <p>Seed for the random number generator.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>s_W_mean_</code> (              <code>Union[Float1DArray, Float2DArray]</code> )          \u2013            <p>Error estimate of the mean work.</p> </li> <li> <code>s_W_diss_</code> (              <code>Union[Float1DArray, Float2DArray]</code> )          \u2013            <p>Error estimate of the mean work.</p> </li> <li> <code>s_dG_</code> (              <code>Union[Float1DArray, Float2DArray]</code> )          \u2013            <p>Error estimate of free energy.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n&gt;&gt;&gt; work_estimator.estimate_free_energy_errors(1000, mode='std')\nBootstrapping progress: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:00&lt;00:00, 12797.15it/s]  # noqa\n&gt;&gt;&gt; work_estimator.s_dG_\narray([..., ])\n</code></pre> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>    @beartype\n    def estimate_free_energy_errors(  # noqa: WPS320\n        self,\n        n_resamples: Int,\n        mode: Union[StrStd, NumInRange0to1],\n        seed: Optional[Int] = None,\n    ) -&gt; Tuple[Union[Float1DArray, Float2DArray],\n               Union[Float1DArray, Float2DArray],  # noqa: WPS318\n               Union[Float1DArray, Float2DArray],\n               ]:\n        \"\"\"\n        Estimate bootstrapping errors for the free energy estimate.\n\n        Bootstrapping errors are calculated for the free energy estimate and\n        the related quantities mean and dissipative work. Return matches the\n        one of [WorkEstimator.estimate_free_energy][dcTMD.dcTMD.WorkEstimator.\\\nestimate_free_energy].\n\n        Parameters\n        ----------\n        n_resamples :\n            Number of drawn resamples for bootstrapping error analysis.\n        mode :\n            Chooses between reducing the resampled statistic via (1) 'std' the\n            element-wise calculation of standard deviations or (2) confidence\n            intervals if `mode` is a float in [0, 1).\n        seed :\n            Seed for the random number generator.\n\n        Returns\n        -------\n        s_W_mean_ :\n            Error estimate of the mean work.\n        s_W_diss_ :\n            Error estimate of the mean work.\n        s_dG_ :\n            Error estimate of free energy.\n\n        Examples\n        --------\n        &gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n        &gt;&gt;&gt; work_estimator.estimate_free_energy_errors(1000, mode='std')\n        Bootstrapping progress: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:00&lt;00:00, 12797.15it/s]  # noqa\n        &gt;&gt;&gt; work_estimator.s_dG_\n        array([..., ])\n        \"\"\"\n        self.free_energy_error_ = {\n            'mode': mode,\n            'n_resamples': n_resamples,\n            'seed': seed,\n        }\n        self._bootstrap_free_energy()\n        return self.s_W_mean_, self.s_W_diss_, self.s_dG_\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.WorkEstimator.estimate_friction","title":"<code>estimate_friction(W_diss=None)</code>","text":"<p>Estimate bootstrapping errors for the friction.</p> <p>Besides calculating dcTMD quantities to the class, this function is also called from the bootstrapping routine. In the latter case, which comes with a passed <code>W_diss</code> parameter, attributes should not be overwritten.</p> <p>Parameters:</p> <ul> <li> <code>W_diss</code>               (<code>Optional[Float1DArray]</code>, default:                   <code>None</code> )           \u2013            <p>Dissipative work, in kJ/mol. Is passed if this function is used during bootstrapping.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>friction</code> (              <code>Float1DArray</code> )          \u2013            <p>Friction factor in kJ/mol/(nm^2/ps).</p> </li> </ul> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef estimate_friction(\n    self,\n    W_diss: Optional[Float1DArray] = None,\n) -&gt; Float1DArray:\n    \"\"\"\n    Estimate bootstrapping errors for the friction.\n\n    Besides calculating dcTMD quantities to the class, this function\n    is also called from the bootstrapping routine. In the latter case,\n    which comes with a passed `W_diss` parameter, attributes should not\n    be overwritten.\n\n    Parameters\n    ----------\n    W_diss :\n        Dissipative work, in kJ/mol. Is passed if this function is used\n        during bootstrapping.\n\n    Returns\n    -------\n    friction :\n        Friction factor in kJ/mol/(nm^2/ps).\n    \"\"\"\n    if W_diss is None:\n        is_bootstrapping = False\n        try:\n            W_diss = self.W_diss_\n        except AttributeError:\n            self.estimate_free_energy()\n            W_diss = self.W_diss_\n    else:\n        is_bootstrapping = True\n\n    delta_x = self.work_set.position_[1] - self.work_set.position_[0]\n    if self.verbose:\n        print(f'calculating friction, delta_x: {delta_x}nm')\n    friction = np.diff(\n        W_diss, prepend=W_diss[0],\n    ) / (delta_x * self.work_set.velocity)\n    if not is_bootstrapping:\n        self.friction_ = friction\n    return friction\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.WorkEstimator.estimate_friction_errors","title":"<code>estimate_friction_errors(n_resamples, mode, seed=None)</code>","text":"<p>Estimate bootstrapping errors for the free energy estimate.</p> <p>Bootstrapping errors are calculated for the free energy estimate and the related quantities mean and dissipative work. Return matches the one of WorkEstimator.estimate_free_energy.</p> <p>Parameters:</p> <ul> <li> <code>n_resamples</code>               (<code>Int</code>)           \u2013            <p>Number of drawn resamples for bootstrapping error analysis.</p> </li> <li> <code>mode</code>               (<code>Union[StrStd, NumInRange0to1]</code>)           \u2013            <p>Chooses between reducing the resampled statistic via     1.  'std' the element-wise calculation of standard deviations,     2.  confidence intervals if <code>mode</code> is a float in [0, 1).</p> </li> <li> <code>seed</code>               (<code>Optional[Int]</code>, default:                   <code>None</code> )           \u2013            <p>Seed for the random number generator.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>s_friction_</code> (              <code>Float1DArray</code> )          \u2013            <p>Bootstrap error of the friction factor in kJ/mol/(nm^2/ps).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n&gt;&gt;&gt; work_estimator.estimate_friction_errors(1000, mode='std')\nBootstrapping progress: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:00&lt;00:00, 10245.63it/s]  # noqa\n&gt;&gt;&gt; work_estimator.s_friction_\narray([..., ])\n</code></pre> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>    @beartype\n    def estimate_friction_errors(\n        self,\n        n_resamples: Int,\n        mode: Union[StrStd, NumInRange0to1],\n        seed: Optional[Int] = None,\n    ) -&gt; Float1DArray:\n        \"\"\"\n        Estimate bootstrapping errors for the free energy estimate.\n\n        Bootstrapping errors are calculated for the free energy estimate and\n        the related quantities mean and dissipative work. Return matches the\n        one of [WorkEstimator.estimate_free_energy][dcTMD.dcTMD.WorkEstimator.\\\nestimate_free_energy].\n\n        Parameters\n        ----------\n        n_resamples :\n            Number of drawn resamples for bootstrapping error analysis.\n        mode :\n            Chooses between reducing the resampled statistic via\n                1.  'std' the element-wise calculation of standard deviations,\n                2.  confidence intervals if `mode` is a float in [0, 1).\n        seed :\n            Seed for the random number generator.\n\n        Returns\n        -------\n        s_friction_ :\n            Bootstrap error of the friction factor in kJ/mol/(nm^2/ps).\n\n        Examples\n        --------\n        &gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n        &gt;&gt;&gt; work_estimator.estimate_friction_errors(1000, mode='std')\n        Bootstrapping progress: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:00&lt;00:00, 10245.63it/s]  # noqa\n        &gt;&gt;&gt; work_estimator.s_friction_\n        array([..., ])\n        \"\"\"\n        self.friction_error_ = {\n            'n_resamples': n_resamples,\n            'mode': mode,\n            'seed': seed,\n        }\n        self._bootstrap_friction()\n        return self.s_friction_\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.ForceEstimator","title":"<code>ForceEstimator(temperature, verbose=False)</code>","text":"<p>               Bases: <code>_SmoothBasisEstimator</code>, <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Class for performing dcTMD analysis on a force set.</p> <p>Parameters:</p> <ul> <li> <code>temperature</code>               (<code>Union[Float, Int]</code>)           \u2013            <p>Temperature at which the simulations were carried out, in K.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Enables verbose mode.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>position_</code>           \u2013            <p>Positions time trace, product of time trace and velocity, in nm.</p> </li> <li> <code>W_mean_</code>           \u2013            <p>Mean work, in kJ/mol.</p> </li> <li> <code>W_diss_</code>           \u2013            <p>Dissipative work, in kJ/mol.</p> </li> <li> <code>dG_</code>           \u2013            <p>Free energy estimate, in kJ/mol.</p> </li> <li> <code>friction_</code>           \u2013            <p>Friction factor in kJ/mol/(nm^2/ps).</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from dcTMD.dcTMD import ForceEstimator\n&gt;&gt;&gt; from dcTMD.storing import load\n&gt;&gt;&gt; force = load('my_force_set')\n&gt;&gt;&gt; # Instantiate a ForceEstimator instance and fit it with the\n&gt;&gt;&gt; # ForceSet instance\n&gt;&gt;&gt; force_estimator = ForceEstimator(temperature=290.15)\n&gt;&gt;&gt; force_estimator.fit(force)\n&gt;&gt;&gt; force_estimator.dG_\narray([..., ])\n</code></pre> <p>Initialize class.</p> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef __init__(\n    self,\n    temperature: Union[Float, Int],\n    verbose: bool = False,\n) -&gt; None:\n    \"\"\"Initialize class.\"\"\"\n    self.temperature = temperature\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.ForceEstimator.fit","title":"<code>fit(force_set)</code>","text":"<p>Estimate free energy and friction.</p> <p>Parameters:</p> <ul> <li> <code>force_set</code>           \u2013            <p>Instance of ForceSet containing constraint forces, for which the free energy and friction are estimated.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code>          \u2013            <p>Fitted estimator.</p> </li> </ul> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef fit(\n    self,\n    force_set,\n):\n    \"\"\"\n    Estimate free energy and friction.\n\n    Parameters\n    ----------\n    force_set :\n        Instance of ForceSet containing constraint forces, for which the\n        free energy and friction are estimated.\n\n    Returns\n    -------\n    self :\n        Fitted estimator.\n    \"\"\"\n    self._reset()\n    self.force_set = force_set\n    self.names_ = force_set.names_\n    self.estimate_free_energy_friction()\n    return self\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.ForceEstimator.transform","title":"<code>transform(X, y=None)</code>","text":"<p>Return free energy and friction estimates.</p> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef transform(\n    self, X, y=None,\n) -&gt; Tuple[Float1DArray, Float1DArray]:  # noqa: WPS111\n    \"\"\"Return free energy and friction estimates.\"\"\"\n    return self.dG_, self.friction_\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.ForceEstimator.estimate_free_energy_friction","title":"<code>estimate_free_energy_friction()</code>","text":"<p>Estimate free energy and friction from force auto correlation.</p> <p>Returns:</p> <ul> <li> <code>W_mean</code> (              <code>1D np.array</code> )          \u2013            <p>Mean work, in kJ/mol.</p> </li> <li> <code>W_diss</code> (              <code>1D np.array</code> )          \u2013            <p>Dissipative work, in kJ/mol.</p> </li> <li> <code>dG_</code> (              <code>1D np.array</code> )          \u2013            <p>Free energy estimate, in kJ/mol.</p> </li> <li> <code>friction_</code> (              <code>1D np.array</code> )          \u2013            <p>Friction factor in kJ/mol/(nm^2/ps).</p> </li> </ul> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef estimate_free_energy_friction(\n    self,\n) -&gt; Tuple[Float1DArray, Float1DArray, Float1DArray, Float1DArray]:\n    \"\"\"\n    Estimate free energy and friction from force auto correlation.\n\n    Returns\n    -------\n    W_mean : 1D np.array\n        Mean work, in kJ/mol.\n    W_diss : 1D np.array\n        Dissipative work, in kJ/mol.\n    dG_ : 1D np.array\n        Free energy estimate, in kJ/mol.\n    friction_ : 1D np.array\n        Friction factor in kJ/mol/(nm^2/ps).\n    \"\"\"\n    from scipy.constants import R  # noqa: WPS347\n    from scipy.integrate import cumulative_trapezoid\n    RT = R * self.temperature / 1e3\n\n    # average over all trajectories in each time step\n    force_mean = np.mean(self.force_set.force_, axis=0)\n\n    # calculate $\\delta f(t) = f(t) - \\left&lt; f(t) \\right&gt;_N$\n    self.delta_force_array = self.force_set.force_ - force_mean\n\n    # integrate f(t) over time\n    int_delta_force = cumulative_trapezoid(\n        self.delta_force_array,\n        self.force_set.time_,\n        axis=-1,\n        initial=0,\n    )\n    # multiply $\\delta f(t) \\int_0^t \\delta f(t') dt'$ for each N\n    intcorr = np.multiply(\n        self.delta_force_array,\n        int_delta_force,\n    )\n    friction = np.mean(intcorr, axis=0) / RT\n\n    W_mean = cumulative_trapezoid(\n        force_mean,\n        self.force_set.position_,\n        initial=0,\n    )\n    W_diss = cumulative_trapezoid(\n        friction,\n        self.force_set.position_,\n        initial=0,\n    ) * self.force_set.velocity\n\n    # Reduce resolution\n    self.position_ = self.force_set.position_[::self.force_set.resolution]\n    self.W_mean_ = W_mean[::self.force_set.resolution]\n    self.W_diss_ = W_diss[::self.force_set.resolution]\n    self.dG_ = self.W_mean_ - self.W_diss_\n    self.friction_ = friction[::self.force_set.resolution]\n\n    return self.W_mean_, self.W_diss_, self.dG_, self.friction_\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.ForceEstimator.kernel_at_ndx","title":"<code>kernel_at_ndx(delta_force_array, ndx)</code>  <code>staticmethod</code>","text":"<p>Calculate the kernel at a specific index.</p> <p>Args:     ndx (Int): Index at which the kernel is calculated.</p> <p>Returns:     Float1DArray: The mean force correlation     &lt; df(t(x)) df(t) &gt;_N at the given index.</p> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\n@staticmethod\ndef kernel_at_ndx(\n    delta_force_array: Float2DArray,\n    ndx: Int\n) -&gt; Float1DArray:\n    \"\"\"\n    Calculate the kernel at a specific index.\n\n    Args:\n        ndx (Int): Index at which the kernel is calculated.\n\n    Returns:\n        Float1DArray: The mean force correlation\n        &lt; df(t(x)) df(t) &gt;_N at the given index.\n    \"\"\"\n    delta_force_point = delta_force_array[:, ndx]\n    force_correlation_at_ndx = (\n        delta_force_array.T * delta_force_point\n    ).T\n    return np.mean(force_correlation_at_ndx, axis=0)\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.ForceEstimator.memory_kernel","title":"<code>memory_kernel(index=None, ndx_striding=None)</code>","text":"<p>Calculate memory kernel at index.</p> <p>Either give a index (as Int or an array of indices) or ndx_striding as an argument. The latter creates the index array from the force data with striding.</p> <p>Parameters:</p> <ul> <li> <code>x_indices</code>           \u2013            <p>Indices at which the memory kernel is calculated. If None, indices will be generated based on <code>ndx_striding</code>. Default is None.</p> </li> <li> <code>ndx_striding</code>               (<code>Union[Int, None]</code>, default:                   <code>None</code> )           \u2013            <p>Resolution for creating index array. If provided, indices will be generated at intervals of <code>ndx_resolution</code>. Default is None.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <ul> <li>A 2D NumPy array containing the memory kernel values.</li> </ul> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from dcTMD.dcTMD import ForceEstimator\n&gt;&gt;&gt; from dcTMD.storing import load\n&gt;&gt;&gt; force = load('my_force_set')\n&gt;&gt;&gt; # Instantiate a ForceEstimator instance and fit it with the\n&gt;&gt;&gt; # ForceSet instance\n&gt;&gt;&gt; force_estimator = ForceEstimator(temperature=290.15)\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.ForceEstimator.memory_kernel--example-usage-with-specific-indices","title":"Example usage with specific indices:","text":"<pre><code>&gt;&gt;&gt; kernel = force_estimator.memory_kernel(index=[10, 20, 30])\n&gt;&gt;&gt; print(kernel)\n</code></pre>"},{"location":"reference/dcTMD/#dcTMD.dcTMD.ForceEstimator.memory_kernel--example-usage-with-resolution","title":"Example usage with resolution:","text":"<pre><code>&gt;&gt;&gt; force_estimator.memory_kernel(ndx_resolution=1000)\n&gt;&gt;&gt; print(force_estimator.memory_kernel_index_)\n&gt;&gt;&gt; print(force_estimator.memory_kernel_)\n</code></pre> Source code in <code>src/dcTMD/dcTMD.py</code> <pre><code>@beartype\ndef memory_kernel(\n    self,\n    index: Union[Int, Index1DArray, None] = None,\n    ndx_striding: Union[Int, None] = None,\n) -&gt; Float2DArray:\n    \"\"\"\n    Calculate memory kernel at index.\n\n    Either give a index (as Int or an array of indices) or\n    ndx_striding as an argument. The latter creates the index array\n    from the force data with striding.\n\n    Parameters\n    ----------\n    x_indices :\n        Indices at which the memory kernel is calculated.\n        If None, indices will\n        be generated based on `ndx_striding`. Default is None.\n    ndx_striding:\n        Resolution for creating index array.\n        If provided, indices will be\n        generated at intervals of `ndx_resolution`. Default is None.\n\n    Returns\n    -------\n    numpy.ndarray\n        - A 2D NumPy array containing the memory kernel values.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from dcTMD.dcTMD import ForceEstimator\n    &gt;&gt;&gt; from dcTMD.storing import load\n    &gt;&gt;&gt; force = load('my_force_set')\n    &gt;&gt;&gt; # Instantiate a ForceEstimator instance and fit it with the\n    &gt;&gt;&gt; # ForceSet instance\n    &gt;&gt;&gt; force_estimator = ForceEstimator(temperature=290.15)\n\n    # Example usage with specific indices:\n\n    &gt;&gt;&gt; kernel = force_estimator.memory_kernel(index=[10, 20, 30])\n    &gt;&gt;&gt; print(kernel)\n\n    # Example usage with resolution:\n\n    &gt;&gt;&gt; force_estimator.memory_kernel(ndx_resolution=1000)\n    &gt;&gt;&gt; print(force_estimator.memory_kernel_index_)\n    &gt;&gt;&gt; print(force_estimator.memory_kernel_)\n    \"\"\"\n    # Argument validation (mutual exclusion / requirement)\n    if index is not None and ndx_striding is not None:\n        raise ValueError(\n            'Only index or ndx_resolution can be given.'\n        )\n    if index is None and ndx_striding is None:\n        raise ValueError(\n            'Either index or ndx_resolution must be given.'\n        )\n    # read in index or create index array\n    if index is not None:\n        if isinstance(index, (int, np.integer)):\n            print('create index with single int')\n            index = np.array([index])\n        if np.any(index &gt;= len(self.force_set.time_)):\n            raise ValueError(\n                'Index values must be less than length of data.'\n            )\n    elif ndx_striding is not None:\n        print('create index with ndx_resolution')\n        index = np.arange(\n            ndx_striding,\n            len(self.force_set.time_) - 1,\n            ndx_striding,\n            dtype=int\n        )\n    # calculate memory kernel at given indices\n    correlation_set = np.zeros((len(index), len(self.force_set.time_)))\n    for i, ndx in enumerate(index):\n        correlation_set[i] = self.kernel_at_ndx(\n            self.delta_force_array,\n            ndx\n        )\n    self.memory_kernel_ = correlation_set\n    self.memory_kernel_index_ = index\n    return correlation_set\n</code></pre>"},{"location":"reference/featureset/","title":"featureset","text":""},{"location":"reference/featureset/#dcTMD.featureset.FeatureSet","title":"<code>FeatureSet(filenames=None, filenameprefix=None, wildcard='*{}*', verbose=False)</code>","text":"<p>A class to create a array based on trajectory features. This array is later on used to calculate similarities between trajectories.</p> <p>The class loads trajectory-specific features and organizes them into arrays for further analysis. It assumes that all files have the same shape. The order in which they are loaded needs to be specified.</p> <p>Initialize the FeatureSet.</p> <p>Parameters:</p> <ul> <li> <code>filenames</code>               (<code>Union[List[str], ndarray]</code>, default:                   <code>None</code> )           \u2013            <p>A list or array of filenames.</p> </li> <li> <code>filenameprefix</code>               (<code>Union[List[str], ndarray]</code>, default:                   <code>None</code> )           \u2013            <p>A list or array of names that contain the running number. Must be used together with wildcard.</p> </li> <li> <code>wildcard</code>               (<code>str</code>, default:                   <code>'*{}*'</code> )           \u2013            <p>A wildcard string pattern for generating filenames in combination with the running number from filenameprefix. Must be provided if filenameprefix is used, by default '{}'.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Whether to print logs during execution, by default False.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; filenames = ['traj_01_contacts.txt', 'traj_02_contacts.txt']\n&gt;&gt;&gt; featureset = FeatureSet(filenames, verbose=True)\n&gt;&gt;&gt; featureset.fill_array()\n&gt;&gt;&gt; array = featureset.array\n&gt;&gt;&gt; 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| X/X [XX:XX&lt;00:00, X.XXit/s] # noqa\n</code></pre> Source code in <code>src/dcTMD/featureset.py</code> <pre><code>@beartype\ndef __init__(\n    self,\n    filenames: Union[List[str], np.ndarray] = None,\n    filenameprefix: Union[List[str], np.ndarray] = None,\n    wildcard: str = '*{}*',\n    verbose: bool = False\n) -&gt; None:\n    \"\"\"\n    Initialize the FeatureSet.\n\n    Parameters\n    ----------\n    filenames :\n        A list or array of filenames.\n    filenameprefix :\n        A list or array of names that contain the running number.\n        Must be used together with wildcard.\n    wildcard :\n        A wildcard string pattern for generating filenames\n        in combination with the running number from filenameprefix.\n        Must be provided if filenameprefix is used, by default '*{}*'.\n    verbose : bool, optional\n        Whether to print logs during execution, by default False.\n\n    Examples\n    --------\n    &gt;&gt;&gt; filenames = ['traj_01_contacts.txt', 'traj_02_contacts.txt']\n    &gt;&gt;&gt; featureset = FeatureSet(filenames, verbose=True)\n    &gt;&gt;&gt; featureset.fill_array()\n    &gt;&gt;&gt; array = featureset.array\n    &gt;&gt;&gt; 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| X/X [XX:XX&lt;00:00, X.XXit/s] # noqa\n    \"\"\"\n    self.verbose = verbose\n\n    if filenames is not None:\n        self.filenames = np.asarray(filenames)\n    elif filenameprefix is not None and wildcard:\n        self.filenames = self._get_filenames(filenameprefix, wildcard)\n    else:\n        raise ValueError(\n            'Either `filenames` must be provided directly, '\n            'or both `filenameprefix` and `wildcard` '\n            'must be provided together.'\n        )\n    if self.verbose:\n        print(f'Loaded filenames: {self.filenames}')\n</code></pre>"},{"location":"reference/featureset/#dcTMD.featureset.FeatureSet.fill_array","title":"<code>fill_array()</code>","text":"<p>Load the data from trajectory files into a NumPy array.</p> <p>This method reads each file in self.filenames and fills the data into a pre-allocated NumPy array based on the file shape determined by <code>_read_testfile</code>.</p> <p>Files that cannot be loaded or its shape does not match the expected shape, are skipped.</p> <p>Returns:</p> <ul> <li> <code>ndarray</code>           \u2013            <p>A array where each entry corresponds to the data from a trajectory file.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; filenames = ['traj_01_contacts.txt', 'traj_02_contacts.txt']\n&gt;&gt;&gt; featureset = FeatureSet(filenames, verbose=True)\n&gt;&gt;&gt; featureset.fill_array()\n&gt;&gt;&gt; array = featureset.array\n&gt;&gt;&gt; 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| X/X [XX:XX&lt;00:00, X.XXit/s] # noqa\n</code></pre> Source code in <code>src/dcTMD/featureset.py</code> <pre><code>def fill_array(self) -&gt; np.ndarray:\n    \"\"\"\n    Load the data from trajectory files into a NumPy array.\n\n    This method reads each file in self.filenames and fills the data into a pre-allocated NumPy array based on the file shape determined by `_read_testfile`.\n\n    Files that cannot be loaded or its shape does not match the expected shape, are skipped.\n\n    Returns\n    -------\n    np.ndarray\n        A array where each entry corresponds to the data from a trajectory file.\n\n    Examples\n    --------\n    &gt;&gt;&gt; filenames = ['traj_01_contacts.txt', 'traj_02_contacts.txt']\n    &gt;&gt;&gt; featureset = FeatureSet(filenames, verbose=True)\n    &gt;&gt;&gt; featureset.fill_array()\n    &gt;&gt;&gt; array = featureset.array\n    &gt;&gt;&gt; 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| X/X [XX:XX&lt;00:00, X.XXit/s] # noqa\n    \"\"\"\n    self._read_testfile()\n    array = np.zeros(shape=(\n        len(self.filenames),\n        *self.fileshape,\n    ))\n    self.names_ = []\n\n    with tqdm(\n        total=len(self.filenames),\n        desc='Loading files',\n    ) as pbar:\n        for i, current_fname in enumerate(self.filenames):\n            if self.verbose:\n                print(f'Reading file {current_fname}')\n\n            file_data = self._safe_loadtxt(current_fname)\n\n            if file_data.shape != self.fileshape:\n                print(\n                    f'Skipping file {current_fname} due to shape mismatch')\n                continue\n\n            array[i, :] = file_data\n            self.names_.append(current_fname)\n            pbar.update(1)\n\n    self.array = array\n    return self.array\n</code></pre>"},{"location":"reference/io/","title":"io","text":"<p>Submodule handling the input/output operations.</p>"},{"location":"reference/io/#dcTMD.io.load_pullf","title":"<code>load_pullf(pullf_files)</code>","text":"<p>Load filenames and resturns them as list.</p> <p>Filenames can be taken from file or glob them from globpattern.</p> <p>Parameters:</p> <ul> <li> <code>pullf_files</code>               (<code>Str</code>)           \u2013            <p>file which contains <code>pullf</code> filenames or globpattern</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>filenames</code> (              <code>(List[Str], Str1DArray)</code> )          \u2013            <p>list/array of filenames</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from dcTMD.io import load_pullf\n&gt;&gt;&gt; # load filenames form file\n&gt;&gt;&gt; filenames = load_pullf('pullf_files.txt')\n&gt;&gt;&gt; # load filenames with glob pattern\n&gt;&gt;&gt; filenames = load_pullf('data/*.pullf.xvg')\n</code></pre> Source code in <code>src/dcTMD/io.py</code> <pre><code>@beartype\ndef load_pullf(pullf_files: Str) -&gt; (List[Str], Str1DArray):\n    \"\"\"Load filenames and resturns them as list.\n\n    Filenames can be taken from file or glob them from globpattern.\n\n    Parameters\n    ----------\n    pullf_files :\n        file which contains `pullf` filenames or globpattern\n\n    Returns\n    -------\n    filenames:\n        list/array of filenames\n\n    Examples\n    --------\n    &gt;&gt;&gt; from dcTMD.io import load_pullf\n    &gt;&gt;&gt; # load filenames form file\n    &gt;&gt;&gt; filenames = load_pullf('pullf_files.txt')\n    &gt;&gt;&gt; # load filenames with glob pattern\n    &gt;&gt;&gt; filenames = load_pullf('data/*.pullf.xvg')\n    \"\"\"\n    try:\n        filenames = np.loadtxt(pullf_files, dtype='str')\n    except FileNotFoundError as fnf_error:\n        print(f'file {fnf_error} using glob.glob({pullf_files})')\n        filenames = glob.glob(pullf_files)\n\n    if not len(filenames):\n        raise ValueError('No constraint force files found.')\n\n    return filenames\n</code></pre>"},{"location":"reference/io/#dcTMD.io.write_output","title":"<code>write_output(out, estimator, filetype=('dat', 'npz'))</code>","text":"<p>Take all calculated quantities and save them.</p> <p>Parameters:</p> <ul> <li> <code>out</code>               (<code>Str</code>)           \u2013            <p>Output name. By default f'{out}_N{n_traj}'</p> </li> <li> <code>estimator</code>           \u2013            <p>Either a ForceEstimator or WorkEstimator instance.</p> </li> <li> <code>filetype</code>           \u2013            <p>Output filetype, either 'dat', 'npz' or both ('dat', 'npz').</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from dcTMD.storing import load\n&gt;&gt;&gt; from dcTMD.io import write_output\n&gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n&gt;&gt;&gt; # Save the results from WorkEstimator\n&gt;&gt;&gt; # (ForceEstimator works similarly)\n&gt;&gt;&gt; # calculate dcTMD results from workset\n&gt;&gt;&gt; work = load('my_work_set')\n&gt;&gt;&gt; work_estimator = WorkEstimator(temperature=290.15)\n&gt;&gt;&gt; work_estimator.fit(work)\n&gt;&gt;&gt; out = 'my_dcTMD_results'\n&gt;&gt;&gt; # save results as 'npz' file\n&gt;&gt;&gt; write_output(out, work_estimator, filetype='npz')\n&gt;&gt;&gt; # results saves as 'my_dcTMD_results_N100.npz'\n&gt;&gt;&gt; # save results as 'dat' file\n&gt;&gt;&gt; write_output(out, work_estimator, filetype='dat')\n&gt;&gt;&gt; # save results as 'dat' and 'npz' file\n&gt;&gt;&gt; write_output(out, work_estimator, filetype=('dat', 'npz'))\n</code></pre> Source code in <code>src/dcTMD/io.py</code> <pre><code>@beartype\ndef write_output(\n    out: Str,\n    estimator,\n    filetype=('dat', 'npz'),\n) -&gt; None:\n    \"\"\"Take all calculated quantities and save them.\n\n    Parameters\n    ----------\n    out :\n        Output name. By default f'{out}_N{n_traj}'\n    estimator :\n        Either a ForceEstimator or WorkEstimator instance.\n    filetype:\n        Output filetype, either 'dat', 'npz' or both ('dat', 'npz').\n\n    Examples\n    --------\n    &gt;&gt;&gt; from dcTMD.storing import load\n    &gt;&gt;&gt; from dcTMD.io import write_output\n    &gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n    &gt;&gt;&gt; # Save the results from WorkEstimator\n    &gt;&gt;&gt; # (ForceEstimator works similarly)\n    &gt;&gt;&gt; # calculate dcTMD results from workset\n    &gt;&gt;&gt; work = load('my_work_set')\n    &gt;&gt;&gt; work_estimator = WorkEstimator(temperature=290.15)\n    &gt;&gt;&gt; work_estimator.fit(work)\n    &gt;&gt;&gt; out = 'my_dcTMD_results'\n    &gt;&gt;&gt; # save results as 'npz' file\n    &gt;&gt;&gt; write_output(out, work_estimator, filetype='npz')\n    &gt;&gt;&gt; # results saves as 'my_dcTMD_results_N100.npz'\n    &gt;&gt;&gt; # save results as 'dat' file\n    &gt;&gt;&gt; write_output(out, work_estimator, filetype='dat')\n    &gt;&gt;&gt; # save results as 'dat' and 'npz' file\n    &gt;&gt;&gt; write_output(out, work_estimator, filetype=('dat', 'npz'))\n    \"\"\"\n    n_traj = len(estimator.names_)\n    out = f'{out}_N{n_traj}'\n\n    results_dict = {\n        'x': estimator.position_,\n        'Wmean': estimator.W_mean_,\n        'Wdiss': estimator.W_diss_,\n        'dG': estimator.dG_,\n        'Gamma': estimator.friction_,\n    }\n    if hasattr(estimator, 's_dG_'):\n        results_dict.update({\n            's_W_mean': estimator.s_W_mean_,\n            's_W_diss': estimator.s_W_diss_,\n            's_dG': estimator.s_dG_,\n        })\n    if hasattr(estimator, 'friction_smooth_'):\n        results_dict['Gamma_smooth'] = estimator.friction_smooth_\n    if hasattr(estimator, 's_friction_'):\n        results_dict['s_Gamma'] = estimator.s_friction_\n\n    if 'dat' in filetype:\n        header = list(results_dict.keys())\n        arrays = np.vstack(list(results_dict.values()))\n        print(f'save file {out}.dat')\n        np.savetxt(\n            f'{out}.dat',\n            arrays.T,\n            fmt='%20.8f',  # noqa: WPS323\n            header='    '.join(header),\n        )\n    if 'npz' in filetype:\n        print(f'save file {out}.npz')\n        np.savez(\n            f'{out}.npz',\n            **results_dict,\n        )\n</code></pre>"},{"location":"reference/io/#dcTMD.io.load_output","title":"<code>load_output(filepath)</code>","text":"<p>Load file produced by <code>write_output</code>.</p> <p>Parameters:</p> <ul> <li> <code>filepath</code>               (<code>str</code>)           \u2013            <p>Path to the .dat or .npz file to be loaded.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>Dict[str, Any]</code>           \u2013            <p>A dictionary containing the loaded data. Keys correspond to the quantities saved in the .npz file, such as 'x', 'Wmean', 'Wdiss', 'dG', 'Gamma', and optionally 's_W_mean', 's_W_diss', 's_dG', 'Gamma_smooth', 's_Gamma' if they were present during saving.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from dcTMD.storing import load\n&gt;&gt;&gt; from dcTMD.io import write_output, load_output\n&gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n&gt;&gt;&gt; # Save the results from WorkEstimator\n&gt;&gt;&gt; work = load('my_work_set')\n&gt;&gt;&gt; work_estimator = WorkEstimator(temperature=290.15)\n&gt;&gt;&gt; work_estimator.fit(work)\n&gt;&gt;&gt; # save results as '.npz' file\n&gt;&gt;&gt; out = 'my_dcTMD_results'\n&gt;&gt;&gt; write_output(out, work_estimator, filetype='npz')\n&gt;&gt;&gt; # load results\n&gt;&gt;&gt; results = load_output('my_dcTMD_results_N100.npz')\n&gt;&gt;&gt; positions = results['x']\n&gt;&gt;&gt; mean_work = results['Wmean']\n&gt;&gt;&gt; dG = results['dG']\n</code></pre> Source code in <code>src/dcTMD/io.py</code> <pre><code>@beartype\ndef load_output(filepath: Str):\n    \"\"\"\n    Load file produced by `write_output`.\n\n    Parameters\n    ----------\n    filepath : str\n        Path to the .dat or .npz file to be loaded.\n\n    Returns\n    -------\n    Dict[str, Any]\n        A dictionary containing the loaded data. Keys correspond to the\n        quantities saved in the .npz file, such as 'x', 'Wmean', 'Wdiss',\n        'dG', 'Gamma', and optionally 's_W_mean', 's_W_diss', 's_dG',\n        'Gamma_smooth', 's_Gamma' if they were present during saving.\n\n    Examples\n    --------\n    &gt;&gt;&gt; from dcTMD.storing import load\n    &gt;&gt;&gt; from dcTMD.io import write_output, load_output\n    &gt;&gt;&gt; from dcTMD.dcTMD import WorkEstimator\n    &gt;&gt;&gt; # Save the results from WorkEstimator\n    &gt;&gt;&gt; work = load('my_work_set')\n    &gt;&gt;&gt; work_estimator = WorkEstimator(temperature=290.15)\n    &gt;&gt;&gt; work_estimator.fit(work)\n    &gt;&gt;&gt; # save results as '.npz' file\n    &gt;&gt;&gt; out = 'my_dcTMD_results'\n    &gt;&gt;&gt; write_output(out, work_estimator, filetype='npz')\n    &gt;&gt;&gt; # load results\n    &gt;&gt;&gt; results = load_output('my_dcTMD_results_N100.npz')\n    &gt;&gt;&gt; positions = results['x']\n    &gt;&gt;&gt; mean_work = results['Wmean']\n    &gt;&gt;&gt; dG = results['dG']\n    \"\"\"\n    if not Path(filepath).is_file():\n        raise FileNotFoundError(\n            f'The file \"{filepath}\" does not exist.',\n        )\n    if '.npz' in filepath:\n        with np.load(filepath) as npzfile:\n            res_dict = {key: npzfile[key] for key in npzfile.files}\n        print(f'Loaded data from {filepath}')\n        return res_dict\n    elif '.dat' in filepath:\n        headers = None\n        with open(filepath, 'r') as datfile:\n            # Read the header line, which starts with '#'\n            for line in datfile:\n                if line.startswith('#', 0, 5):\n                    headers = line.split()\n                    headers.remove('#')\n                    break\n        dctmd_results = np.loadtxt(filepath)\n        res_dict = {}\n        if headers is None:\n            raise ValueError(\n                f'No header line starting with \"#\" found in {filepath}'\n            )\n        if len(headers) != dctmd_results.shape[1]:\n            raise ValueError(\n                'Number of headers does not match number of data columns.'\n            )\n        for idx, key in enumerate(headers):\n            res_dict[key] = dctmd_results[:, idx]\n        print(f'Loaded data from {filepath}')\n        return res_dict\n    else:\n        print('Could not load file.')\n        print(f'{filepath} needs to be .dat or .npz file.')\n</code></pre>"},{"location":"reference/storing/","title":"storing","text":"<p>Classes that store constraint force data as work or force time traces.</p> <p>The resulting force or work sets are needed for further analysis.</p>"},{"location":"reference/storing/#dcTMD.storing.WorkSet","title":"<code>WorkSet(velocity, resolution=1, verbose=False)</code>","text":"<p>               Bases: <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Class for managing constraint work data.</p> <p>Parameters:</p> <ul> <li> <code>velocity</code>               (<code>Float</code>)           \u2013            <p>Pulling velocity in nm/ps.</p> </li> <li> <code>resolution</code>               (<code>Int</code>, default:                   <code>1</code> )           \u2013            <p>Striding to reduce work time trace.</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Enables verbose mode.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>work_</code>           \u2013            <p>Constraint work time traces, in kJ/mol.</p> </li> <li> <code>names_</code>           \u2013            <p>Constraint force file names corresponding to work time traces.</p> </li> <li> <code>time_</code>           \u2013            <p>Time trace corresponding to the work, in ps.</p> </li> <li> <code>position_</code>           \u2013            <p>Positions time trace, product of time trace and velocity, in nm.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Load some file names listed in 'filenames'\n&gt;&gt;&gt; import numpy as np\n&gt;&gt;&gt; from dcTMD.storing import WorkSet\n&gt;&gt;&gt; work_set = WorkSet(velocity=0.001, resolution=1)\n&gt;&gt;&gt; work_set.fit(filenames)  # noqa: F821\nLoading &amp; integrating force files: 100%|\u2588\u2588\u2588\u2588| X/X [XX:XX&lt;00:00,  X.XX/it]\nWorkSet(velocity=0.001)\n&gt;&gt;&gt; work_set.work_.shape\n(N_trajectories_, len(time_))\n</code></pre> <pre><code>&gt;&gt;&gt; # Reduce work by selecting some trajectories via their indices,\n&gt;&gt;&gt; # for example the first three, and receive a new WorkSet instance\n&gt;&gt;&gt; indices = np.array([0, 1, 2])\n&gt;&gt;&gt; reduced_set = work_set.reduce(indices)\n&gt;&gt;&gt; reduced_set.work_.shape\n(3, len(time_))\n</code></pre> <p>Initialize WorkSet class.</p> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef __init__(\n    self,\n    velocity: Float,\n    resolution: Int = 1,\n    verbose: bool = False,\n) -&gt; None:\n    \"\"\"Initialize WorkSet class.\"\"\"\n    self.velocity = velocity\n    self.resolution = resolution\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.WorkSet.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Load constraint force files and calculate work time traces.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ArrayLikeStr</code>)           \u2013            <p>File names of constraint force files to be read in and integrated.</p> </li> <li> <code>y</code>               (<code>Optional[ndarray]</code>, default:                   <code>None</code> )           \u2013            <p>Not used, present for scikit API consistency by convention.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code>          \u2013            <p>Fitted estimator.</p> </li> </ul> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef fit(\n    self,\n    X: ArrayLikeStr,  # noqa: WPS111 N803\n    y: Optional[np.ndarray] = None,  # noqa: WPS111\n):\n    \"\"\"\n    Load constraint force files and calculate work time traces.\n\n    Parameters\n    ----------\n    X :\n        File names of constraint force files to be read in and integrated.\n    y :\n        Not used, present for scikit API consistency by convention.\n\n    Returns\n    -------\n    self:\n        Fitted estimator.\n    \"\"\"\n    self.X = X  # noqa: WPS111 N803\n    # read a test file for the time trace\n    _get_time_from_testfile(self)\n    # fill arrays with data\n    self._fill_work()\n    return self\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.WorkSet.transform","title":"<code>transform(X, y=None)</code>","text":"<p>Return work set.</p> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef transform(self, X, y=None) -&gt; Float2DArray:  # noqa: WPS111 N803\n    \"\"\"Return work set.\"\"\"\n    return self.work_\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.WorkSet.reduce","title":"<code>reduce(indices)</code>","text":"<p>Reduce work set to a chosen subset and return new instance.</p> <p>Parameters:</p> <ul> <li> <code>indices</code>               (<code>Index1DArray</code>)           \u2013            <p>Indices corresponding to the work trajectories that are kept in the work set.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code>          \u2013            <p>Instance of WorkSet.</p> </li> </ul> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef reduce(self, indices: Index1DArray):\n    \"\"\"\n    Reduce work set to a chosen subset and return new instance.\n\n    Parameters\n    ----------\n    indices :\n        Indices corresponding to the work trajectories that are kept in the\n        work set.\n\n    Returns\n    -------\n    self :\n        Instance of WorkSet.\n    \"\"\"\n    import copy\n    reduced_work_set = copy.deepcopy(self)\n    reduced_work_set.work_ = reduced_work_set.work_[indices]\n    reduced_work_set.names_ = reduced_work_set.names_[indices]\n    return reduced_work_set\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.ForceSet","title":"<code>ForceSet(velocity, resolution=1, verbose=False)</code>","text":"<p>               Bases: <code>TransformerMixin</code>, <code>BaseEstimator</code></p> <p>Class for managing constraint force data.</p> <p>Parameters:</p> <ul> <li> <code>velocity</code>               (<code>Float</code>)           \u2013            <p>Pulling velocity in nm/ps.</p> </li> <li> <code>resolution</code>               (<code>Int</code>, default:                   <code>1</code> )           \u2013            <p>Striding to reduce work time trace. This parameter is only added for compatibility with WorkSet</p> </li> <li> <code>verbose</code>               (<code>bool</code>, default:                   <code>False</code> )           \u2013            <p>Enables verbose mode.</p> </li> </ul> <p>Attributes:</p> <ul> <li> <code>force_</code>           \u2013            <p>Constraint force time traces, in kJ/mol.</p> </li> <li> <code>names_</code>           \u2013            <p>Constraint force file names corresponding to force time traces.</p> </li> <li> <code>time_</code>           \u2013            <p>Time trace corresponding to the force, in ps.</p> </li> <li> <code>position_</code>           \u2013            <p>Positions time trace, product of time trace and velocity, in nm.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Load some file names listed in 'filenames'\n&gt;&gt;&gt; import numpy as np  # noqa: F401\n&gt;&gt;&gt; from dcTMD.storing import ForceSet\n&gt;&gt;&gt; filenames = np.loadtxt('my_filenames.txt')\n&gt;&gt;&gt; force_set = ForceSet(velocity=0.001, resolution=1)\n&gt;&gt;&gt; force_set.fit(filenames)\nLoading force files: 100%|\u2588\u2588\u2588\u2588| X/X [XX:XX&lt;00:00,  X.XX/it]\nForceSet(velocity=0.001)\n&gt;&gt;&gt; force_set.work_.shape\n(N_trajectories_, len(time_))\n</code></pre> <p>Initialize WorkSet class.</p> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef __init__(\n    self,\n    velocity: Float,\n    resolution: Int = 1,\n    verbose: bool = False,\n) -&gt; None:\n    \"\"\"Initialize WorkSet class.\"\"\"\n    self.velocity = velocity\n    self.resolution = resolution\n    self.verbose = verbose\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.ForceSet.fit","title":"<code>fit(X, y=None)</code>","text":"<p>Load constraint force files.</p> <p>Parameters:</p> <ul> <li> <code>X</code>               (<code>ArrayLikeStr</code>)           \u2013            <p>File names of constraint force files to be read in.</p> </li> <li> <code>y</code>               (<code>Optional[ndarray]</code>, default:                   <code>None</code> )           \u2013            <p>Not used, present for scikit API consistency by convention.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>self</code>          \u2013            <p>Fitted estimator.</p> </li> </ul> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef fit(\n    self,\n    X: ArrayLikeStr,  # noqa: WPS111 N803\n    y: Optional[np.ndarray] = None,  # noqa: WPS111\n):\n    \"\"\"\n    Load constraint force files.\n\n    Parameters\n    ----------\n    X :\n        File names of constraint force files to be read in.\n    y :\n        Not used, present for scikit API consistency by convention.\n\n    Returns\n    -------\n    self:\n        Fitted estimator.\n    \"\"\"\n    self.X = X  # noqa: WPS111 N803\n    # read a test file for the time trace\n    _get_time_from_testfile(self)\n    # fill arrays with data\n    self._fill_force()\n    self.integrate()\n    return self\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.ForceSet.transform","title":"<code>transform(X, y=None)</code>","text":"<p>Return force set.</p> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef transform(self, X, y=None) -&gt; Float2DArray:  # noqa: WPS111 N803\n    \"\"\"Return force set.\"\"\"\n    return self.force_\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.ForceSet.integrate","title":"<code>integrate()</code>","text":"<p>Integrate forces.</p> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef integrate(self) -&gt; None:\n    \"\"\"Integrate forces.\"\"\"\n    self.work_ = _integrate_force(self, self.force_)\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.save","title":"<code>save(filename, classobject)</code>","text":"<p>Save a class object: a data handler or an estimator.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>Str</code>)           \u2013            <p>File name to which classobject is saved.</p> </li> <li> <code>classobject</code>           \u2013            <p>Instance of the data handler, i.e. a WorkSet or ForceSet instance, or of an estimator, i.e. a WorkEstimator or ForceEstimator instance.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Save Estimators and data handlers. Here: WorkSet.\n&gt;&gt;&gt; # Save a WorkSet instance named work_set and load it again:\n&gt;&gt;&gt; from dcTMD.storing import save, load\n&gt;&gt;&gt; save(work_set, 'my_workset.joblib')  # noqa: F821\n&gt;&gt;&gt; my_workset = load('my_workset.joblib')\n</code></pre> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef save(\n    filename: Str,\n    classobject,\n) -&gt; None:\n    \"\"\"\n    Save a class object: a data handler or an estimator.\n\n    Parameters\n    ----------\n    filename :\n        File name to which classobject is saved.\n    classobject :\n        Instance of the data handler, i.e. a WorkSet or ForceSet instance, or\n        of an estimator, i.e. a WorkEstimator or ForceEstimator instance.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Save Estimators and data handlers. Here: WorkSet.\n    &gt;&gt;&gt; # Save a WorkSet instance named work_set and load it again:\n    &gt;&gt;&gt; from dcTMD.storing import save, load\n    &gt;&gt;&gt; save(work_set, 'my_workset.joblib')  # noqa: F821\n    &gt;&gt;&gt; my_workset = load('my_workset.joblib')\n    \"\"\"\n    joblib.dump(classobject, filename)\n</code></pre>"},{"location":"reference/storing/#dcTMD.storing.load","title":"<code>load(filename)</code>","text":"<p>Load a data handler or an estimator.</p> <p>Parameters:</p> <ul> <li> <code>filename</code>               (<code>Str</code>)           \u2013            <p>Name of the file containing the data handler.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>handler</code> (              <code>Any</code> )          \u2013            <p>Loaded class object.</p> </li> </ul> <p>Examples:</p> <pre><code>&gt;&gt;&gt; # Loads estimators and data handlers. Here: WorkSet.\n&gt;&gt;&gt; # Save a WorkSet instance named work_set and load it again:\n&gt;&gt;&gt; from dcTMD.storing import save, load\n&gt;&gt;&gt; save(work_set, 'my_workset.joblib')  # noqa: F821\n&gt;&gt;&gt; my_workset = load('my_workset.joblib')\n</code></pre> Source code in <code>src/dcTMD/storing.py</code> <pre><code>@beartype\ndef load(\n    filename: Str,\n) -&gt; Any:\n    \"\"\"\n    Load a data handler or an estimator.\n\n    Parameters\n    ----------\n    filename :\n        Name of the file containing the data handler.\n\n    Returns\n    -------\n    handler:\n        Loaded class object.\n\n    Examples\n    --------\n    &gt;&gt;&gt; # Loads estimators and data handlers. Here: WorkSet.\n    &gt;&gt;&gt; # Save a WorkSet instance named work_set and load it again:\n    &gt;&gt;&gt; from dcTMD.storing import save, load\n    &gt;&gt;&gt; save(work_set, 'my_workset.joblib')  # noqa: F821\n    &gt;&gt;&gt; my_workset = load('my_workset.joblib')\n    \"\"\"\n    return joblib.load(filename)\n</code></pre>"},{"location":"reference/utils/","title":"utils","text":"<p>Utils submodule.</p>"},{"location":"reference/utils/#dcTMD.utils.gaussfilter_friction","title":"<code>gaussfilter_friction(friction, pos, sigma, mode='nearest')</code>","text":"<p>Smoothes friction with a gaussian kernel and 'nearest' borders.</p> <p>Parameters:</p> <ul> <li> <code>friction</code>               (<code>1d np.array</code>)           \u2013            <p>Array that contains the friction.</p> </li> <li> <code>pos</code>               (<code>1d np.array</code>)           \u2013            <p>Positions corresponding to entries in friction array in nm.</p> </li> <li> <code>sigma</code>               (<code>float</code>)           \u2013            <p>Standard deviation of gaussian kernel in nm.</p> </li> <li> <code>mode</code>               (<code>Str</code>, default:                   <code>'nearest'</code> )           \u2013            <p>options: \u2018reflect\u2019, \u2018constant\u2019, \u2018nearest\u2019, \u2018mirror\u2019, \u2018wrap\u2019 The mode parameter determines how the input array is extended beyond its boundaries. Default is \u2018reflect\u2019. Behavior for each option see scipy.ndimage.gaussian_filter1d</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>1d np.array</code>           \u2013            <p>Smoothed friction.</p> </li> </ul> Source code in <code>src/dcTMD/utils/_smoothing.py</code> <pre><code>@beartype\ndef gaussfilter_friction(\n    friction: Float1DArray,\n    pos: Float1DArray,\n    sigma: Float,\n    mode: Str = 'nearest',\n) -&gt; Float1DArray:\n    \"\"\"\n    Smoothes friction with a gaussian kernel and 'nearest' borders.\n\n    Parameters\n    ----------\n    friction : 1d np.array\n        Array that contains the friction.\n    pos : 1d np.array\n        Positions corresponding to entries in friction array in nm.\n    sigma : float\n        Standard deviation of gaussian kernel in nm.\n    mode:\n        options: \u2018reflect\u2019, \u2018constant\u2019, \u2018nearest\u2019, \u2018mirror\u2019, \u2018wrap\u2019\n        The mode parameter determines how the input array is\n        extended beyond its boundaries. Default is \u2018reflect\u2019.\n        Behavior for each option see scipy.ndimage.gaussian_filter1d\n\n    Returns\n    -------\n    1d np.array\n        Smoothed friction.\n    \"\"\"\n    from scipy.ndimage import gaussian_filter1d\n    delta_x = pos[1] - pos[0]\n    blur = np.ceil(sigma / delta_x).astype(int)\n    return gaussian_filter1d(friction, sigma=blur, mode=mode)\n</code></pre>"},{"location":"reference/utils/#dcTMD.utils.bootstrapping","title":"<code>bootstrapping(estimator, func, descriptor, verbose=False)</code>","text":"<p>Perform a bootstrapping error analysis.</p> <p>The bootstrapping error analysis is performed using a given function <code>func</code> by drawing random work trajectories from the <code>estimator</code>'s WorkSet instance with replacement. The quantity of interest is then calculated for the new sample and stored in <code>quantity_resampled</code>. This process is repeated <code>n_resamples</code> times, which is a key of the <code>descriptor</code> dictionary. The random number generator can be fed a <code>seed</code>, the second key of the <code>descriptor</code> which is optional. Thirdly, a <code>mode</code> must be in the <code>descriptor</code>, which can either be the string 'std' for a standard distribution of the resampled quantity or a number in the interval [0, 1) which yields confidence intervals instead.</p> <p>Parameters:</p> <ul> <li> <code>estimator</code>           \u2013            <p>Instance of a WorkEstimator.</p> </li> <li> <code>func</code>               (<code>Callable</code>)           \u2013            <p>Function which takes a WorkSet instance as single argument and returns the the quantitity for which the bootstrapping error analysis is performed.</p> </li> <li> <code>descriptor</code>               (<code>dict</code>)           \u2013            <p>Dictionary of the estimator which provides <code>mode</code>, <code>n_resampled</code> and <code>seed</code> as keys.</p> </li> <li> <code>verbose</code>               (<code>Optional[bool]</code>, default:                   <code>False</code> )           \u2013            <p>Enables verbose mode.</p> </li> </ul> <p>Returns:</p> <ul> <li> <code>s_quantity</code>          \u2013            <p>Estimated error for the quantity returned by <code>func</code>.</p> </li> <li> <code>quantity_resampled</code>          \u2013            <p>Quantities returned by <code>func</code> for the resampled work trajectories.</p> </li> </ul> Source code in <code>src/dcTMD/utils/_bootstrapping.py</code> <pre><code>@beartype\ndef bootstrapping(\n    estimator,\n    func: Callable,\n    descriptor: dict,\n    verbose: Optional[bool] = False,\n):\n    \"\"\"\n    Perform a bootstrapping error analysis.\n\n    The bootstrapping error analysis is performed using a given function `func`\n    by drawing random work trajectories from the `estimator`'s WorkSet\n    instance with replacement. The quantity of interest is then calculated for\n    the new sample and stored in `quantity_resampled`. This process is repeated\n    `n_resamples` times, which is a key of the `descriptor` dictionary. The\n    random number generator can be fed a `seed`, the second key of the\n    `descriptor` which is optional. Thirdly, a `mode` must be in the\n    `descriptor`, which can either be the string 'std' for a standard\n    distribution of the resampled quantity or a number in the interval [0, 1)\n    which yields confidence intervals instead.\n\n    Parameters\n    ----------\n    estimator :\n        Instance of a WorkEstimator.\n    func :\n        Function which takes a WorkSet instance as single argument and returns\n        the the quantitity for which the bootstrapping error analysis is\n        performed.\n    descriptor :\n        Dictionary of the estimator which provides `mode`, `n_resampled`\n        and `seed` as keys.\n    verbose :\n        Enables verbose mode.\n\n    Returns\n    -------\n    s_quantity :\n        Estimated error for the quantity returned by `func`.\n    quantity_resampled :\n        Quantities returned by `func` for the resampled work trajectories.\n    \"\"\"\n\n    \"\"\"\n    n_traj, length_data = np.shape(estimator.work_set.work_)\n    probe_return = func(estimator.work_set.work_)\n    if isinstance(probe_return, tuple):\n        len_of_return = len(probe_return)\n    else:\n        len_of_return = 1\n\n    quantity_resampled = np.empty((\n        descriptor['n_resamples'],\n        len_of_return,\n        length_data,\n    ))\n    # Initialize RNG.\n    rng = np.random.default_rng(descriptor['seed'])\n    for idx in tqdm.tqdm(\n        range(descriptor['n_resamples']),\n        desc='Bootstrapping progress',\n    ):\n        # Draw random work time traces\n        random_indices = rng.integers(0, n_traj, n_traj)\n        work_set_resampled = estimator.work_set.work_[random_indices]\n\n        # Calculate and save the relevant statistic\n        quantity = func(work_set_resampled)\n        quantity_resampled[idx] = quantity\n    \"\"\"\n    quantity_resampled = _bootstrap_resampling(\n        estimator,\n        func,\n        descriptor,\n    )\n    # There are now bootstrapped quantities in the '_resampled' variables.\n    # We are interested in the element-wise distributions and thus\n    # calculate (1) the standard distribution of the resampled quantity\n    # at all points or (2) confidence intervals.\n    if verbose:\n        sys.stdout.write('Finished resampling, starting reduction.')\n    s_quantity = _bootstrap_reducer(\n        descriptor,\n        quantity_resampled,\n    )\n    # The distributions of the '_resampled' variables must be inspected\n    # and are thus also returned.\n    return s_quantity, quantity_resampled\n</code></pre>"},{"location":"reference/utils/plotting/","title":"plotting","text":"<p>Simple plot functions for dcTMD results.</p>"},{"location":"reference/utils/plotting/#dcTMD.utils.plotting.plot_dcTMD_results","title":"<code>plot_dcTMD_results(estimator, friction=None, x=None, figsize=(4, 4))</code>","text":"<p>Plot dcTMD results overview in two subplots. This function generates a figure with two subplots. The top subplot contains free energy, dissipative work, and mean work. The bottom subplot contains friction vs. position.</p> <p>Args:     estimator:         dcTMD work or force estimator object,         containing the dcTMD results.     friction (array-like, optional):         Friction values to plot. If not provided,         the function uses <code>estimator.friction_</code>. If <code>estimator</code> has a         <code>friction_smooth_</code> attribute, it will use that instead.     x (array-like, optional):         The x-axis positions for the plots. If not         provided, <code>estimator.position_</code> is used.     figsize (tuple, optional):         Size of the figure. Default is (4, 4).</p> <p>Returns:     tuple: containing fig and axs</p> <p>Example:     &gt;&gt;&gt; plot_dcTMD_results(     ...     estimator=my_estimator,     ...     figsize=(6, 6),     ... )     &gt;&gt;&gt; plt.show()</p> Source code in <code>src/dcTMD/utils/plotting.py</code> <pre><code>def plot_dcTMD_results(\n    estimator,\n    friction=None,\n    x=None,\n    figsize=(4, 4),\n):\n    \"\"\"Plot dcTMD results overview in two subplots.\n    This function generates a figure with two subplots.\n    The top subplot contains free energy, dissipative work, and mean work.\n    The bottom subplot contains friction vs. position.\n\n    Args:\n        estimator:\n            dcTMD work or force estimator object,\n            containing the dcTMD results.\n        friction (array-like, optional):\n            Friction values to plot. If not provided,\n            the function uses `estimator.friction_`. If `estimator` has a\n            `friction_smooth_` attribute, it will use that instead.\n        x (array-like, optional):\n            The x-axis positions for the plots. If not\n            provided, `estimator.position_` is used.\n        figsize (tuple, optional):\n            Size of the figure. Default is (4, 4).\n\n    Returns:\n        tuple: containing fig and axs\n\n    Example:\n        &gt;&gt;&gt; plot_dcTMD_results(\n        ...     estimator=my_estimator,\n        ...     figsize=(6, 6),\n        ... )\n        &gt;&gt;&gt; plt.show()\n    \"\"\"\n    fig, axs = plt.subplots(ncols=1,\n                            nrows=2,\n                            sharex=True,\n                            figsize=figsize,\n                            )\n    if x is None:\n        x = estimator.position_\n    plot_dG_Wdiss(estimator, axs[0], x=x)\n    if friction is None:\n        friction = estimator.friction_\n        if hasattr(estimator, 'friction_smooth_'):\n            friction = estimator.friction_smooth_\n    plot_Gamma(x, friction, axs[1])\n    axs[0].legend(\n        loc='lower left',\n        mode='expand',\n        bbox_to_anchor=(0, 1.05, 1, 0.2),\n        bbox_transform=axs[0].transAxes,\n        frameon=False,\n        ncol=3,\n    )\n    axs[0].set_xlabel(\"\")\n    plt.tight_layout()\n    return fig, axs\n</code></pre>"},{"location":"reference/utils/plotting/#dcTMD.utils.plotting.plot_dG_Wdiss","title":"<code>plot_dG_Wdiss(workestimator, ax, x=None)</code>","text":"<p>Plot free energy, dissipative work and mean work vs position.</p> <p>Args:     workestimator:         dcTMD workestimator object,         containing the dcTMD results.     ax (matplotlib.axes.Axes):         The axes object where the plot will be drawn.     x (array-like, optional):         The x-axis positions for the plot. If not provided,         <code>workestimator.position_</code> is used.</p> <p>Returns:     None</p> <p>Notes:     - The x-axis represents the position along the coordinate (in nm).     - The y-axis represents the energy values (in kJ/mol).</p> <p>Example:     &gt;&gt;&gt; fig, ax = plt.subplots()     &gt;&gt;&gt; plot_dG_Wdiss(workestimator=my_estimator, ax=ax)     &gt;&gt;&gt; plt.show()</p> Source code in <code>src/dcTMD/utils/plotting.py</code> <pre><code>def plot_dG_Wdiss(workestimator, ax, x=None):\n    \"\"\"Plot free energy, dissipative work and mean work vs position.\n\n    Args:\n        workestimator:\n            dcTMD workestimator object,\n            containing the dcTMD results.\n        ax (matplotlib.axes.Axes):\n            The axes object where the plot will be drawn.\n        x (array-like, optional):\n            The x-axis positions for the plot. If not provided,\n            `workestimator.position_` is used.\n\n    Returns:\n        None\n\n    Notes:\n        - The x-axis represents the position along the coordinate (in nm).\n        - The y-axis represents the energy values (in kJ/mol).\n\n    Example:\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; plot_dG_Wdiss(workestimator=my_estimator, ax=ax)\n        &gt;&gt;&gt; plt.show()\n    \"\"\"\n    if x is None:\n        x = workestimator.position_\n    ax.plot(x, workestimator.dG_, label=LABEL_dG)\n    ax.plot(x, workestimator.W_mean_, label=r'W$_{\\mathrm{mean}}$')\n    ax.plot(x, workestimator.W_diss_, label=r'W$_{\\mathrm{diss}}$')\n    ax.set(xlabel=LABEL_POSITION_NM,\n           ylabel=UNIT_ENERGY,\n           xlim=[min(x), max(x)],\n           )\n</code></pre>"},{"location":"reference/utils/plotting/#dcTMD.utils.plotting.plot_Gamma","title":"<code>plot_Gamma(x, friction, ax, label=None)</code>","text":"<p>Plot friction factor (\u0393) vs position.</p> <p>Args:     x (array-like):         Positions along the coordinate (in nm).     friction (array-like):         Friction factor values (in kJ nm\u00b2/(mol ps)).     ax (matplotlib.axes.Axes):         The axes object where the plot will be drawn.     label (str, optional):         Label for the friction curve. Default is None.</p> <p>Example:     &gt;&gt;&gt; fig, ax = plt.subplots()     &gt;&gt;&gt; plot_Gamma(positions, friction_values, ax)     &gt;&gt;&gt; plt.legend()     &gt;&gt;&gt; plt.show()</p> Source code in <code>src/dcTMD/utils/plotting.py</code> <pre><code>def plot_Gamma(x, friction, ax, label=None):\n    \"\"\"Plot friction factor (\u0393) vs position.\n\n    Args:\n        x (array-like):\n            Positions along the coordinate (in nm).\n        friction (array-like):\n            Friction factor values (in kJ nm\u00b2/(mol ps)).\n        ax (matplotlib.axes.Axes):\n            The axes object where the plot will be drawn.\n        label (str, optional):\n            Label for the friction curve. Default is None.\n\n    Example:\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; plot_Gamma(positions, friction_values, ax)\n        &gt;&gt;&gt; plt.legend()\n        &gt;&gt;&gt; plt.show()\n    \"\"\"\n    ax.plot(x, friction, label=label)\n    ax.set(xlabel=LABEL_POSITION_NM,\n           ylabel=LABEL_FRICTION,\n           xlim=[min(x), max(x)],\n           )\n</code></pre>"},{"location":"reference/utils/plotting/#dcTMD.utils.plotting.plot_dG","title":"<code>plot_dG(x, dG, ax, label=None, color=None)</code>","text":"<p>Plot free energy vs position.</p> <p>Args:     x (array-like):         Positions along the coordinate (in nm).     dG (array-like):         Free energy values (in kJ/mol).     ax (matplotlib.axes.Axes):         The axes object where the plot will be drawn.     label (str, optional):         Label for the free energy curve. Default is None.     color (str, optional):         Color of the free energy curve. Default is None.</p> <p>Returns:     matplotlib.lines.Line2D:         The line object representing the plotted curve.</p> <p>Example:     &gt;&gt;&gt; fig, ax = plt.subplots()     &gt;&gt;&gt; plot_dG(positions, free_energy_values, ax)     &gt;&gt;&gt; plt.legend()     &gt;&gt;&gt; plt.show()</p> Source code in <code>src/dcTMD/utils/plotting.py</code> <pre><code>def plot_dG(x, dG, ax, label=None, color=None):\n    \"\"\"Plot free energy vs position.\n\n    Args:\n        x (array-like):\n            Positions along the coordinate (in nm).\n        dG (array-like):\n            Free energy values (in kJ/mol).\n        ax (matplotlib.axes.Axes):\n            The axes object where the plot will be drawn.\n        label (str, optional):\n            Label for the free energy curve. Default is None.\n        color (str, optional):\n            Color of the free energy curve. Default is None.\n\n    Returns:\n        matplotlib.lines.Line2D:\n            The line object representing the plotted curve.\n\n    Example:\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; plot_dG(positions, free_energy_values, ax)\n        &gt;&gt;&gt; plt.legend()\n        &gt;&gt;&gt; plt.show()\n    \"\"\"\n    line = ax.plot(x, dG, label=label, color=color)[0]\n    ax.set(xlabel=LABEL_POSITION_NM,\n           ylabel=r'$\\Delta G$ [kJ/mol]',\n           xlim=[min(x), max(x)],\n           )\n    return line\n</code></pre>"},{"location":"reference/utils/plotting/#dcTMD.utils.plotting.plot_dG_werrors","title":"<code>plot_dG_werrors(workestimator, ax, labeldG=None, color=None)</code>","text":"<p>Plot free energy with errors against position. This function generates a plot of the free energy change (\u0394G) as a function of position (x), including error bands if available.</p> <p>Args:     workestimator:         dcTMD workestimator object.         It is expected to have the following attributes:         <code>position_</code>, <code>dG_</code>, <code>s_dG_</code>     ax (matplotlib.axes.Axes):         The axes object where the plot will be drawn.     labeldG (str, optional):         Label for the free energy curve. Default is None.     color (str, optional):         Color of the free energy curve. Default is None.</p> <p>Notes:     - If <code>s_dG_</code> is not available in <code>workestimator</code>,         the function will print an errors message.     - The error band is plotted as a shaded region         around the free energy curve.</p> <p>Example:     &gt;&gt;&gt; fig, ax = plt.subplots()     &gt;&gt;&gt; plot_dG_werrors(workestimator=my_estimator, ax=ax)     &gt;&gt;&gt; plt.show()</p> Source code in <code>src/dcTMD/utils/plotting.py</code> <pre><code>def plot_dG_werrors(\n    workestimator,\n    ax,\n    labeldG=None,\n    color=None,\n):\n    \"\"\"Plot free energy with errors against position.\n    This function generates a plot of the free energy change (\u0394G)\n    as a function of position (x), including error bands if available.\n\n    Args:\n        workestimator:\n            dcTMD workestimator object.\n            It is expected to have the following attributes:\n            `position_`, `dG_`, `s_dG_`\n        ax (matplotlib.axes.Axes):\n            The axes object where the plot will be drawn.\n        labeldG (str, optional):\n            Label for the free energy curve. Default is None.\n        color (str, optional):\n            Color of the free energy curve. Default is None.\n\n    Notes:\n        - If `s_dG_` is not available in `workestimator`,\n            the function will print an errors message.\n        - The error band is plotted as a shaded region\n            around the free energy curve.\n\n    Example:\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; plot_dG_werrors(workestimator=my_estimator, ax=ax)\n        &gt;&gt;&gt; plt.show()\n    \"\"\"\n    if hasattr(workestimator, 's_dG_'):\n        x = workestimator.position_\n        dG = workestimator.dG_\n        sdG = workestimator.s_dG_\n        line = plot_dG(x, dG, ax, label=labeldG, color=color)\n        color = line.get_color()\n        if len(sdG) == 2:\n            ax.fill_between(\n                x,\n                sdG[0],\n                sdG[1],\n                facecolor=color,\n                alpha=ALPHA_VALUE,\n            )\n        else:\n            ax.fill_between(\n                x,\n                dG - sdG,\n                dG + sdG,\n                facecolor=color,\n                alpha=ALPHA_VALUE,\n            )\n    else:\n        sys.stdout.write(\n            f'no errors are determined for {workestimator}'\n        )\n        sys.stdout.write(\n            'use estimate_free_energy_errors() to determine errors'\n        )\n        return\n</code></pre>"},{"location":"reference/utils/plotting/#dcTMD.utils.plotting.plot_worklines","title":"<code>plot_worklines(workset, ax, x=None, color='#777', res=1)</code>","text":"<p>Line plots of the individual work trajectories in the workset.</p> <p>Args:     workset:         workset object     ax (matplotlib.axes.Axes):         The axes object where the plot will be drawn.     x (array-like, optional):         The x-axis positions for the plot. If not provided,         <code>workset.position_</code> is used.     color (str, optional):         Color of the work lines. Default is '#777'.     res (int, optional):         Resolution for downsampling the data.         Only every <code>res</code>-th point         will be plotted. Default is 1 (no downsampling).</p> <p>Notes:     - The x-axis represents the position (in nm).     - The y-axis represents the work values (in kJ/mol).     - Each trajectory is plotted as a semi-transparent line.</p> <p>Example:     &gt;&gt;&gt; fig, ax = plt.subplots()     &gt;&gt;&gt; plot_worklines(workset=my_workset, ax=ax)     &gt;&gt;&gt; plt.show()</p> Source code in <code>src/dcTMD/utils/plotting.py</code> <pre><code>def plot_worklines(workset, ax, x=None, color='#777', res=1):\n    \"\"\"Line plots of the individual work trajectories\n    in the workset.\n\n    Args:\n        workset:\n            workset object\n        ax (matplotlib.axes.Axes):\n            The axes object where the plot will be drawn.\n        x (array-like, optional):\n            The x-axis positions for the plot. If not provided,\n            `workset.position_` is used.\n        color (str, optional):\n            Color of the work lines. Default is '#777'.\n        res (int, optional):\n            Resolution for downsampling the data.\n            Only every `res`-th point\n            will be plotted. Default is 1 (no downsampling).\n\n    Notes:\n        - The x-axis represents the position (in nm).\n        - The y-axis represents the work values (in kJ/mol).\n        - Each trajectory is plotted as a semi-transparent line.\n\n    Example:\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; plot_worklines(workset=my_workset, ax=ax)\n        &gt;&gt;&gt; plt.show()\n    \"\"\"\n    if x is None:\n        x = workset.position_\n    for w in workset.work_:\n        w_reduced = w[::res]\n        x_reduced = x[::res]\n        ax.plot(\n            x_reduced,\n            w_reduced,\n            color=color,\n            alpha=ALPHA_VALUE,\n            lw=WORKLINES_WIDTH,\n        )\n    ax.set(xlabel=LABEL_POSITION_NM,\n           ylabel=r'work $W$ [kJ/mol]',\n           xlim=[min(x), max(x)],\n           )\n</code></pre>"},{"location":"reference/utils/plotting/#dcTMD.utils.plotting.plot_histo_normaldist","title":"<code>plot_histo_normaldist(histodata, ax, color='None', label=None)</code>","text":"<p>Plots a histogram of the input data and overlays a probability density function (PDF) of a normal distribution fitted to the data.</p> <p>Args:     histodata (array-like):         The data to be plotted.         It will be flattened if not already 1D.     ax (matplotlib.axes.Axes):         The axes object where the plot will be drawn.     color (str, optional):         Color of the histogram and the fitted         normal distribution curve.         Default is 'None'.     label (str, optional):         Label for the histogram. Default is None.</p> <p>Notes:     - Bin width is estimated with the Freedman-Diaconis rule (bins='fd').     - The normal distribution is fitted using <code>scipy.stats.norm.fit</code>.     - The x-axis represents the probability density (P),     - The y-axis represents the work values (W) in kJ/mol.</p> <p>Example:     &gt;&gt;&gt; fig, ax = plt.subplots()     &gt;&gt;&gt; plot_histo_normaldist(my_data, ax=ax)     &gt;&gt;&gt; plt.legend()     &gt;&gt;&gt; plt.show()</p> Source code in <code>src/dcTMD/utils/plotting.py</code> <pre><code>def plot_histo_normaldist(histodata, ax, color='None', label=None):\n    \"\"\"Plots a histogram of the input data and overlays a\n    probability density function (PDF) of a normal distribution\n    fitted to the data.\n\n    Args:\n        histodata (array-like):\n            The data to be plotted.\n            It will be flattened if not already 1D.\n        ax (matplotlib.axes.Axes):\n            The axes object where the plot will be drawn.\n        color (str, optional):\n            Color of the histogram and the fitted\n            normal distribution curve.\n            Default is 'None'.\n        label (str, optional):\n            Label for the histogram. Default is None.\n\n    Notes:\n        - Bin width is estimated with the Freedman-Diaconis rule (bins='fd').\n        - The normal distribution is fitted using `scipy.stats.norm.fit`.\n        - The x-axis represents the probability density (P),\n        - The y-axis represents the work values (W) in kJ/mol.\n\n    Example:\n        &gt;&gt;&gt; fig, ax = plt.subplots()\n        &gt;&gt;&gt; plot_histo_normaldist(my_data, ax=ax)\n        &gt;&gt;&gt; plt.legend()\n        &gt;&gt;&gt; plt.show()\n    \"\"\"\n    histo = histodata.ravel()\n    ax.hist(\n        histo,\n        bins='fd',\n        density=True,\n        histtype='stepfilled',\n        align='mid',\n        alpha=0.5,\n        orientation='horizontal',\n        color=color,\n        label=label,\n        ec=color,\n        zorder=3,\n    )\n    mu, std = norm.fit(histo)\n    # Plot the PDF.\n    y = np.linspace(np.min(histo) - 10,\n                    np.max(histo) + 10,\n                    100,\n                    )\n    p = norm.pdf(y, mu, std)\n    ax.plot(p, y, color=color, zorder=1)\n    ax.set(xlabel=r'$P$',\n           ylabel=r'$W$ [kJ/mol]',\n           )\n</code></pre>"},{"location":"tutorials/CLI/","title":"CLI","text":"In\u00a0[4]: Copied! <pre>%%bash\npython -m dcTMD\n</pre> %%bash python -m dcTMD <pre>Usage: python -m dcTMD [OPTIONS]\n\n  ------------------------- |         dcTMD         |\n  ------------------------- Calculate free energy and friction for given\n  constraint force files.\n\n  Analysis tools for dissipation-corrected targeted molecular dynamics, which\n  is an enhanced sampling method to enforce rare events in biomolecular\n  systems. When publishing results gained with this python package, please\n  cite the following publications: (1) T\u00e4nzel, Victor and J\u00e4ger, Miriam and\n  Wolf, Steffen in preparation. (2) Wolf, Steffen, and Gerhard Stock.\n  \"Targeted molecular dynamics calculations of free energy profiles using a\n  nonequilibrium friction correction.\" Journal of chemical theory and\n  computation 14.12 (2018): 6175- 6182.\n\nOptions:\n  -m, --mode [work|force]  Use either work or force autocovariance function to\n                           calculatedcTMD quantities.  [default: work;\n                           required]\n  -f, --file TEXT          Input: File containing list of all constraint force\n                           file namesor glob pattern e.g.\"*.xvg\" to generate a\n                           list of all constraint force files using\n                           glob.glob()  [required]\n  -o, --outname PATH       Output: Path/prefix of output names.\n  -T, --temperature FLOAT  Simulation temperature in K.  [required]\n  -vel, --velocity FLOAT   Pulling velocity in nm/ps.  [required]\n  --res INTEGER            Striding to reduce size of returned free energy and\n                           friction  [default: 1]\n  -s, --sigma FLOAT        Standard deviation of gaussian filter in nm.\n  --resamples INTEGER      Number of resamples used in optional bootstrapping.\n                           This is only available in mode work\n  -v, --verbose            Enable verbose mode.  [default: False]\n  -p, --plot               Plots free energy and smoothed friction.  [default:\n                           False]\n  -sd, --save_dataset      Save the Work/ForceSet class to file.  [default:\n                           False]\n  --help                   Show this message and exit.\n</pre> In\u00a0[\u00a0]: Copied! <pre># Usage example:\npython -m dcTMD -f '*.xvg' -o path/to/output/name  -T 290.5 -v 0.001 --verbose --plot --save_dataset\n</pre> # Usage example: python -m dcTMD -f '*.xvg' -o path/to/output/name  -T 290.5 -v 0.001 --verbose --plot --save_dataset"},{"location":"tutorials/CLI/#command-line-interface","title":"Command Line Interface\u00b6","text":"<p>Our package features a Python command-line interface (CLI) script called \"dcTMD\".</p> <p>The script loads the constraint force files, generates a work/force set, and calculates the mean work, dissipated work, free energy, and friction factor. The output is saved as a .npz and .dat file, and the work/force set can be saved separately using the \"--save_dataset\" option. Furthermore, with the --plot option an overview plot of the results in generated.</p> <p>The CLI also provides a verbose mode for debugging and error reporting.</p> <p>To get an overview over all modules simply run the following command in the shell.</p>"},{"location":"tutorials/Gromacs/","title":"Create trajectories with Gromacs","text":""},{"location":"tutorials/Gromacs/#input-files","title":"Input files","text":"<p>Download the tutorial_files.tar.gz and unpack via</p> <p><pre><code>tar -xzvf ./tutorial_files.tar\n</code></pre> You will find a folder with the following files:</p> <pre><code>ls\n\n3ptb_AMBER99SB_ben_pushEQUIBRUN.mdp \n3ptb_AMBER99SB_ben_pushRUN_v0.001.mdp\n3ptb_AMBER99SB_ben.gro\n3ptb_AMBER99SB_ben.top\n3ptb_AMBER99SB_ben.ndx\n3ptb_AMBER99SB_ben_Protein_chain_A.itp\n3ptb_AMBER99SB_ben_Ion_chain_B.itp\n3ptb_ben_H2_GMX_RESP.itp\nposre_Protein_chain_A.itp\nposre_Ion_chain_B.itp\nposre_ben.itp\n</code></pre> <ul> <li> <p>Files for run input commands:</p> <ul> <li> <p>The pushEQUIBRUN.mdp file is an initial equilibration file for generating start simulation files with different initial velocity distributions.</p> </li> <li> <p>The pushRUN_v0.001.mdp file is the respective command input for the non-equilibrium pulling. </p> </li> <li> <p>3ptb refers to the protein data base code of a trypsin structure, AMBER99SB to the employed force field, and ben to the benzamidine ligand.</p> </li> </ul> </li> <li> <p>Structure file: </p> <ul> <li>3ptb_AMBER99SB_ben.gro in which the trypsin-benzamidine complex is equilibrated in TIP3P water with a physiological NaCl concentration and a single Ca2+ ion.</li> </ul> </li> <li> <p>Topologies and position restraint files:</p> <ul> <li>3ptb_AMBER99SB_ben.top</li> <li>3ptb_AMBER99SB_ben_Protein_chain_A.itp</li> <li>3ptb_AMBER99SB_ben_Ion_chain_B.itp</li> <li>3ptb_ben_H2_GMX_RESP.itp</li> <li>posre_Protein_chain_A.itp</li> <li>posre_Ion_chain_B.itp</li> <li>posre_ben.itp</li> </ul> </li> <li> <p>Index file:</p> <ul> <li>3ptb_AMBER99SB_ben.ndx</li> <li>Important: the index file needs to include an anchor group from whose center of mass the ligand is pulled away (in this case: the group [sheet] containing C-alpha atoms from the central beta-sheet) and the ligand itself (or better, the heavy atoms of the ligand, here group [ BEN_heavy ]). If you want to create a respective anchor index for your own simulation problem, choose an anchor group that is tightly connected to the remainder of the protein (such as C-alpha atoms in alpha-helices and beta-sheets). The vector connecting the centers of mass of anchor and ligand needs to roughly point into the direction of a putative unbinding path.</li> </ul> </li> </ul>"},{"location":"tutorials/Gromacs/#carrying-out-pulling-md-simulations","title":"Carrying out pulling MD simulations","text":"<p>For the generation of the input structure in your own project, we advise you to carry out an initial NPT equilibration simulation of at least 10 ns length. Here, we have done this already for you and generated an equilibrated structure.</p> <p>You will need a number (optimally between 100-200, but here we restrict ourselves to 10) of equilibrated trajectories with different initial velocity distributions. For this, generate an initial equilibration folder and the simulation start TPR files using:</p> <pre><code>mkdir equib\ncd equib/\n\nfor i in {000..009}\ndo\ngmx grompp -f ../3ptb_AMBER99SB_ben_pushEQUIBRUN.mdp -c ../3ptb_AMBER99SB_ben.gro -r ../3ptb_AMBER99SB_ben.gro -p ../3ptb_AMBER99SB_ben.top -n ../3ptb_AMBER99SB_ben.ndx -o 3ptb_AMBER99SB_ben_pushEQUIBRUN_\"$i\".tpr -maxwarn 1 \ndone\n</code></pre> <p>and run the individual simulations via, e.g., <pre><code>gmx mdrun -v -deffnm 3ptb_AMBER99SB_ben_pushEQUIBRUN_001\n</code></pre></p> <p>As these initial runs only require simulations of 0.1 ns length, they should be ready within a reasonably short time, i.e., some minutes.</p> <p>When all equilibration simulations have been carried out, prepare a separate directory for the pulling simulations and the individual pulling input TPR files via: <pre><code>cd ..\nmkdir v0.001\ncd v0.001/\n\nfor i in {000..009}\ndo\ngmx grompp -f ../3ptb_AMBER99SB_ben_pushRUN_v0.001.mdp -c ../equib/3ptb_AMBER99SB_ben_pushEQUIBRUN_\"$i\".gro -p ../3ptb_AMBER99SB_ben.top -n ../3ptb_AMBER99SB_ben.ndx -o 3ptb_AMBER99SB_ben_pushRUN_0.001_\"$i\".tpr\ndone\n</code></pre> Note that the notation _0.001_ stands for a velocity in Gromacs units of \\(0.001~\\text{nm}/\\text{ps}\\), i.e., \\(1~\\text{m}/\\text{s}\\). To our current experience, this is a sweet-spot velocity with the best trade-off between slow pulling and minimal computational effort. Run the simulations via, e.g., <pre><code>gmx mdrun -v -deffnm 3ptb_AMBER99SB_ben_pushRUN_0.001_000\n</code></pre> These simulations will each require 1-2 hours on a modern workstation, so you better run them in parallel on a HPC cluster of your choice.</p> <p>For all further analysis, you require the 3ptb_AMBER99SB_ben_pushRUN_0.001_*_pullf.xvg files (with * denoting the respective run number).</p>"},{"location":"tutorials/create_featureset/","title":"Cluster trajectories","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nfrom dcTMD import storing\n\npullf_files = '../../tests/testdata/pullf_filenames.dat'\npullf_filenames = np.loadtxt(pullf_files, dtype=str)\n\nworkestimator = storing.load('my_workestimator')\n\nprint(workestimator.names_)\nprint(pullf_filenames)\n</pre> import numpy as np from dcTMD import storing  pullf_files = '../../tests/testdata/pullf_filenames.dat' pullf_filenames = np.loadtxt(pullf_files, dtype=str)  workestimator = storing.load('my_workestimator')  print(workestimator.names_) print(pullf_filenames)  <pre>['t_middle_32_pullf.xvg' 't_middle_28_pullf.xvg' 't_middle_09_pullf.xvg'\n 't_middle_25_pullf.xvg' 't_middle_03_pullf.xvg' 't_middle_04_pullf.xvg'\n 't_middle_17_pullf.xvg' 't_middle_01_pullf.xvg' 't_middle_30_pullf.xvg'\n 't_middle_21_pullf.xvg' 't_middle_05_pullf.xvg' 't_middle_29_pullf.xvg'\n 't_middle_31_pullf.xvg' 't_middle_19_pullf.xvg' 't_middle_16_pullf.xvg'\n 't_middle_26_pullf.xvg' 't_middle_24_pullf.xvg' 't_middle_34_pullf.xvg']\n['testdata/t_middle_01_pullf.xvg' 'testdata/t_middle_03_pullf.xvg'\n 'testdata/t_middle_04_pullf.xvg' 'testdata/t_middle_05_pullf.xvg'\n 'testdata/t_middle_09_pullf.xvg' 'testdata/t_middle_16_pullf.xvg'\n 'testdata/t_middle_17_pullf.xvg' 'testdata/t_middle_19_pullf.xvg'\n 'testdata/t_middle_21_pullf.xvg' 'testdata/t_middle_24_pullf.xvg'\n 'testdata/t_middle_25_pullf.xvg' 'testdata/t_middle_26_pullf.xvg'\n 'testdata/t_middle_28_pullf.xvg' 'testdata/t_middle_29_pullf.xvg'\n 'testdata/t_middle_30_pullf.xvg' 'testdata/t_middle_31_pullf.xvg'\n 'testdata/t_middle_32_pullf.xvg' 'testdata/t_middle_34_pullf.xvg']\n</pre> <p>As you can see from the printed output, the order of the filenames differs between the <code>workestimator</code> and the <code>pullf_filenames.dat</code> file. For pathwise predictions, this order is crucial: each feature vector must correspond to the correct trajectory in the estimator. If the order in the feature set does not match the order stored in the estimator, the predictions will be misaligned and therefore incorrect.</p> <p>To ensure valid pathwise estimates, always verify that:</p> <ul> <li>the feature set,</li> <li>the work/force estimator, and</li> <li>the trajectory filenames</li> </ul> <p>all share the same order.</p> <p>If they do not match, you must reorder the feature set or reload the estimator with consistent input.</p> In\u00a0[2]: Copied! <pre>from dcTMD.featureset import FeatureSet\n\nwildcard = '../../tests/testdata/feature_1D_{}.txt'\npullf_filenames = workestimator.names_\nfeatureset = FeatureSet(\n    filenameprefix=pullf_filenames,\n    wildcard=wildcard,\n    verbose=False,\n)\nfeatureset.fill_array()\n\nfeature_array = featureset.array\n\nfeature_array.shape\n</pre>  from dcTMD.featureset import FeatureSet  wildcard = '../../tests/testdata/feature_1D_{}.txt' pullf_filenames = workestimator.names_ featureset = FeatureSet(     filenameprefix=pullf_filenames,     wildcard=wildcard,     verbose=False, ) featureset.fill_array()  feature_array = featureset.array  feature_array.shape <pre>Loading files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:00&lt;00:00, 5244.70it/s]\n</pre> Out[2]: <pre>(18, 100)</pre> <p>Creating a festureset with 1D data results in a 2D NumPy array with shape:</p> <pre><code>(num_trajectories, num_timepoints)\n</code></pre> <p>Note that the number of timepoints often differs from the number of steps in the corresponding <code>pullf</code> files. This is because the xtc trajectory files are typically saved at a lower temporal resolution than the <code>pullf</code> files, leading to fewer sampled timepoints in the feature data.</p> In\u00a0[3]: Copied! <pre>import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nn_tray, timesteps = feature_array.shape\nfor n in range(n_tray):\n    ax.plot(feature_array[n, :])\n\nax.set(xlabel=\"time step\", ylabel=\"feature value\")\nplt.show()\n</pre> import matplotlib.pyplot as plt  fig, ax = plt.subplots() n_tray, timesteps = feature_array.shape for n in range(n_tray):     ax.plot(feature_array[n, :])  ax.set(xlabel=\"time step\", ylabel=\"feature value\") plt.show()  <p>Next, we construct a 2D histogram that shows how frequently certain feature values occur at each time step across all trajectories. Zero entries are treated as <code>np.nan</code>.</p> In\u00a0[4]: Copied! <pre>feature_array_nan = np.where(feature_array == 0, np.nan, feature_array)\nhisto = np.histogram2d(\n    np.tile(np.linspace(1, 100, feature_array.shape[1]), feature_array.shape[0]),\n    feature_array_nan.flatten(),\n    bins=(100, 100),\n    range=[[1, 100], [np.min(feature_array), np.max(feature_array)]],\n)[0].T\nhisto_nan = np.where(histo == 0, np.nan, histo)\n\nfig, ax = plt.subplots()\nim = ax.imshow(\n    histo_nan,\n    aspect='auto',\n    origin='lower',\n    interpolation='nearest',\n    extent=(1, 100, np.min(feature_array), np.max(feature_array)),\n)\nfig.colorbar(im, ax=ax, label='counts')\nax.set(xlabel=\"time step\", ylabel=\"feature value\")\nplt.tight_layout()\nplt.show()\n</pre> feature_array_nan = np.where(feature_array == 0, np.nan, feature_array) histo = np.histogram2d(     np.tile(np.linspace(1, 100, feature_array.shape[1]), feature_array.shape[0]),     feature_array_nan.flatten(),     bins=(100, 100),     range=[[1, 100], [np.min(feature_array), np.max(feature_array)]], )[0].T histo_nan = np.where(histo == 0, np.nan, histo)  fig, ax = plt.subplots() im = ax.imshow(     histo_nan,     aspect='auto',     origin='lower',     interpolation='nearest',     extent=(1, 100, np.min(feature_array), np.max(feature_array)), ) fig.colorbar(im, ax=ax, label='counts') ax.set(xlabel=\"time step\", ylabel=\"feature value\") plt.tight_layout() plt.show()   In\u00a0[5]: Copied! <pre>wildcard = '../../tests/testdata/feature_2D_{}.txt'\npullf_filenames = workestimator.names_\nfeatureset = FeatureSet(\n    filenameprefix=pullf_filenames,\n    wildcard=wildcard,\n    verbose=False,\n)\nfeatureset.fill_array()\n\nfeature_array = featureset.array\n\nn_traj, n_timesteps, n_features = feature_array.shape\n</pre> wildcard = '../../tests/testdata/feature_2D_{}.txt' pullf_filenames = workestimator.names_ featureset = FeatureSet(     filenameprefix=pullf_filenames,     wildcard=wildcard,     verbose=False, ) featureset.fill_array()  feature_array = featureset.array  n_traj, n_timesteps, n_features = feature_array.shape <pre>Loading files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:00&lt;00:00, 1682.69it/s]\n</pre> In\u00a0[6]: Copied! <pre>fig, axs = plt.subplots(ncols=2, nrows=5)\nfig.supxlabel('time step')\nfig.supylabel('contact distance')\nax = axs.flatten()\nfor feature_ndx in range(n_features):\n    for n in range(n_traj):\n        ax[feature_ndx].plot(feature_array[n, :, feature_ndx])\n    ax[feature_ndx].set_title(f'Contact {feature_ndx}')\n\nplt.tight_layout()\nplt.show()\n</pre> fig, axs = plt.subplots(ncols=2, nrows=5) fig.supxlabel('time step') fig.supylabel('contact distance') ax = axs.flatten() for feature_ndx in range(n_features):     for n in range(n_traj):         ax[feature_ndx].plot(feature_array[n, :, feature_ndx])     ax[feature_ndx].set_title(f'Contact {feature_ndx}')  plt.tight_layout() plt.show()   In\u00a0[7]: Copied! <pre>fig, axs = plt.subplots(ncols=2, nrows=5, sharex=True, sharey=True)\nfig.supxlabel('time step')\nfig.supylabel('contact distance')\nax = axs.flatten()\nfeature_array_nan = np.where(feature_array == 0, np.nan, feature_array)\nn_contacts = feature_array.shape[-1]\n\nfor feature_ndx in range(n_contacts):\n    contact_feature_array = feature_array[:, :, feature_ndx]\n    histo = np.histogram2d(\n        np.tile(np.linspace(1, 100, contact_feature_array.shape[1]), contact_feature_array.shape[0]),\n        contact_feature_array.flatten(),\n        bins=(100, 100),\n        range=[\n            [1, 100],\n            [np.min(contact_feature_array), np.max(contact_feature_array)],\n        ],\n    )[0].T\n    histo_nan = np.where(histo == 0, np.nan, histo)\n    im = ax[feature_ndx].imshow(\n        histo_nan,\n        aspect='auto',\n        origin='lower',\n        interpolation='nearest',\n        extent=(1, 100, np.min(contact_feature_array), np.max(contact_feature_array)),\n    )\nfig.colorbar(im,  ax=axs, label='counts')\n#plt.tight_layout()\nplt.show()\n</pre> fig, axs = plt.subplots(ncols=2, nrows=5, sharex=True, sharey=True) fig.supxlabel('time step') fig.supylabel('contact distance') ax = axs.flatten() feature_array_nan = np.where(feature_array == 0, np.nan, feature_array) n_contacts = feature_array.shape[-1]  for feature_ndx in range(n_contacts):     contact_feature_array = feature_array[:, :, feature_ndx]     histo = np.histogram2d(         np.tile(np.linspace(1, 100, contact_feature_array.shape[1]), contact_feature_array.shape[0]),         contact_feature_array.flatten(),         bins=(100, 100),         range=[             [1, 100],             [np.min(contact_feature_array), np.max(contact_feature_array)],         ],     )[0].T     histo_nan = np.where(histo == 0, np.nan, histo)     im = ax[feature_ndx].imshow(         histo_nan,         aspect='auto',         origin='lower',         interpolation='nearest',         extent=(1, 100, np.min(contact_feature_array), np.max(contact_feature_array)),     ) fig.colorbar(im,  ax=axs, label='counts') #plt.tight_layout() plt.show() In\u00a0[8]: Copied! <pre>import tqdm\n\ndef _euclidean_dist(X, Y):\n    \"\"\"as implemented in\n    https://doi.org/10.1021/acs.jctc.4c00250\n    \"\"\"\n    trj_length = X.shape[1]\n    d = np.zeros(trj_length)\n    for t in range(trj_length):\n        d[t] = np.sqrt(np.sum((X[t] - Y[t])**2))\n    return np.mean(d)\n\ndef SimMatrix(feature_array, simmeasure):\n    \"\"\"\n    Compute the similarity matrix using a custom similarity measure.\n    Parameters\n    ----------\n    feature_array : ndarray\n        A 3D array of shape (n_trj, trj_length, n_contacts) containing the features of the trajectories.\n    simmeasure : callable\n        A function that computes the similarity between two trajectories. \n        It should take two arguments (X, Y) and return a scalar similarity value.\n    Returns\n    -------\n    matrix_ : ndarray\n        A 2D array of shape (n_trj, n_trj) representing the similarity matrix, \n        where each entry is the normalized similarity between two trajectories.\n    Examples\n    --------\n    &gt;&gt;&gt; import numpy as np\n    &gt;&gt;&gt; feature_array = np.random.rand(5, 100, 3)  # Example feature array\n    &gt;&gt;&gt; simmeasure = _euclidean_dist  # Example similarity measure\n    &gt;&gt;&gt; similarity_matrix = SimMatrix(feature_array, simmeasure)\n    &gt;&gt;&gt; print(similarity_matrix)\n    \"\"\"\n    n_trj, trj_length, n_features = feature_array.shape\n    total_iterations = int(\n            .5 * n_trj * (n_trj + 1)\n        )\n    dist = np.zeros(shape=(n_trj, n_trj))\n    with tqdm.tqdm(total=total_iterations) as pbar:\n        for i in range(n_trj):\n            for j in range(i+1):\n                X = feature_array[i]\n                Y = feature_array[j]\n                d = simmeasure(X, Y)\n                dist[i, j] = d\n                dist[j, i] = d\n                pbar.update(1)\n    dist = dist\n    max_dist = dist.max()\n    if max_dist == 0:\n        raise ValueError(\n            'Maximum distance is zero, cannot normalize similarity matrix.')\n    matrix_ = 1 - dist / max_dist\n    return matrix_\n</pre> import tqdm  def _euclidean_dist(X, Y):     \"\"\"as implemented in     https://doi.org/10.1021/acs.jctc.4c00250     \"\"\"     trj_length = X.shape[1]     d = np.zeros(trj_length)     for t in range(trj_length):         d[t] = np.sqrt(np.sum((X[t] - Y[t])**2))     return np.mean(d)  def SimMatrix(feature_array, simmeasure):     \"\"\"     Compute the similarity matrix using a custom similarity measure.     Parameters     ----------     feature_array : ndarray         A 3D array of shape (n_trj, trj_length, n_contacts) containing the features of the trajectories.     simmeasure : callable         A function that computes the similarity between two trajectories.          It should take two arguments (X, Y) and return a scalar similarity value.     Returns     -------     matrix_ : ndarray         A 2D array of shape (n_trj, n_trj) representing the similarity matrix,          where each entry is the normalized similarity between two trajectories.     Examples     --------     &gt;&gt;&gt; import numpy as np     &gt;&gt;&gt; feature_array = np.random.rand(5, 100, 3)  # Example feature array     &gt;&gt;&gt; simmeasure = _euclidean_dist  # Example similarity measure     &gt;&gt;&gt; similarity_matrix = SimMatrix(feature_array, simmeasure)     &gt;&gt;&gt; print(similarity_matrix)     \"\"\"     n_trj, trj_length, n_features = feature_array.shape     total_iterations = int(             .5 * n_trj * (n_trj + 1)         )     dist = np.zeros(shape=(n_trj, n_trj))     with tqdm.tqdm(total=total_iterations) as pbar:         for i in range(n_trj):             for j in range(i+1):                 X = feature_array[i]                 Y = feature_array[j]                 d = simmeasure(X, Y)                 dist[i, j] = d                 dist[j, i] = d                 pbar.update(1)     dist = dist     max_dist = dist.max()     if max_dist == 0:         raise ValueError(             'Maximum distance is zero, cannot normalize similarity matrix.')     matrix_ = 1 - dist / max_dist     return matrix_ In\u00a0[9]: Copied! <pre>similarity_matrix = SimMatrix(feature_array, _euclidean_dist)\n</pre> similarity_matrix = SimMatrix(feature_array, _euclidean_dist) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 171/171 [00:00&lt;00:00, 9674.07it/s]\n</pre> In\u00a0[10]: Copied! <pre>fig, ax = plt.subplots()\nim = ax.pcolormesh(similarity_matrix)\nax.invert_yaxis()  # origin to the upper left\nax.set_aspect('equal')  # 1:1 ratio\nax.set_xlabel('traj')\nax.set_ylabel('traj')\nax.grid(False)\nplt.colorbar(im, label=r'$s$')\nplt.show()\n</pre> fig, ax = plt.subplots() im = ax.pcolormesh(similarity_matrix) ax.invert_yaxis()  # origin to the upper left ax.set_aspect('equal')  # 1:1 ratio ax.set_xlabel('traj') ax.set_ylabel('traj') ax.grid(False) plt.colorbar(im, label=r'$s$') plt.show() In\u00a0[11]: Copied! <pre>plt.hist(similarity_matrix.flatten(), bins=50)\nplt.xlabel('similarity s')\nplt.ylabel('counts')\nplt.show()\n</pre> plt.hist(similarity_matrix.flatten(), bins=50) plt.xlabel('similarity s') plt.ylabel('counts') plt.show() In\u00a0[12]: Copied! <pre>import mosaic\n\n# Cluster the similarity matrix\nclustering = mosaic.Clustering(\n    mode='CPM',\n    weighted=True,\n    resolution_parameter=0.5,\n)\nclustering.fit(similarity_matrix)\n\nfig, ax = plt.subplots()\nim = ax.pcolormesh(clustering.matrix_)\nax.invert_yaxis()  # origin to the upper left\nax.set_aspect('equal')  # 1:1 ratio\nax.set_xticks(clustering.ticks_)\nax.set_yticks(clustering.ticks_)\nax.set_xticklabels([])\nax.set_yticklabels([])\nax.set_xlabel('clusters')\nax.set_ylabel('clusters')\nax.grid(False)\nplt.colorbar(im, label=r'$s$')\nplt.show()\n</pre> import mosaic  # Cluster the similarity matrix clustering = mosaic.Clustering(     mode='CPM',     weighted=True,     resolution_parameter=0.5, ) clustering.fit(similarity_matrix)  fig, ax = plt.subplots() im = ax.pcolormesh(clustering.matrix_) ax.invert_yaxis()  # origin to the upper left ax.set_aspect('equal')  # 1:1 ratio ax.set_xticks(clustering.ticks_) ax.set_yticks(clustering.ticks_) ax.set_xticklabels([]) ax.set_yticklabels([]) ax.set_xlabel('clusters') ax.set_ylabel('clusters') ax.grid(False) plt.colorbar(im, label=r'$s$') plt.show()  In\u00a0[13]: Copied! <pre># plot dcTMD results\nfrom dcTMD.utils import plotting\nfrom dcTMD.dcTMD import WorkEstimator\n\n# use work.ipynb to save 'my_workset' in cell 5, comment in\n# \"dcTMD.storing.save('my_workset', workset)\"\nworkset = storing.load('my_workset')\ntemperature = 300\nfor i, cluster_list in enumerate(clustering.clusters_):\n    print(cluster_list)\n    # create WorkEstimator instance\n    workestimator = WorkEstimator(temperature)\n    # convert cluster list to numpy array\n    cluster_list = np.asarray(cluster_list)\n    current_workset = workset.reduce(cluster_list)\n    workestimator.fit(current_workset)\n    workestimator.smooth_friction(sigma=0.1)\n\n    fig, axs = plotting.plot_dcTMD_results(workestimator)\n    fig.suptitle(f'Cluster {i+1}')\n    plt.tight_layout()\n    plt.show()\n</pre> # plot dcTMD results from dcTMD.utils import plotting from dcTMD.dcTMD import WorkEstimator  # use work.ipynb to save 'my_workset' in cell 5, comment in # \"dcTMD.storing.save('my_workset', workset)\" workset = storing.load('my_workset') temperature = 300 for i, cluster_list in enumerate(clustering.clusters_):     print(cluster_list)     # create WorkEstimator instance     workestimator = WorkEstimator(temperature)     # convert cluster list to numpy array     cluster_list = np.asarray(cluster_list)     current_workset = workset.reduce(cluster_list)     workestimator.fit(current_workset)     workestimator.smooth_friction(sigma=0.1)      fig, axs = plotting.plot_dcTMD_results(workestimator)     fig.suptitle(f'Cluster {i+1}')     plt.tight_layout()     plt.show()  <pre>[14, 15, 16, 13, 2, 5, 3, 4, 6, 1, 7, 9, 10]\n</pre> <pre>[12, 17, 11, 0, 8]\n</pre>"},{"location":"tutorials/create_featureset/#how-to-create-a-featureset-for-path-separation","title":"How to create a FeatureSet for path separation\u00b6","text":""},{"location":"tutorials/create_featureset/#1-create-a-featureset-in-the-order-of-the-pullf-files","title":"1. Create a FeatureSet in the order of the <code>pullf</code> Files\u00b6","text":"<p>When working with pathwise estimates, the order of the trajectories is critical. If you already initialized a <code>ForceSet</code>, <code>WorkSet</code>, <code>WorkEstimator</code>, or <code>ForceEstimator</code>, we strongly recommend using the <code>names_</code> instance together with the wildcard option. This ensures that the file order used for the feature set matches the order used during initialization.</p> <p>The following cell shows the filename order of a <code>workset</code> initialized with:</p> <pre>pullf_files = '../../tests/testdata/*pullf.xvg'\nfilenames = dcTMD.io.load_pullf(pullf_files)\n</pre> <p>This uses a shell-style wildcard (<code>*pullf.xvg</code>) to glob all matching files.</p> <p>Below, we compare the resulting order with the order stored in the <code>pullf_filenames.dat</code> file.</p>"},{"location":"tutorials/create_featureset/#illustrating-the-concept-with-dummy-data","title":"Illustrating the Concept with Dummy Data\u00b6","text":"<p>We now demonstrate it using simple 1D and 2D dummy data. In practice, such data could represent any trajectory-dependent quantity\u2014for example, the distance between two residues over time.</p> <p>By using the trajectory names stored in the <code>workestimator</code>, we ensure that the features are loaded in a consistent and matching order.</p>"},{"location":"tutorials/create_featureset/#visualizing-the-feature-data-line-plots-and-a-2d-histogram","title":"Visualizing the feature data: Line Plots and a 2D Histogram\u00b6","text":"<p>To better understand the structure of the feature data, we first visualize the trajectories as simple line plots. Each line corresponds to one trajectory and shows how the feature value evolves over time.</p>"},{"location":"tutorials/create_featureset/#multidimensional-data","title":"Multidimensional Data\u00b6","text":"<p>The same procedure applies when working with multidimensional features. In the next example, the data set does not represent just the distance between two residues, but the distances between ten different residue pairs.</p> <p>This results in a feature array with an additional dimension, where each time point contains a vector of measurements instead of a single value. The workflow remains identical\u2014only the data structure becomes richer, allowing you to analyze patterns across multiple residue pairs simultaneously.</p>"},{"location":"tutorials/create_featureset/#visualizing-multidimensional-feature-data","title":"Visualizing Multidimensional Feature Data\u00b6","text":"<p>When the feature data is multidimensional, each trajectory contains multiple measurements at every time point\u2014for example, the distances between ten different residue pairs. This produces a 3D array with shape:</p> <pre><code>(n_traj, n_timesteps, n_features)\n</code></pre> <p>where <code>n_features = 10</code> in this example.</p> <p>To explore this data, we can visualize:</p> <ol> <li>All features for a single trajectory, or</li> <li>A single feature across all trajectories, or</li> <li>A histogram for each feature to capture its distribution over time.</li> </ol> <p>Below, we show two useful visualizations: a line plot per feature, and a stacked 2D histogram grid.</p>"},{"location":"tutorials/create_featureset/#computing-euclidean-distances-between-trajectories","title":"Computing Euclidean Distances Between Trajectories\u00b6","text":"<p>In the multidimensional case, each trajectory is described by $N$ feature values at every time point. We can interpret each time point as a ND vector:</p> <p>$$ \\mathbf{x}(t) = (x_1(t), x_2(t), ..., x_N(t) $$</p> <p>To compare two trajectories, a simple and intuitive approach is to compute the Euclidean distance between their time-dependent feature vectors.</p> <p>For two trajectories (A) and (B), the Euclidean distance at each time step is:</p> <p>$$ d(t) = \\lVert \\mathbf{x}_A(t) - \\mathbf{x}_B(t) \\rVert_2 $$</p> <p>The result is a 1D array describing how similar or different the two trajectories are over time. We can then summarize the overall distance between the two trajectories by computing the average distance over all time steps:</p> <p>$$ d_{AB} = \\frac{1}{T} \\sum_{t=1}^{T} d(t) $$</p>"},{"location":"tutorials/create_featureset/#creating-a-similarity-matrix","title":"Creating a Similarity Matrix\u00b6","text":"<p>To quantitatively compare trajectories, we compute a similarity matrix based on a distance measure between pairs of trajectories. Each entry $(i, j)$ represents how similar trajectory $i$ is to trajectory $j$, computed using a user-defined metric (here, the mean Euclidean distance between their feature vectors over time).</p> <p>After computing all pairwise distances, we normalize them into a similarity score in the range $[0, 1]$, where:</p> <ul> <li>$1$ \u2192 trajectories are identical</li> <li>$0$ \u2192 trajectories are maximally different</li> </ul>"},{"location":"tutorials/create_featureset/#plotting","title":"Plotting\u00b6","text":"<p>The two following plots show that by design the dataset contains:</p> <ul> <li>highly similar clusters (similarity values close to $1$), and</li> <li>strongly dissimilar clusters (similarity values closer to $0$).</li> </ul>"},{"location":"tutorials/create_featureset/#similarity-matrix","title":"Similarity Matrix\u00b6","text":"<p>Once the similarity matrix has been computed, we can visualize it as a heatmap and use it for clustering.</p>"},{"location":"tutorials/create_featureset/#similarity-distribution","title":"Similarity Distribution\u00b6","text":"<p>By also plotting the distribution of similarity values, we gain a global view of how the trajectories relate to one another.</p>"},{"location":"tutorials/create_featureset/#clustering-the-similarity-matrix-using-mosaic-cpm-leiden","title":"Clustering the Similarity Matrix Using MoSAIC (CPM + Leiden)\u00b6","text":"<p>To reveal structural patterns within the similarity matrix, we use the MoSAIC Python package. You can find it here.</p> <p>In this tutorial, we apply CPM clustering (Constant Potts Model), a community-detection method that identifies groups of trajectories based on their pairwise similarities. MoSAIC optimizes CPM using the Leiden algorithm.</p>"},{"location":"tutorials/create_featureset/#computing-dctmd-estimates-for-each-cluster","title":"Computing dcTMD Estimates for Each Cluster\u00b6","text":"<p>Once the trajectories have been clustered (e.g. using MoSAIC with CPM + Leiden), we can compute separate dcTMD estimates for each cluster. This allows us to compare trajectory groups\u2014such as different unbinding pathways.</p> <p>For each cluster, we:</p> <ol> <li>Extract the trajectory indices belonging to that cluster.</li> <li>Reduce the original <code>workset</code> to include only those trajectories.</li> <li>Fit a new <code>WorkEstimator</code> using the reduced dataset.</li> <li>Optionally smooth the friction profile for better interpretability.</li> <li>Plot the dcTMD results (work, friction, free energy, etc.) for that cluster.</li> </ol> <p>The following code performs exactly this procedure:</p> <p>Each plot corresponds to one cluster and visualizes its cluster-specific dcTMD profile.</p>"},{"location":"tutorials/force/","title":"dcTMD via Force","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nfrom dcTMD.dcTMD import ForceEstimator\nfrom dcTMD.storing import ForceSet, load\nimport dcTMD\n</pre> import numpy as np from dcTMD.dcTMD import ForceEstimator from dcTMD.storing import ForceSet, load import dcTMD In\u00a0[2]: Copied! <pre># define variables\nvelocity = 0.001\nres = 1\nverbose = True\ntemperature = 300\n</pre> # define variables velocity = 0.001 res = 1 verbose = True temperature = 300 In\u00a0[3]: Copied! <pre>pullf_files = '../../tests/testdata/pullf_filenames.dat'\npullf_files = '../../tests/testdata/*pullf.xvg'\nfilenames = dcTMD.io.load_pullf(pullf_files)\n\nfilenames\n</pre> pullf_files = '../../tests/testdata/pullf_filenames.dat' pullf_files = '../../tests/testdata/*pullf.xvg' filenames = dcTMD.io.load_pullf(pullf_files)  filenames  <pre>file ../../tests/testdata/*pullf.xvg not found. using glob.glob(../../tests/testdata/*pullf.xvg)\n</pre> Out[3]: <pre>['../../tests/testdata/t_middle_32_pullf.xvg',\n '../../tests/testdata/t_middle_28_pullf.xvg',\n '../../tests/testdata/t_middle_09_pullf.xvg',\n '../../tests/testdata/t_middle_25_pullf.xvg',\n '../../tests/testdata/t_middle_03_pullf.xvg',\n '../../tests/testdata/t_middle_04_pullf.xvg',\n '../../tests/testdata/t_middle_17_pullf.xvg',\n '../../tests/testdata/t_middle_01_pullf.xvg',\n '../../tests/testdata/t_middle_30_pullf.xvg',\n '../../tests/testdata/t_middle_21_pullf.xvg',\n '../../tests/testdata/t_middle_05_pullf.xvg',\n '../../tests/testdata/t_middle_29_pullf.xvg',\n '../../tests/testdata/t_middle_31_pullf.xvg',\n '../../tests/testdata/t_middle_19_pullf.xvg',\n '../../tests/testdata/t_middle_16_pullf.xvg',\n '../../tests/testdata/t_middle_26_pullf.xvg',\n '../../tests/testdata/t_middle_24_pullf.xvg',\n '../../tests/testdata/t_middle_34_pullf.xvg']</pre> <ol> <li>the force set is created by creating a <code>ForceSet</code> instance which is fitted with the filenames.</li> </ol> In\u00a0[4]: Copied! <pre># create ForceSet instance\nforceset = ForceSet(velocity=velocity,\n                  resolution=res,\n                  verbose=verbose,\n                  )\nforceset\n</pre> # create ForceSet instance forceset = ForceSet(velocity=velocity,                   resolution=res,                   verbose=verbose,                   ) forceset  Out[4]: <pre>ForceSet(velocity=0.001, verbose=True)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ForceSetiNot fitted Parameters velocity\u00a0 0.001 resolution\u00a0 1 verbose\u00a0 True In\u00a0[5]: Copied! <pre># fit/fill workset\nforceset.fit(filenames)\n# save workset\n#dcTMD.storing.save('my_forceset', forceset)\n</pre> # fit/fill workset forceset.fit(filenames) # save workset #dcTMD.storing.save('my_forceset', forceset)   <pre>Using ../../tests/testdata/t_middle_32_pullf.xvg to initialize arrays.\nlength of pullf file is 20001\nreduced length is 20001\n</pre> <pre>Loading force files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:00&lt;00:00, 149.65it/s]</pre> <pre>Reading file ../../tests/testdata/t_middle_32_pullf.xvg\nReading file ../../tests/testdata/t_middle_28_pullf.xvg\nReading file ../../tests/testdata/t_middle_09_pullf.xvg\nReading file ../../tests/testdata/t_middle_25_pullf.xvg\nReading file ../../tests/testdata/t_middle_03_pullf.xvg\nReading file ../../tests/testdata/t_middle_04_pullf.xvg\nReading file ../../tests/testdata/t_middle_17_pullf.xvg\nReading file ../../tests/testdata/t_middle_01_pullf.xvg\nReading file ../../tests/testdata/t_middle_30_pullf.xvg\nReading file ../../tests/testdata/t_middle_21_pullf.xvg\nReading file ../../tests/testdata/t_middle_05_pullf.xvg\nReading file ../../tests/testdata/t_middle_29_pullf.xvg\nReading file ../../tests/testdata/t_middle_31_pullf.xvg\nReading file ../../tests/testdata/t_middle_19_pullf.xvg\nReading file ../../tests/testdata/t_middle_16_pullf.xvg\nReading file ../../tests/testdata/t_middle_26_pullf.xvg\nReading file ../../tests/testdata/t_middle_24_pullf.xvg\nReading file ../../tests/testdata/t_middle_34_pullf.xvg\n</pre> <pre>\n</pre> Out[5]: <pre>ForceSet(velocity=0.001, verbose=True)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ForceSetiFitted Parameters velocity\u00a0 0.001 resolution\u00a0 1 verbose\u00a0 True In\u00a0[6]: Copied! <pre># plot workset\nimport matplotlib.pyplot as plt\nfrom dcTMD.utils import plotting\n\nfig, ax = plt.subplots()\nplotting.plot_worklines(forceset, ax)\nplt.show()\n</pre> # plot workset import matplotlib.pyplot as plt from dcTMD.utils import plotting  fig, ax = plt.subplots() plotting.plot_worklines(forceset, ax) plt.show() In\u00a0[7]: Copied! <pre>from scipy.stats import probplot\n\ndef plot_worknormalitychecks(\n    workset,\n    index,\n    x=None,\n    worklinecolor='#777',\n    colors=None,\n    figsize=(6, 2),\n    axs=None,\n    res=10,\n):\n    \"\"\"Plots the work values of trajectories individually.\n\n    This function generates a plot with three subplots:\n    1. Line plots of the work values for all trajectories.\n    2. Work value histograms for the indices given `index`.\n    3. As well as normality plot (Q-Q plot) for the work values the indices given `index`..\n\n    Args:\n        workset: workset object\n        index (list of int): Indices of the positions. These indices\n            are used to extract specific columns from `workset.work_` for\n            histogram and normality plots.\n        x (array-like, optional): The x-axis positions for the work values. If\n            not provided, `workset.position_` is used.\n        worklinecolor (str, optional): Color of the work line plot. Default is\n            '#777'.\n        colors (list of str, optional):\n            Colors for the histogram and normality\n            plots. If not provided, the `Dark2` colormap is used.\n        figsize (tuple, optional):\n            Size of the figure. Default is (6, 2).\n        axs (list of matplotlib.axes.Axes, optional):\n            Axes for the subplots. If\n            not provided, new axes are created.\n        res (int, optional): Resolution for the work line plot. Default is 10.\n\n    Returns:\n        list of matplotlib.axes.Axes: The axes containing the subplots.\n\n    Example:\n        &gt;&gt;&gt; plot_worknormalitychecks(\n        ...     workset=my_workset,\n        ...     index=[0, 5, 10],\n        ... )\n        &gt;&gt;&gt; plt.show()\n\n    \"\"\"\n    if axs is None:\n        print('No axs given. Create figure.')\n        fig, axs = plt.subplots(\n            ncols=3,\n            nrows=1,\n            figsize=figsize,\n        )\n    if x is None:\n        x = workset.position_\n    plotting.plot_worklines(workset, axs[0], x=x, res=res, color=worklinecolor)\n\n    if not colors:\n        cmap = plt.get_cmap('Dark2')\n        colors = cmap.colors\n\n    for j, idx in enumerate(index):\n        work = workset.work_[:, idx].ravel()\n        axs[1].set_title(r'Histogram at $x$')\n        plotting.plot_histo_normaldist(work, axs[1], colors[j])\n        axs[0].axvline(\n            x[idx],\n            color=colors[j],\n            zorder=3,\n            label=rf'$x={x[idx]:.2f}$',\n        )\n\n        probplot(work, plot=axs[2], fit=True)\n        axs[2].get_lines()[j * 2].set_color(colors[j])  # noqa: WPS221\n        axs[2].set_title('Normality plot')\n\n    axs[0].legend()\n    return axs\n</pre> from scipy.stats import probplot  def plot_worknormalitychecks(     workset,     index,     x=None,     worklinecolor='#777',     colors=None,     figsize=(6, 2),     axs=None,     res=10, ):     \"\"\"Plots the work values of trajectories individually.      This function generates a plot with three subplots:     1. Line plots of the work values for all trajectories.     2. Work value histograms for the indices given `index`.     3. As well as normality plot (Q-Q plot) for the work values the indices given `index`..      Args:         workset: workset object         index (list of int): Indices of the positions. These indices             are used to extract specific columns from `workset.work_` for             histogram and normality plots.         x (array-like, optional): The x-axis positions for the work values. If             not provided, `workset.position_` is used.         worklinecolor (str, optional): Color of the work line plot. Default is             '#777'.         colors (list of str, optional):             Colors for the histogram and normality             plots. If not provided, the `Dark2` colormap is used.         figsize (tuple, optional):             Size of the figure. Default is (6, 2).         axs (list of matplotlib.axes.Axes, optional):             Axes for the subplots. If             not provided, new axes are created.         res (int, optional): Resolution for the work line plot. Default is 10.      Returns:         list of matplotlib.axes.Axes: The axes containing the subplots.      Example:         &gt;&gt;&gt; plot_worknormalitychecks(         ...     workset=my_workset,         ...     index=[0, 5, 10],         ... )         &gt;&gt;&gt; plt.show()      \"\"\"     if axs is None:         print('No axs given. Create figure.')         fig, axs = plt.subplots(             ncols=3,             nrows=1,             figsize=figsize,         )     if x is None:         x = workset.position_     plotting.plot_worklines(workset, axs[0], x=x, res=res, color=worklinecolor)      if not colors:         cmap = plt.get_cmap('Dark2')         colors = cmap.colors      for j, idx in enumerate(index):         work = workset.work_[:, idx].ravel()         axs[1].set_title(r'Histogram at $x$')         plotting.plot_histo_normaldist(work, axs[1], colors[j])         axs[0].axvline(             x[idx],             color=colors[j],             zorder=3,             label=rf'$x={x[idx]:.2f}$',         )          probplot(work, plot=axs[2], fit=True)         axs[2].get_lines()[j * 2].set_color(colors[j])  # noqa: WPS221         axs[2].set_title('Normality plot')      axs[0].legend()     return axs In\u00a0[8]: Copied! <pre># check if work distribution follows a normal distribution\nfrom scipy.stats import kstest, shapiro, anderson\nfrom dcTMD.utils import plotting\n\nindex = [5000, 15000]\nx = forceset.position_\n\naxs = plot_worknormalitychecks(forceset, index)\n\nfor i, p in enumerate(index):\n    # Shapiro-Wilk Test\n    shapiro_test = shapiro(forceset.work_[:,p])\n    print(f'shapiro wilkins results at x={x[p]} is {shapiro_test}')\n    # Anderson-Darling Test\n    # If the test statistic is larger than the critical value of a given\n    # significance_level in percent, the null hypothesis that the work\n    # is normally distributed has to be rejected.\n    anderson_test = anderson(forceset.work_[:,p], 'norm')\n    print(f'anderson darling results at x={x[p]} is {anderson_test}.')\n    # Kolmogorov-Smirnov Test (requires centering and scaling of input data)\n    kstest_test = kstest(\n        (forceset.work_[:,p]-np.mean(forceset.work_[:,p]))/np.std(forceset.work_[:,p]),\n        'norm'\n    )\n    print(f'Kolmogorov-Smirnov results at x={x[p]} is {kstest_test}')\n</pre> # check if work distribution follows a normal distribution from scipy.stats import kstest, shapiro, anderson from dcTMD.utils import plotting  index = [5000, 15000] x = forceset.position_  axs = plot_worknormalitychecks(forceset, index)  for i, p in enumerate(index):     # Shapiro-Wilk Test     shapiro_test = shapiro(forceset.work_[:,p])     print(f'shapiro wilkins results at x={x[p]} is {shapiro_test}')     # Anderson-Darling Test     # If the test statistic is larger than the critical value of a given     # significance_level in percent, the null hypothesis that the work     # is normally distributed has to be rejected.     anderson_test = anderson(forceset.work_[:,p], 'norm')     print(f'anderson darling results at x={x[p]} is {anderson_test}.')     # Kolmogorov-Smirnov Test (requires centering and scaling of input data)     kstest_test = kstest(         (forceset.work_[:,p]-np.mean(forceset.work_[:,p]))/np.std(forceset.work_[:,p]),         'norm'     )     print(f'Kolmogorov-Smirnov results at x={x[p]} is {kstest_test}') <pre>No axs given. Create figure.\nshapiro wilkins results at x=0.5 is ShapiroResult(statistic=np.float64(0.9809889406089324), pvalue=np.float64(0.95963623434336))\nanderson darling results at x=0.5 is AndersonResult(statistic=np.float64(0.1889729620402001), critical_values=array([0.503, 0.573, 0.687, 0.802, 0.954]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]), fit_result=  params: FitParams(loc=np.float64(67.28161594817962), scale=np.float64(12.135336573012399))\n success: True\n message: '`anderson` successfully fit the distribution to the data.').\nKolmogorov-Smirnov results at x=0.5 is KstestResult(statistic=np.float64(0.12229979875552988), pvalue=np.float64(0.9209557348362518), statistic_location=np.float64(-1.013218181258686), statistic_sign=np.int8(1))\nshapiro wilkins results at x=1.5 is ShapiroResult(statistic=np.float64(0.9350144421408519), pvalue=np.float64(0.23768137296093406))\nanderson darling results at x=1.5 is AndersonResult(statistic=np.float64(0.38109849215264546), critical_values=array([0.503, 0.573, 0.687, 0.802, 0.954]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]), fit_result=  params: FitParams(loc=np.float64(92.54892049414025), scale=np.float64(19.147779388352493))\n success: True\n message: '`anderson` successfully fit the distribution to the data.').\nKolmogorov-Smirnov results at x=1.5 is KstestResult(statistic=np.float64(0.14917443864214242), pvalue=np.float64(0.7646028245726427), statistic_location=np.float64(0.5380536480357736), statistic_sign=np.int8(-1))\n</pre> In\u00a0[9]: Copied! <pre>## load force\n# force = load('my_force_set')\n# Instantiate a ForceEstimator instance and fit it with the ForceSet\n# instance\nforceestimator = ForceEstimator(temperature)\nforceestimator.fit(forceset)\nvars(forceestimator)\n</pre> ## load force # force = load('my_force_set') # Instantiate a ForceEstimator instance and fit it with the ForceSet # instance forceestimator = ForceEstimator(temperature) forceestimator.fit(forceset) vars(forceestimator) Out[9]: <pre>{'temperature': 300,\n 'verbose': False,\n 'force_set': ForceSet(velocity=0.001, verbose=True),\n 'names_': array(['t_middle_32_pullf.xvg', 't_middle_28_pullf.xvg',\n        't_middle_09_pullf.xvg', 't_middle_25_pullf.xvg',\n        't_middle_03_pullf.xvg', 't_middle_04_pullf.xvg',\n        't_middle_17_pullf.xvg', 't_middle_01_pullf.xvg',\n        't_middle_30_pullf.xvg', 't_middle_21_pullf.xvg',\n        't_middle_05_pullf.xvg', 't_middle_29_pullf.xvg',\n        't_middle_31_pullf.xvg', 't_middle_19_pullf.xvg',\n        't_middle_16_pullf.xvg', 't_middle_26_pullf.xvg',\n        't_middle_24_pullf.xvg', 't_middle_34_pullf.xvg'], dtype='&lt;U32'),\n 'delta_force_array': array([[ -873.73688333,  2064.04026667, -1646.75083333, ...,\n          -384.51461111,  -660.01724444,  1038.23811111],\n        [ 2551.34481667,  -738.89973333,   437.76516667, ...,\n          1906.91438889,  1521.64075556,    71.79311111],\n        [   19.00181667,  1142.11026667,  2706.29916667, ...,\n          1092.73438889, -1149.08724444,   308.22211111],\n        ...,\n        [ 2488.41481667, -2751.03973333,  -922.63583333, ...,\n          1105.01438889,  1294.69275556,  1361.89911111],\n        [ -181.92018333, -1352.27973333,  1215.67916667, ...,\n          -233.74361111,  2845.73275556, -1574.22088889],\n        [ -250.70318333,   628.82026667,  -742.81483333, ...,\n          1878.19438889,   696.55775556, -1876.26088889]],\n       shape=(18, 20001)),\n 'position_': array([0.0000e+00, 1.0000e-04, 2.0000e-04, ..., 1.9998e+00, 1.9999e+00,\n        2.0000e+00], shape=(20001,)),\n 'W_mean_': array([0.00000000e+00, 4.41837458e-02, 4.44572742e-02, ...,\n        9.33136501e+01, 9.32887153e+01, 9.32516402e+01], shape=(20001,)),\n 'W_diss_': array([0.00000000e+00, 1.31284676e-03, 5.44972880e-03, ...,\n        1.03329455e+02, 1.03220321e+02, 1.03098458e+02], shape=(20001,)),\n 'dG_': array([  0.        ,   0.0428709 ,   0.03900755, ..., -10.01580464,\n         -9.93160537,  -9.84681799], shape=(20001,)),\n 'friction_': array([       0.        ,    26256.93524311,    56480.70560018, ...,\n         1453172.40054124, -3635855.06732884,  1198605.76617033],\n       shape=(20001,))}</pre> In\u00a0[10]: Copied! <pre># plot dcTMD results\nfrom dcTMD.utils import plotting\n\nfig, axs = plotting.plot_dcTMD_results(forceestimator)\n\nplt.show()\n</pre> # plot dcTMD results from dcTMD.utils import plotting  fig, axs = plotting.plot_dcTMD_results(forceestimator)  plt.show() In\u00a0[11]: Copied! <pre># smooth friction and plot results\nforceestimator.smooth_friction(sigma=0.1)\n\n# if the friction is smoothed that value is automatically plotted\nfig, axs = plotting.plot_dcTMD_results(forceestimator)\nplt.show()\n\n# but one can also specify the friction\n#fig, axs = plotting.plot_dcTMD_results(\n#    forceestimator,\n#    friction=forceestimator.friction_\n#)\n</pre> # smooth friction and plot results forceestimator.smooth_friction(sigma=0.1)  # if the friction is smoothed that value is automatically plotted fig, axs = plotting.plot_dcTMD_results(forceestimator) plt.show()  # but one can also specify the friction #fig, axs = plotting.plot_dcTMD_results( #    forceestimator, #    friction=forceestimator.friction_ #)   <p>Using different smoothing windows and modes changes the results significantly. Because of the different boundary handling in the modes, <code>mode='nearest'</code> leads to an overestimation at the right hand border (end of the simulation), while <code>mode='reflect'</code> leads to a washing out of the boarder on the left hand side.</p> <p>Here are some examples:</p> In\u00a0[12]: Copied! <pre>fig, axs = plt.subplots()\n\nx = forceestimator.position_\nplotting.plot_Gamma(\n    x,\n    forceestimator.friction_smooth_,\n    axs,\n    label='default (reflect) 0.1nm'\n)\n\n# using different smoothing windows and modes changes the results significantly\nsmooth_friction = dcTMD.utils.gaussfilter_friction(\n    forceestimator.friction_,\n    x,\n    sigma=.01,\n    mode='reflect',\n)\naxs.plot(x, smooth_friction, label='reflect .01nm')\nsmooth_friction = dcTMD.utils.gaussfilter_friction(\n    forceestimator.friction_,\n    x,\n    sigma=.01,\n    mode='nearest',\n)\naxs.plot(x, smooth_friction, label='nearest .01nm')\nsmooth_friction = dcTMD.utils.gaussfilter_friction(\n    forceestimator.friction_,\n    x,\n    sigma=0.2,\n    mode='reflect',\n)\n\naxs.plot(x, smooth_friction, label='reflect .2nm')\naxs.legend()\n\nplt.show()\n</pre> fig, axs = plt.subplots()  x = forceestimator.position_ plotting.plot_Gamma(     x,     forceestimator.friction_smooth_,     axs,     label='default (reflect) 0.1nm' )  # using different smoothing windows and modes changes the results significantly smooth_friction = dcTMD.utils.gaussfilter_friction(     forceestimator.friction_,     x,     sigma=.01,     mode='reflect', ) axs.plot(x, smooth_friction, label='reflect .01nm') smooth_friction = dcTMD.utils.gaussfilter_friction(     forceestimator.friction_,     x,     sigma=.01,     mode='nearest', ) axs.plot(x, smooth_friction, label='nearest .01nm') smooth_friction = dcTMD.utils.gaussfilter_friction(     forceestimator.friction_,     x,     sigma=0.2,     mode='reflect', )  axs.plot(x, smooth_friction, label='reflect .2nm') axs.legend()  plt.show() In\u00a0[13]: Copied! <pre># save forceestimator instance\n# dcTMD.storing.save('my_forceestimator', forceestimator)\n\n# save data as .npz and .dat file\noutname = 'my_forceestimator_results'\ndcTMD.io.write_output(outname, forceestimator)\n\nresults = np.load(f'{outname}_N{len(forceestimator.names_)}.npz')\n\nresults.files\n</pre> # save forceestimator instance # dcTMD.storing.save('my_forceestimator', forceestimator)  # save data as .npz and .dat file outname = 'my_forceestimator_results' dcTMD.io.write_output(outname, forceestimator)  results = np.load(f'{outname}_N{len(forceestimator.names_)}.npz')  results.files <pre>save file my_forceestimator_results_N18.dat\nsave file my_forceestimator_results_N18.npz\n</pre> Out[13]: <pre>['x', 'Wmean', 'Wdiss', 'dG', 'Gamma', 'Gamma_smooth']</pre> In\u00a0[14]: Copied! <pre># load results\nresults = dcTMD.io.load_output(f'{outname}_N{len(forceestimator.names_)}.npz')\n#results = dcTMD.io.load_output(f'{outname}_N{len(workestimator.names_)}.dat')\n\nprint(results.keys())\n\n# results is a dictionary-like object\n# access e.g. the free energy estimate\n\nresults['dG']\n</pre> # load results results = dcTMD.io.load_output(f'{outname}_N{len(forceestimator.names_)}.npz') #results = dcTMD.io.load_output(f'{outname}_N{len(workestimator.names_)}.dat')  print(results.keys())  # results is a dictionary-like object # access e.g. the free energy estimate  results['dG'] <pre>Loaded data from my_forceestimator_results_N18.npz\ndict_keys(['x', 'Wmean', 'Wdiss', 'dG', 'Gamma', 'Gamma_smooth'])\n</pre> Out[14]: <pre>array([  0.        ,   0.0428709 ,   0.03900755, ..., -10.01580464,\n        -9.93160537,  -9.84681799], shape=(20001,))</pre>"},{"location":"tutorials/force/#introduction","title":"Introduction\u00b6","text":"<p>Another option to directly analyze the constraint force time traces is to calculate $\\Delta G$ on-the-fly starting from the friction estimate ${\\it{\\Gamma}}$ which is calculated from the force $f_c(t)$ autocorrelation function via:</p> <p>$$ \\begin{align} \\Gamma &amp;= \\beta \\int_{0}^{t} \\text{d}\\tau \\left&lt;\\delta f_c(t)\\delta f_c(t-\\tau)\\right&gt;_\\text{N},\\\\ \\Delta G(x) &amp;= - v_c\\int_{x_0}^{x} \\text{d}x' \\Gamma(x') + \\int_{x_0}^{x} \\text{d}x' \\left&lt;f_c(x')\\right&gt;_\\text{N} \\end{align} $$</p> <p>This approach is computationally more demanding, since the full resolution of the force time traces is needed to determine friction and free energy estimates. Therefore, we recommend the use of the <code>WorkEstimator</code> class, which is computationally less demanding, since it does not require the full resolution of the force time traces.</p>"},{"location":"tutorials/force/#workflow","title":"Workflow:\u00b6","text":""},{"location":"tutorials/force/#0-load-packages-and-define-variables","title":"0. load packages and define variables\u00b6","text":""},{"location":"tutorials/force/#i-create-forceset","title":"I. create forceset\u00b6","text":"<p>To calculate free energy and friction estimates, a forceset containing all the force time traces is needed.</p> <ol> <li>An array containing the filenames is generated. This can be done via the function dcTMD.io.load_pullf() which takes either a glob pattern or a file containing the pullf file names as argument.</li> </ol>"},{"location":"tutorials/force/#ii-check-normality-of-work-distribution","title":"II. check normality of work distribution\u00b6","text":"<p>One of the main conditions which need to be fulfilled for dcTMD is a normally distributed work.</p> <p>This can be checked via different methods, e.g., plotting the work time traces, normality checks at different $x$, Kolmogorov-Smirnov test, Shapiro-Wilk test, Anderson-Darling test.</p> <p>Caution: if the work distribution is not normal, your results are compromised and a path separation is necessary.</p>"},{"location":"tutorials/force/#iii-derive-estimates-from-forceset","title":"III. derive estimates from forceset\u00b6","text":"<ol> <li>create ForceEstimator instance</li> <li>fit ForceEstimator instance with previously created forceset</li> </ol>"},{"location":"tutorials/force/#visualize-results","title":"Visualize results\u00b6","text":"<p>A couple of simple plot functions to get an overview of the results are implemented.</p>"},{"location":"tutorials/force/#smooth-friction-estimate","title":"Smooth friction estimate\u00b6","text":"<p>Finally, the friction estimate needs to be smoothed. This can be done via <code>dcTMD.utils.smoothing.gaussfilter_friction()</code> or <code>dcTMD.WorkEstimator.smooth_friction(sigma, mode)</code>.</p> <p><code>sigma</code> is the standard deviation of gaussian kernel in nm, <code>mode</code> determines how the input array is extended input array is extended when the filter overlaps a border, as used by <code>scipy.ndimage.gaussian_filter()</code>.</p> <p>Caution: this can lead to long computation times when using large datasets and/or big smoothing windows.</p>"},{"location":"tutorials/force/#iv-save-and-load-results","title":"IV. Save and load results\u00b6","text":""},{"location":"tutorials/force_correlation/","title":"Analyse force correlations","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nN = 100  # number of trajectories\nlength_data = 3500  # nuber of time steps\n\n# create a mock delta_force_array with sine functions:\nforce_array = np.array([\n    np.sin(np.linspace(0, 2 * np.pi, length_data) + phase)\n    for phase in np.linspace(0, 0.5 * np.pi, N)\n])\n\nprint(force_array.shape)\nforce_mean = np.mean(force_array, axis=0)\n\n# calculate $\\delta f(t) = f(t) - \\left&lt; f(t) \\right&gt;_N$\ndelta_force_array = force_array - force_mean\n</pre>  import numpy as np import matplotlib.pyplot as plt  N = 100  # number of trajectories length_data = 3500  # nuber of time steps  # create a mock delta_force_array with sine functions: force_array = np.array([     np.sin(np.linspace(0, 2 * np.pi, length_data) + phase)     for phase in np.linspace(0, 0.5 * np.pi, N) ])  print(force_array.shape) force_mean = np.mean(force_array, axis=0)  # calculate $\\delta f(t) = f(t) - \\left&lt; f(t) \\right&gt;_N$ delta_force_array = force_array - force_mean   <pre>(100, 3500)\n</pre> In\u00a0[\u00a0]: Copied! <pre># define x and y labels for plotting\nxlabel = r'time step $\\tau$'\nylabel = r'$C_t({\\tau}) = \\left\\langle\\delta f(t)\\delta f(\\tau)\\right\\rangle_N$'\nlegend_title = 'ref. time step / position'\n</pre> # define x and y labels for plotting xlabel = r'time step $\\tau$' ylabel = r'$C_t({\\tau}) = \\left\\langle\\delta f(t)\\delta f(\\tau)\\right\\rangle_N$' legend_title = 'ref. time step / position' <p>plot example force data</p> In\u00a0[3]: Copied! <pre>x = np.linspace(0, 3.5-0.001, length_data)\n\nfig, ax = plt.subplots()\nfor n in range(10):\n    ax.plot(force_array[n], label=f'{n}')\nax.set(\n    xlabel=r'time step $t$',\n    ylabel=r'$f(t)$',\n    title='10 example trajectories'\n)\nax.plot(force_mean, color='black', linewidth=2, label='mean')\nplt.legend(title='traj no.')\nplt.show()\n</pre> x = np.linspace(0, 3.5-0.001, length_data)  fig, ax = plt.subplots() for n in range(10):     ax.plot(force_array[n], label=f'{n}') ax.set(     xlabel=r'time step $t$',     ylabel=r'$f(t)$',     title='10 example trajectories' ) ax.plot(force_mean, color='black', linewidth=2, label='mean') plt.legend(title='traj no.') plt.show()   <p>plot $\\delta f(t)$</p> In\u00a0[4]: Copied! <pre>fig, ax = plt.subplots()\nfor n in range(10):\n    ax.plot(delta_force_array[n], label=f'{n}')\nax.plot(force_mean, color='black', linewidth=2, label='mean')\nax.set(\n    xlabel=r'time step $t$',\n    ylabel=r'$\\delta f(t)$',\n    title='10 example trajectories'\n)\nplt.legend(title='traj no.')\nplt.show()\n</pre> fig, ax = plt.subplots() for n in range(10):     ax.plot(delta_force_array[n], label=f'{n}') ax.plot(force_mean, color='black', linewidth=2, label='mean') ax.set(     xlabel=r'time step $t$',     ylabel=r'$\\delta f(t)$',     title='10 example trajectories' ) plt.legend(title='traj no.') plt.show() <p>calculate memory at a given time index using the kernel_at_ndx function</p> In\u00a0[5]: Copied! <pre>from dcTMD.dcTMD import ForceEstimator as fe\n\nt_ndx_list = [0, 1000, 2000]\ncorrelation_array = np.zeros((len(t_ndx_list), length_data))\nfor i, t_ndx in enumerate(t_ndx_list):\n    correlation_array[i] = fe.kernel_at_ndx(delta_force_array, t_ndx)\n\nfig, ax = plt.subplots()\nfor i in range(len(t_ndx_list)):\n    ax.plot(correlation_array[i], label=t_ndx_list[i])\nax.set(\n    xlabel=xlabel,\n    ylabel=ylabel,\n    title=r'Correlation at different reference times $t$'\n)\nplt.legend(title=r'ref. time $t$')\nplt.show()\n</pre> from dcTMD.dcTMD import ForceEstimator as fe  t_ndx_list = [0, 1000, 2000] correlation_array = np.zeros((len(t_ndx_list), length_data)) for i, t_ndx in enumerate(t_ndx_list):     correlation_array[i] = fe.kernel_at_ndx(delta_force_array, t_ndx)  fig, ax = plt.subplots() for i in range(len(t_ndx_list)):     ax.plot(correlation_array[i], label=t_ndx_list[i]) ax.set(     xlabel=xlabel,     ylabel=ylabel,     title=r'Correlation at different reference times $t$' ) plt.legend(title=r'ref. time $t$') plt.show()  In\u00a0[6]: Copied! <pre>import numpy as np\nfrom dcTMD.dcTMD import ForceEstimator\nfrom dcTMD.storing import ForceSet\nimport dcTMD\n</pre> import numpy as np from dcTMD.dcTMD import ForceEstimator from dcTMD.storing import ForceSet import dcTMD In\u00a0[7]: Copied! <pre># define variables\nvelocity = 0.001\nres = 10\nverbose = True\ntemperature = 300\n</pre> # define variables velocity = 0.001 res = 10 verbose = True temperature = 300 In\u00a0[8]: Copied! <pre># if the filesnames are stored in a file\npullf_files = '../../tests/testdata/pullf_filenames.dat'\n# using a glob pattern / wildcard\npullf_files = '../../tests/testdata/*pullf.xvg'\n# loading the filenames\nfilenames = dcTMD.io.load_pullf(pullf_files)\n\nprint(filenames)\n</pre> # if the filesnames are stored in a file pullf_files = '../../tests/testdata/pullf_filenames.dat' # using a glob pattern / wildcard pullf_files = '../../tests/testdata/*pullf.xvg' # loading the filenames filenames = dcTMD.io.load_pullf(pullf_files)  print(filenames)  <pre>file ../../tests/testdata/*pullf.xvg not found. using glob.glob(../../tests/testdata/*pullf.xvg)\n['../../tests/testdata/t_middle_16_pullf.xvg', '../../tests/testdata/t_middle_26_pullf.xvg', '../../tests/testdata/t_middle_29_pullf.xvg', '../../tests/testdata/t_middle_32_pullf.xvg', '../../tests/testdata/t_middle_19_pullf.xvg', '../../tests/testdata/t_middle_03_pullf.xvg', '../../tests/testdata/t_middle_04_pullf.xvg', '../../tests/testdata/t_middle_05_pullf.xvg', '../../tests/testdata/t_middle_25_pullf.xvg', '../../tests/testdata/t_middle_31_pullf.xvg', '../../tests/testdata/t_middle_21_pullf.xvg', '../../tests/testdata/t_middle_17_pullf.xvg', '../../tests/testdata/t_middle_24_pullf.xvg', '../../tests/testdata/t_middle_09_pullf.xvg', '../../tests/testdata/t_middle_28_pullf.xvg', '../../tests/testdata/t_middle_30_pullf.xvg', '../../tests/testdata/t_middle_34_pullf.xvg', '../../tests/testdata/t_middle_01_pullf.xvg']\n</pre> In\u00a0[9]: Copied! <pre># create ForceSet instance\nforceset = ForceSet(velocity=velocity,\n                  resolution=res,\n                  verbose=verbose,\n                  )\n# fit/fill workset\nforceset.fit(filenames)\n</pre> # create ForceSet instance forceset = ForceSet(velocity=velocity,                   resolution=res,                   verbose=verbose,                   ) # fit/fill workset forceset.fit(filenames)   <pre>Using ../../tests/testdata/t_middle_16_pullf.xvg to initialize arrays.\nlength of pullf file is 20001\nreduced length is 2001\n</pre> <pre>Loading force files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:00&lt;00:00, 138.31it/s]</pre> <pre>Reading file ../../tests/testdata/t_middle_16_pullf.xvg\nReading file ../../tests/testdata/t_middle_26_pullf.xvg\nReading file ../../tests/testdata/t_middle_29_pullf.xvg\nReading file ../../tests/testdata/t_middle_32_pullf.xvg\nReading file ../../tests/testdata/t_middle_19_pullf.xvg\nReading file ../../tests/testdata/t_middle_03_pullf.xvg\nReading file ../../tests/testdata/t_middle_04_pullf.xvg\nReading file ../../tests/testdata/t_middle_05_pullf.xvg\nReading file ../../tests/testdata/t_middle_25_pullf.xvg\nReading file ../../tests/testdata/t_middle_31_pullf.xvg\nReading file ../../tests/testdata/t_middle_21_pullf.xvg\nReading file ../../tests/testdata/t_middle_17_pullf.xvg\nReading file ../../tests/testdata/t_middle_24_pullf.xvg\nReading file ../../tests/testdata/t_middle_09_pullf.xvg\nReading file ../../tests/testdata/t_middle_28_pullf.xvg\nReading file ../../tests/testdata/t_middle_30_pullf.xvg\nReading file ../../tests/testdata/t_middle_34_pullf.xvg\nReading file ../../tests/testdata/t_middle_01_pullf.xvg\n</pre> <pre>\n</pre> Out[9]: <pre>ForceSet(resolution=10, velocity=0.001, verbose=True)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u00a0ForceSetiFitted<pre>ForceSet(resolution=10, velocity=0.001, verbose=True)</pre> In\u00a0[10]: Copied! <pre>forceestimator = ForceEstimator(temperature)\nforceestimator.fit(forceset)\n</pre> forceestimator = ForceEstimator(temperature) forceestimator.fit(forceset) Out[10]: <pre>ForceEstimator(temperature=300)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.\u00a0ForceEstimatoriFitted<pre>ForceEstimator(temperature=300)</pre> In\u00a0[11]: Copied! <pre>index = np.array((0, 1000, 2000))\ncorrelation_at_given_ndx = forceestimator.memory_kernel(index=index)\n</pre> index = np.array((0, 1000, 2000)) correlation_at_given_ndx = forceestimator.memory_kernel(index=index) In\u00a0[12]: Copied! <pre>fig, ax = plt.subplots()\nfor (c, n) in zip(correlation_at_given_ndx, index):\n    plt.plot(c, label=fr'$t$={n} x={forceset.position_[n]:.2f}')\nplt.legend(title=legend_title)\nax.set(\n    xlabel=xlabel,\n    ylabel=ylabel,\n    title=r'Correlation at different $t$ values / positions'\n)\n#plt.savefig('forceforce_correlation_2dplot.png', dpi=300)\nplt.show()\n</pre> fig, ax = plt.subplots() for (c, n) in zip(correlation_at_given_ndx, index):     plt.plot(c, label=fr'$t$={n} x={forceset.position_[n]:.2f}') plt.legend(title=legend_title) ax.set(     xlabel=xlabel,     ylabel=ylabel,     title=r'Correlation at different $t$ values / positions' ) #plt.savefig('forceforce_correlation_2dplot.png', dpi=300) plt.show() <p>Since the data is very noisy one can apply a Gaussian filter to the data</p> In\u00a0[13]: Copied! <pre>from scipy.ndimage import gaussian_filter1d\n\nfilter_width = 1000\nfilter_width_in_nm = filter_width * forceset.position_[1]\n\nprint(f'Applying Gaussian filter with sigma={filter_width} time steps (~{filter_width_in_nm:.2f} nm)')\n\nfig, ax = plt.subplots()\nfor (c, n) in zip(correlation_at_given_ndx, index):\n    data = gaussian_filter1d(c, sigma=filter_width)\n    plt.plot(data, label=fr'$t$={n} x={forceset.position_[n]:.2f}')\nplt.legend(title=legend_title)\nax.set(\n    xlabel=xlabel,\n    ylabel=ylabel,\n    title=rf'smoothed correlation ($\\sigma$={filter_width})'\n)\n#plt.savefig('forceforce_correlation_2dplot.png', dpi=300)\nplt.show()\n</pre> from scipy.ndimage import gaussian_filter1d  filter_width = 1000 filter_width_in_nm = filter_width * forceset.position_[1]  print(f'Applying Gaussian filter with sigma={filter_width} time steps (~{filter_width_in_nm:.2f} nm)')  fig, ax = plt.subplots() for (c, n) in zip(correlation_at_given_ndx, index):     data = gaussian_filter1d(c, sigma=filter_width)     plt.plot(data, label=fr'$t$={n} x={forceset.position_[n]:.2f}') plt.legend(title=legend_title) ax.set(     xlabel=xlabel,     ylabel=ylabel,     title=rf'smoothed correlation ($\\sigma$={filter_width})' ) #plt.savefig('forceforce_correlation_2dplot.png', dpi=300) plt.show()   <pre>Applying Gaussian filter with sigma=1000 time steps (~0.10 nm)\n</pre> <ol> <li>calculate correlation every ndx_striding=1000 time steps</li> </ol> In\u00a0[14]: Copied! <pre>ndx_striding = 5000\nstriding_in_nm = ndx_striding * forceset.position_[1]\nprint(f'Calculating correlation every ndx_striding={ndx_striding} time steps (~{striding_in_nm:.2f} nm)')\nforceestimator.memory_kernel(\n    ndx_striding=ndx_striding\n)\ncorrelation_at_ndx_striding = forceestimator.memory_kernel_\nindex = forceestimator.memory_kernel_index_\n</pre> ndx_striding = 5000 striding_in_nm = ndx_striding * forceset.position_[1] print(f'Calculating correlation every ndx_striding={ndx_striding} time steps (~{striding_in_nm:.2f} nm)') forceestimator.memory_kernel(     ndx_striding=ndx_striding ) correlation_at_ndx_striding = forceestimator.memory_kernel_ index = forceestimator.memory_kernel_index_ <pre>Calculating correlation every ndx_striding=5000 time steps (~0.50 nm)\ncreate index with ndx_resolution\n</pre> In\u00a0[15]: Copied! <pre>fig, ax = plt.subplots()\nfor i, (data, n) in enumerate(zip(correlation_at_ndx_striding, index)):\n    plt.plot(data, label=fr'$t$={n} x={forceset.position_[n]:.2f}')\n    if i&gt;=10:\n        break\nplt.legend(title=legend_title)\nax.set(\n    xlabel=xlabel,\n    ylabel=ylabel,\n    title=rf'Correlation at time step inervals $\\Delta t= ${ndx_striding}'\n)\nplt.show()\n</pre>  fig, ax = plt.subplots() for i, (data, n) in enumerate(zip(correlation_at_ndx_striding, index)):     plt.plot(data, label=fr'$t$={n} x={forceset.position_[n]:.2f}')     if i&gt;=10:         break plt.legend(title=legend_title) ax.set(     xlabel=xlabel,     ylabel=ylabel,     title=rf'Correlation at time step inervals $\\Delta t= ${ndx_striding}' ) plt.show()  In\u00a0[16]: Copied! <pre># here we can reuse filter_width defined earlier\n\nfilter_width_in_nm = filter_width * forceset.position_[1]\nprint(f'Applying Gaussian filter with sigma={filter_width} time steps (~{filter_width_in_nm:.2f} nm)')\n\n\nfig, ax = plt.subplots()\nfor i, (data, n) in enumerate(zip(correlation_at_ndx_striding, index)):\n    data = gaussian_filter1d(data, sigma=filter_width)\n    plt.plot(\n        data,\n        label=fr'$t$={n} x={forceset.position_[n]:.2f}'\n    )\n    if i&gt;=8:\n        break\nplt.legend(title=legend_title, loc='lower right', ncol=2)\nax.set(\n    xlabel=r'time step $t$',\n    ylabel=r'$C_{\\tau}(t) = \\left\\langle\\delta f(t)\\delta f(\\tau)\\right\\rangle_N$',\n    title=rf'smoothed correlation ($\\sigma$={filter_width})'\n)\nplt.show()\n</pre> # here we can reuse filter_width defined earlier  filter_width_in_nm = filter_width * forceset.position_[1] print(f'Applying Gaussian filter with sigma={filter_width} time steps (~{filter_width_in_nm:.2f} nm)')   fig, ax = plt.subplots() for i, (data, n) in enumerate(zip(correlation_at_ndx_striding, index)):     data = gaussian_filter1d(data, sigma=filter_width)     plt.plot(         data,         label=fr'$t$={n} x={forceset.position_[n]:.2f}'     )     if i&gt;=8:         break plt.legend(title=legend_title, loc='lower right', ncol=2) ax.set(     xlabel=r'time step $t$',     ylabel=r'$C_{\\tau}(t) = \\left\\langle\\delta f(t)\\delta f(\\tau)\\right\\rangle_N$',     title=rf'smoothed correlation ($\\sigma$={filter_width})' ) plt.show() <pre>Applying Gaussian filter with sigma=1000 time steps (~0.10 nm)\n</pre> In\u00a0[17]: Copied! <pre># create a 3D plot with the lag time on the x axis\ndef forceforce_correlation_3dplot(\n    index, correlation_set,\n    position=None,\n    smoothing=None,\n    addplane=False\n):\n    \"\"\"\n    Create a 3D plot of the force-force correlation function.\n    Parameters\n    ----------\n    index :\n        Indices at which the correlation is calculated.\n    correlation_set :\n        shape: (len(index), length_data)\n        NaN are set to zero\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    ax.set_xlabel(xlabel)\n    ax.set_ylabel(r'ref. time step $t$')\n    ax.set_zlabel(ylabel)\n    \n    x_plane = np.linspace(0, len(correlation_set[0]), len(correlation_set[0]))\n    y_plane = np.linspace(min(index), max(index), len(index))\n    if position is not None:\n        y_plane = np.linspace(\n            position[min(index)],\n            position[max(index)],\n            len(index)\n        )\n    X_plane, Y_plane = np.meshgrid(x_plane, y_plane)\n    Z_plane = np.zeros_like(X_plane)\n\n\n    for i, ndx in enumerate(index):\n        if smoothing is not None:\n            x = gaussian_filter1d(correlation_set[i], sigma=smoothing)\n        else:\n            x = correlation_set[i]\n        y = np.arange(len(x))\n        if position is not None:\n            z = position[ndx]\n            ax.set_ylabel(r'$x$ [nm]')\n\n        else:\n            z = ndx\n        ax.plot(y, x, zs=z, zdir='y', label=f'lag {ndx}')\n    \n    if addplane:\n        # Create a semi-transparent plane at z=0\n        ax.plot_surface(X_plane, Y_plane, Z_plane, alpha=0.5, color='gray')\n    #ax.set_ylim(ax.get_ylim()[::-1])  # Reverse the y-axis limits\n</pre> # create a 3D plot with the lag time on the x axis def forceforce_correlation_3dplot(     index, correlation_set,     position=None,     smoothing=None,     addplane=False ):     \"\"\"     Create a 3D plot of the force-force correlation function.     Parameters     ----------     index :         Indices at which the correlation is calculated.     correlation_set :         shape: (len(index), length_data)         NaN are set to zero     \"\"\"     fig = plt.figure()     ax = fig.add_subplot(projection='3d')     ax.set_xlabel(xlabel)     ax.set_ylabel(r'ref. time step $t$')     ax.set_zlabel(ylabel)          x_plane = np.linspace(0, len(correlation_set[0]), len(correlation_set[0]))     y_plane = np.linspace(min(index), max(index), len(index))     if position is not None:         y_plane = np.linspace(             position[min(index)],             position[max(index)],             len(index)         )     X_plane, Y_plane = np.meshgrid(x_plane, y_plane)     Z_plane = np.zeros_like(X_plane)       for i, ndx in enumerate(index):         if smoothing is not None:             x = gaussian_filter1d(correlation_set[i], sigma=smoothing)         else:             x = correlation_set[i]         y = np.arange(len(x))         if position is not None:             z = position[ndx]             ax.set_ylabel(r'$x$ [nm]')          else:             z = ndx         ax.plot(y, x, zs=z, zdir='y', label=f'lag {ndx}')          if addplane:         # Create a semi-transparent plane at z=0         ax.plot_surface(X_plane, Y_plane, Z_plane, alpha=0.5, color='gray')     #ax.set_ylim(ax.get_ylim()[::-1])  # Reverse the y-axis limits   In\u00a0[18]: Copied! <pre>forceforce_correlation_3dplot(\n    index,\n    correlation_at_ndx_striding,\n)\nplt.title('3D plot of force-force correlation')\nplt.tight_layout()\nplt.show()\n</pre> forceforce_correlation_3dplot(     index,     correlation_at_ndx_striding, ) plt.title('3D plot of force-force correlation') plt.tight_layout() plt.show()   In\u00a0[19]: Copied! <pre>forceforce_correlation_3dplot(\n    index,\n    correlation_at_ndx_striding,\n    position=forceset.position_,\n    smoothing=filter_width\n)\nplt.title(r'3D plot of smoothed $C_t(\\tau)$ with positions instead of time steps')\nplt.tight_layout()\nplt.show()\n</pre> forceforce_correlation_3dplot(     index,     correlation_at_ndx_striding,     position=forceset.position_,     smoothing=filter_width ) plt.title(r'3D plot of smoothed $C_t(\\tau)$ with positions instead of time steps') plt.tight_layout() plt.show()"},{"location":"tutorials/force_correlation/#force-memory-analysis","title":"Force Memory Analysis\u00b6","text":"<p>The force correlations at a fixed reference time point $t$ between all trajectories at a second time step $\\tau$ are expressed as:</p> <p>$$ \\begin{align} C_t(\\tau) = \\left&lt;\\delta f_c(t)\\delta f_c(\\tau)\\right&gt;_N \\end{align} $$</p> <p>with $\\left&lt;...\\right&gt;_N$ the mean over all $N$ trajectories and $\\delta f_c(t')=f_c(t')-\\left&lt;f_c(t')\\right&gt;_N$ the constraint force $f_c$ at any given point in time $t'$ minus the average of all constraint forces at that time point.</p> <p>This analysis allows to gain insight into correlations and time scales of all other (aka \"bath\") degrees of freedom that are orthogonal to the pulling coordinate and thus allow insights into, e.g., hydration sphere water dynamics and protein conformational changes. In the framework of dcTMD, $C_t(\\tau)$ corresponds to the so-called Memory Kernel. See Wolf, Stock, JCTC 2018, 14, 6715 and Post, Wolf, Stock, JCTC 2022, 18, 2816 for further details and examples for such analyses.</p> <p>Please note: the convergence of $C_t(\\tau)$ is very poor. We advise some soft Gaussian smoothing of the autocorrelation function to check for a specific structure.</p> <p>We start by introducing the general concept with dummy sinoid data and continue with real trajectories.</p>"},{"location":"tutorials/force_correlation/#sinoid-data","title":"Sinoid Data\u00b6","text":""},{"location":"tutorials/force_correlation/#trajectory-data","title":"Trajectory Data:\u00b6","text":"<p>This analysis is usually done in addition to the $\\Delta G$ and $\\Gamma$ evaluation based on the ForceEstimator class. If you have read dcTMD via Force you can skip the steps 0 and 1.</p>"},{"location":"tutorials/force_correlation/#0-load-packages-and-define-variables","title":"0. load packages and define variables\u00b6","text":""},{"location":"tutorials/force_correlation/#1-create-a-forceset-instance","title":"1. create a forceset instance\u00b6","text":"<p>To calculate free energy and friction estimates a forceset containing all the force time traces is needed.</p>"},{"location":"tutorials/force_correlation/#i-an-array-containing-the-filenames-is-generated","title":"I. an array containing the filenames is generated.\u00b6","text":"<p>This can be done via the function dcTMD.io.load_pullf() which takes either a glob pattern or a file containing the pullf file names as argument.</p>"},{"location":"tutorials/force_correlation/#ii-the-forceset-is-created","title":"II. the forceset is created\u00b6","text":"<p>by creating a ForceSet instance which is fitted with the filenames.</p>"},{"location":"tutorials/force_correlation/#iii-derive-estimates-from-the-forceset","title":"III. derive estimates from the forceset\u00b6","text":"<ol> <li>instantiate a ForceEstimator instance</li> <li>fit ForceEstimator instance with previously created forceset</li> </ol> <p>When the ForceEstimator is fit with the forceset the delta_force_array is created</p>"},{"location":"tutorials/force_correlation/#2-calculate-correlations-at-given-reference-time-steps","title":"2. calculate correlations at given reference time steps\u00b6","text":"<p>There are two options for the time steps at which the correlation is calculated.</p> <ol> <li>specify the indices of the time steps with index</li> <li>calculate the correlation every ndx_striding time steps</li> </ol> <p>CAUTION: calculating the correlations is very memory consuming.</p>"},{"location":"tutorials/force_correlation/#3d-plots","title":"3D plots\u00b6","text":"<p>The function forceforce_correlation_3dplot creates a 3D plot to visualize the correlation between forces over time. It allows for optional smoothing and can display specific positions on the z-axis.</p>"},{"location":"tutorials/force_memorytest/","title":"Force memorytest","text":"In\u00a0[3]: Copied! <pre>import numpy as np\nfrom dcTMD.dcTMD import ForceEstimator\nfrom dcTMD.storing import ForceSet, load\nimport dcTMD\n</pre> import numpy as np from dcTMD.dcTMD import ForceEstimator from dcTMD.storing import ForceSet, load import dcTMD In\u00a0[4]: Copied! <pre># define variables\nvelocity = 0.001\nres = 10\nverbose = True\ntemperature = 300\n</pre> # define variables velocity = 0.001 res = 10 verbose = True temperature = 300 In\u00a0[5]: Copied! <pre>pullf_files = '../../tests/testdata/pullf_filenames.dat'\npullf_files = '../../tests/testdata/*pullf.xvg'\nfilenames = dcTMD.io.load_pullf(pullf_files)\n\nfilenames\n</pre> pullf_files = '../../tests/testdata/pullf_filenames.dat' pullf_files = '../../tests/testdata/*pullf.xvg' filenames = dcTMD.io.load_pullf(pullf_files)  filenames  <pre>file ../../tests/testdata/*pullf.xvg not found. using glob.glob(../../tests/testdata/*pullf.xvg)\n</pre> Out[5]: <pre>['../../tests/testdata/t_middle_32_pullf.xvg',\n '../../tests/testdata/t_middle_03_pullf.xvg',\n '../../tests/testdata/t_middle_34_pullf.xvg',\n '../../tests/testdata/t_middle_24_pullf.xvg',\n '../../tests/testdata/t_middle_21_pullf.xvg',\n '../../tests/testdata/t_middle_04_pullf.xvg',\n '../../tests/testdata/t_middle_29_pullf.xvg',\n '../../tests/testdata/t_middle_16_pullf.xvg',\n '../../tests/testdata/t_middle_30_pullf.xvg',\n '../../tests/testdata/t_middle_19_pullf.xvg',\n '../../tests/testdata/t_middle_01_pullf.xvg',\n '../../tests/testdata/t_middle_28_pullf.xvg',\n '../../tests/testdata/t_middle_26_pullf.xvg',\n '../../tests/testdata/t_middle_31_pullf.xvg',\n '../../tests/testdata/t_middle_09_pullf.xvg',\n '../../tests/testdata/t_middle_17_pullf.xvg',\n '../../tests/testdata/t_middle_25_pullf.xvg',\n '../../tests/testdata/t_middle_05_pullf.xvg']</pre> <ol> <li>the forceset is created by creating a ForceSet instance which is fitted with the filenames.</li> </ol> In\u00a0[6]: Copied! <pre># create ForceSet instance\nforceset = ForceSet(velocity=velocity,\n                  resolution=res,\n                  verbose=verbose,\n                  )\nforceset\n</pre> # create ForceSet instance forceset = ForceSet(velocity=velocity,                   resolution=res,                   verbose=verbose,                   ) forceset  Out[6]: <pre>ForceSet(resolution=10, velocity=0.001, verbose=True)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.ForceSet<pre>ForceSet(resolution=10, velocity=0.001, verbose=True)</pre> In\u00a0[7]: Copied! <pre># fit/fill workset\nforceset.fit(filenames)\n# calculate work\nforceset.integrate()\n# save workset\n#dcTMD.storing.save('my_forceset', forceset)\n</pre> # fit/fill workset forceset.fit(filenames) # calculate work forceset.integrate() # save workset #dcTMD.storing.save('my_forceset', forceset)   <pre>Using ../../tests/testdata/t_middle_32_pullf.xvg to initialize arrays.\nlength of pullf file is 20001\nreduced length is 2001\n</pre> <pre>Loading force files:   0%|          | 0/18 [00:00&lt;?, ?it/s]</pre> <pre>Reading file ../../tests/testdata/t_middle_32_pullf.xvg\nReading file ../../tests/testdata/t_middle_03_pullf.xvg\nReading file ../../tests/testdata/t_middle_34_pullf.xvg\n</pre> <pre>Loading force files:  22%|\u2588\u2588\u258f       | 4/18 [00:00&lt;00:00, 34.63it/s]</pre> <pre>Reading file ../../tests/testdata/t_middle_24_pullf.xvg\nReading file ../../tests/testdata/t_middle_21_pullf.xvg\nReading file ../../tests/testdata/t_middle_04_pullf.xvg\nReading file ../../tests/testdata/t_middle_29_pullf.xvg\n</pre> <pre>Loading force files:  22%|\u2588\u2588\u258f       | 4/18 [00:00&lt;00:00, 34.63it/s]</pre> <pre>Reading file ../../tests/testdata/t_middle_16_pullf.xvg\n</pre> <pre>Loading force files:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 13/18 [00:00&lt;00:00, 33.04it/s]</pre> <pre>Reading file ../../tests/testdata/t_middle_30_pullf.xvg\nReading file ../../tests/testdata/t_middle_19_pullf.xvg\nReading file ../../tests/testdata/t_middle_01_pullf.xvg\nReading file ../../tests/testdata/t_middle_28_pullf.xvg\nReading file ../../tests/testdata/t_middle_26_pullf.xvg\nReading file ../../tests/testdata/t_middle_31_pullf.xvg\nReading file ../../tests/testdata/t_middle_09_pullf.xvg\n</pre> <pre>Loading force files:  72%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u258f  | 13/18 [00:00&lt;00:00, 33.04it/s]</pre> <pre>Reading file ../../tests/testdata/t_middle_17_pullf.xvg\nReading file ../../tests/testdata/t_middle_25_pullf.xvg\n</pre> <pre>Loading force files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:00&lt;00:00, 35.12it/s]\n</pre> <pre>Reading file ../../tests/testdata/t_middle_05_pullf.xvg\n</pre> In\u00a0[8]: Copied! <pre># plot workset\nimport matplotlib.pyplot as plt\nfrom dcTMD.utils import plotting\n\n\nfig, ax = plt.subplots()\nplotting.plot_worklines(forceset, ax)\nplt.show()\n\nforceset.work_\n</pre> # plot workset import matplotlib.pyplot as plt from dcTMD.utils import plotting   fig, ax = plt.subplots() plotting.plot_worklines(forceset, ax) plt.show()  forceset.work_ Out[8]: <pre>array([[ 0.00000000e+00,  1.03698915e-01,  1.24836915e-01, ...,\n         8.45118712e+01,  8.44347098e+01,  8.44165457e+01],\n       [ 0.00000000e+00, -1.00744350e-01, -2.14093600e-01, ...,\n         1.15331409e+02,  1.15265871e+02,  1.15229601e+02],\n       [ 0.00000000e+00,  6.30896000e-02,  5.76634000e-02, ...,\n         5.74830869e+01,  5.75868897e+01,  5.74908294e+01],\n       ...,\n       [ 0.00000000e+00, -8.02650000e-03,  1.56785000e-01, ...,\n         5.20392642e+01,  5.21592937e+01,  5.21718456e+01],\n       [ 0.00000000e+00,  1.79783900e-01,  3.88872900e-01, ...,\n         8.74668694e+01,  8.72953927e+01,  8.72269519e+01],\n       [ 0.00000000e+00,  2.15985500e-02, -4.17557500e-02, ...,\n         9.99542344e+01,  9.98090948e+01,  9.98238686e+01]])</pre> In\u00a0[9]: Copied! <pre>from scipy.stats import probplot\n\ndef plot_worknormalitychecks(\n    workset,\n    index,\n    x=None,\n    worklinecolor='#777',\n    colors=None,\n    figsize=(6, 2),\n    axs=None,\n    res=10,\n):\n    \"\"\"Plots the work values of trajectories individually.\n\n    This function generates a plot with three subplots:\n    1. Line plots of the work values for all trajectories.\n    2. Work value histograms for the indices given `index`.\n    3. As well as normality plot (Q-Q plot) for the work values the indices given `index`..\n\n    Args:\n        workset: workset object\n        index (list of int): Indices of the positions. These indices\n            are used to extract specific columns from `workset.work_` for\n            histogram and normality plots.\n        x (array-like, optional): The x-axis positions for the work values. If\n            not provided, `workset.position_` is used.\n        worklinecolor (str, optional): Color of the work line plot. Default is\n            '#777'.\n        colors (list of str, optional):\n            Colors for the histogram and normality\n            plots. If not provided, the `Dark2` colormap is used.\n        figsize (tuple, optional):\n            Size of the figure. Default is (6, 2).\n        axs (list of matplotlib.axes.Axes, optional):\n            Axes for the subplots. If\n            not provided, new axes are created.\n        res (int, optional): Resolution for the work line plot. Default is 10.\n\n    Returns:\n        list of matplotlib.axes.Axes: The axes containing the subplots.\n\n    Example:\n        &gt;&gt;&gt; plot_worknormalitychecks(\n        ...     workset=my_workset,\n        ...     index=[0, 5, 10],\n        ... )\n        &gt;&gt;&gt; plt.show()\n\n    \"\"\"\n    if axs is None:\n        print('No axs given. Create figure.')\n        fig, axs = plt.subplots(\n            ncols=3,\n            nrows=1,\n            figsize=figsize,\n        )\n    if x is None:\n        x = workset.position_\n    plotting.plot_worklines(workset, axs[0], x=x, res=res, color=worklinecolor)\n\n    if not colors:\n        cmap = plt.get_cmap('Dark2')\n        colors = cmap.colors\n\n    for j, idx in enumerate(index):\n        work = workset.work_[:, idx].ravel()\n        axs[1].set_title(r'Histogram at $x$')\n        plotting.plot_histo_normaldist(work, axs[1], colors[j])\n        axs[0].axvline(x[idx],\n                       color=colors[j],\n                       zorder=3,\n                       label=rf'$x={x[idx]:.2f}$',\n                       )\n\n        probplot(work, plot=axs[2], fit=True)\n        axs[2].get_lines()[j * 2].set_color(colors[j])  # noqa: WPS221\n        axs[2].set_title('Normality plot')\n\n    axs[0].legend()\n    return axs\n</pre> from scipy.stats import probplot  def plot_worknormalitychecks(     workset,     index,     x=None,     worklinecolor='#777',     colors=None,     figsize=(6, 2),     axs=None,     res=10, ):     \"\"\"Plots the work values of trajectories individually.      This function generates a plot with three subplots:     1. Line plots of the work values for all trajectories.     2. Work value histograms for the indices given `index`.     3. As well as normality plot (Q-Q plot) for the work values the indices given `index`..      Args:         workset: workset object         index (list of int): Indices of the positions. These indices             are used to extract specific columns from `workset.work_` for             histogram and normality plots.         x (array-like, optional): The x-axis positions for the work values. If             not provided, `workset.position_` is used.         worklinecolor (str, optional): Color of the work line plot. Default is             '#777'.         colors (list of str, optional):             Colors for the histogram and normality             plots. If not provided, the `Dark2` colormap is used.         figsize (tuple, optional):             Size of the figure. Default is (6, 2).         axs (list of matplotlib.axes.Axes, optional):             Axes for the subplots. If             not provided, new axes are created.         res (int, optional): Resolution for the work line plot. Default is 10.      Returns:         list of matplotlib.axes.Axes: The axes containing the subplots.      Example:         &gt;&gt;&gt; plot_worknormalitychecks(         ...     workset=my_workset,         ...     index=[0, 5, 10],         ... )         &gt;&gt;&gt; plt.show()      \"\"\"     if axs is None:         print('No axs given. Create figure.')         fig, axs = plt.subplots(             ncols=3,             nrows=1,             figsize=figsize,         )     if x is None:         x = workset.position_     plotting.plot_worklines(workset, axs[0], x=x, res=res, color=worklinecolor)      if not colors:         cmap = plt.get_cmap('Dark2')         colors = cmap.colors      for j, idx in enumerate(index):         work = workset.work_[:, idx].ravel()         axs[1].set_title(r'Histogram at $x$')         plotting.plot_histo_normaldist(work, axs[1], colors[j])         axs[0].axvline(x[idx],                        color=colors[j],                        zorder=3,                        label=rf'$x={x[idx]:.2f}$',                        )          probplot(work, plot=axs[2], fit=True)         axs[2].get_lines()[j * 2].set_color(colors[j])  # noqa: WPS221         axs[2].set_title('Normality plot')      axs[0].legend()     return axs In\u00a0[10]: Copied! <pre># check if work distribution follows a normal distribution\nfrom scipy.stats import kstest, shapiro, anderson\n\n\nindex = [5000, 15000]\nx = forceset.position_\n\nplot_worknormalitychecks(forceset, index)\nplt.tight_layout()\nplt.show()\nfor i, p in enumerate(index):\n    # Shapiro-Wilk Test\n    shapiro_test = shapiro(forceset.work_[:,p])\n    print(f'shapiro wilkins results at x={x[p]} is {shapiro_test}')\n    # Anderson-Darling Test\n    # If the test statsitics is larger than the critical value of a given\n    # significance_level in percent, the null hypothesis that the work\n    # is normally distributed has to be rejected.\n    anderson_test = anderson(forceset.work_[:,p], 'norm')\n    print(f'anderson darling results at x={x[p]} is {anderson_test}.')\n    # Kolmogorov-Smirnov Test (requires centering and scaling of input data)\n    kstest_test = kstest(\n        (forceset.work_[:,p]-np.mean(forceset.work_[:,p]))/np.std(forceset.work_[:,p]),\n        'norm'\n    )\n    print(f'Kolmogorov-Smirnov results at x={x[p]} is {kstest_test}')\n</pre> # check if work distribution follows a normal distribution from scipy.stats import kstest, shapiro, anderson   index = [5000, 15000] x = forceset.position_  plot_worknormalitychecks(forceset, index) plt.tight_layout() plt.show() for i, p in enumerate(index):     # Shapiro-Wilk Test     shapiro_test = shapiro(forceset.work_[:,p])     print(f'shapiro wilkins results at x={x[p]} is {shapiro_test}')     # Anderson-Darling Test     # If the test statsitics is larger than the critical value of a given     # significance_level in percent, the null hypothesis that the work     # is normally distributed has to be rejected.     anderson_test = anderson(forceset.work_[:,p], 'norm')     print(f'anderson darling results at x={x[p]} is {anderson_test}.')     # Kolmogorov-Smirnov Test (requires centering and scaling of input data)     kstest_test = kstest(         (forceset.work_[:,p]-np.mean(forceset.work_[:,p]))/np.std(forceset.work_[:,p]),         'norm'     )     print(f'Kolmogorov-Smirnov results at x={x[p]} is {kstest_test}') <pre>No axs given. Create figure.\n</pre> <pre>shapiro wilkins results at x=0.5 is ShapiroResult(statistic=0.9809889406089324, pvalue=0.95963623434336)\nanderson darling results at x=0.5 is AndersonResult(statistic=0.1889729620402001, critical_values=array([0.503, 0.573, 0.687, 0.802, 0.954]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]), fit_result=  params: FitParams(loc=67.2816159481796, scale=12.135336573012399)\n success: True\n message: '`anderson` successfully fit the distribution to the data.').\nKolmogorov-Smirnov results at x=0.5 is KstestResult(statistic=0.1222997987555296, pvalue=0.920955734836253, statistic_location=-1.013218181258685, statistic_sign=1)\nshapiro wilkins results at x=1.5 is ShapiroResult(statistic=0.9350144421408513, pvalue=0.237681372960928)\nanderson darling results at x=1.5 is AndersonResult(statistic=0.38109849215264546, critical_values=array([0.503, 0.573, 0.687, 0.802, 0.954]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]), fit_result=  params: FitParams(loc=92.54892049414023, scale=19.147779388352493)\n success: True\n message: '`anderson` successfully fit the distribution to the data.').\nKolmogorov-Smirnov results at x=1.5 is KstestResult(statistic=0.14917443864214264, pvalue=0.7646028245726414, statistic_location=0.5380536480357743, statistic_sign=-1)\n</pre> In\u00a0[11]: Copied! <pre>## load force\n# force = load('my_force_set')\n# Instantiate a ForceEstimator instance and fit it with the ForceSet\n# instance\nforceestimator = ForceEstimator(temperature)\nforceestimator.fit(forceset)\nvars(forceestimator)\n</pre> ## load force # force = load('my_force_set') # Instantiate a ForceEstimator instance and fit it with the ForceSet # instance forceestimator = ForceEstimator(temperature) forceestimator.fit(forceset) vars(forceestimator) Out[11]: <pre>{'temperature': 300,\n 'verbose': False,\n 'force_set': ForceSet(resolution=10, velocity=0.001, verbose=True),\n 'names_': array(['t_middle_32_pullf.xvg', 't_middle_03_pullf.xvg',\n        't_middle_34_pullf.xvg', 't_middle_24_pullf.xvg',\n        't_middle_21_pullf.xvg', 't_middle_04_pullf.xvg',\n        't_middle_29_pullf.xvg', 't_middle_16_pullf.xvg',\n        't_middle_30_pullf.xvg', 't_middle_19_pullf.xvg',\n        't_middle_01_pullf.xvg', 't_middle_28_pullf.xvg',\n        't_middle_26_pullf.xvg', 't_middle_31_pullf.xvg',\n        't_middle_09_pullf.xvg', 't_middle_17_pullf.xvg',\n        't_middle_25_pullf.xvg', 't_middle_05_pullf.xvg'], dtype='&lt;U32'),\n 'delta_force_array': array([[-8.73736883e+02,  2.06404027e+03, -1.64675083e+03, ...,\n         -3.84514611e+02, -6.60017244e+02,  1.03823811e+03],\n        [-1.21761218e+03, -1.68094973e+03, -5.91505833e+02, ...,\n         -1.45385561e+03,  6.41780156e+02, -6.25663889e+02],\n        [-2.50703183e+02,  6.28820267e+02, -7.42814833e+02, ...,\n          1.87819439e+03,  6.96557756e+02, -1.87626089e+03],\n        ...,\n        [-2.08374518e+03,  1.03954027e+03,  2.25121917e+03, ...,\n          1.37587439e+03,  1.52341276e+03, -5.30872889e+02],\n        [-2.15387183e+02,  2.92739027e+03,  1.24891917e+03, ...,\n         -2.93190561e+03,  1.06975556e+00, -6.28384889e+02],\n        [ 2.67058167e+01, -4.78409733e+02, -7.94146833e+02, ...,\n         -3.65687561e+03,  1.25278176e+03, -2.15804889e+02]]),\n 'position_': array([0.000e+00, 1.000e-03, 2.000e-03, ..., 1.998e+00, 1.999e+00,\n        2.000e+00]),\n 'W_mean_': array([ 0.        ,  0.14466391,  0.36114316, ..., 93.12437156,\n        93.16217564, 93.25164019]),\n 'W_diss_': array([0.00000000e+00, 1.99512210e-02, 6.03146650e-02, ...,\n        1.02031176e+02, 1.03067804e+02, 1.03098458e+02]),\n 'dG_': array([ 0.        ,  0.12471269,  0.3008285 , ..., -8.90680403,\n        -9.90562862, -9.846818  ]),\n 'friction_': array([       0.        ,    55230.58782798,  -164363.71925407, ...,\n         -338660.25716201, -1174211.8275909 ,  1198605.76619241])}</pre> In\u00a0[12]: Copied! <pre>def memory_kernel(\n    forceestimator,\n    x_indices,\n):\n    \"\"\"\n    Calculate memory kernel at positions X \"forward\" in time.\n    From fluctuation-dissipation. \n    Parameters\n    ----------\n    x_indices :\n        Indices at which memory kernel is calculated.\n    Returns\n    -------\n    corr_set :\n        shape: (len(X), length_data)\n        NaN are set to zero\n    \"\"\"\n    N, length_data = forceestimator.delta_force_array.shape\n    print(forceestimator.delta_force_array.shape)\n    autocorr_set = np.zeros((len(x_indices), length_data))\n    corr_set = []\n    for tt in range(length_data):\n        currenttstep_array = forceestimator.delta_force_array[:, tt:-2]\n        nexttstep_array = forceestimator.delta_force_array[:, tt + 1:-1]\n        corr_set.append(currenttstep_array * nexttstep_array)\n\n    print(corr_set)\n    print(nexttstep_array.shape, currenttstep_array.shape)\n    #for i, ndx in enumerate(x_indices):\n    #    test = np.mean(\n    #        entries[:, ndx:],\n    #        axis=0,\n    #    )\n    #    print(entries[:, ndx:].shape)\n    #    print(test.shape)\n    return corr_set\n\n#\nmemory_kernel(forceestimator, [100, 200])\n</pre> def memory_kernel(     forceestimator,     x_indices, ):     \"\"\"     Calculate memory kernel at positions X \"forward\" in time.     From fluctuation-dissipation.      Parameters     ----------     x_indices :         Indices at which memory kernel is calculated.     Returns     -------     corr_set :         shape: (len(X), length_data)         NaN are set to zero     \"\"\"     N, length_data = forceestimator.delta_force_array.shape     print(forceestimator.delta_force_array.shape)     autocorr_set = np.zeros((len(x_indices), length_data))     corr_set = []     for tt in range(length_data):         currenttstep_array = forceestimator.delta_force_array[:, tt:-2]         nexttstep_array = forceestimator.delta_force_array[:, tt + 1:-1]         corr_set.append(currenttstep_array * nexttstep_array)      print(corr_set)     print(nexttstep_array.shape, currenttstep_array.shape)     #for i, ndx in enumerate(x_indices):     #    test = np.mean(     #        entries[:, ndx:],     #        axis=0,     #    )     #    print(entries[:, ndx:].shape)     #    print(test.shape)     return corr_set  # memory_kernel(forceestimator, [100, 200]) <pre>(18, 20001)\n</pre> <pre>\n---------------------------------------------------------------------------\nKeyboardInterrupt                         Traceback (most recent call last)\nCell In[12], line 39\n     36     return corr_set\n     38 #\n---&gt; 39 memory_kernel(forceestimator, [100, 200])\n\nCell In[12], line 25, in memory_kernel(forceestimator, x_indices)\n     23     currenttstep_array = forceestimator.delta_force_array[:, tt:-2]\n     24     nexttstep_array = forceestimator.delta_force_array[:, tt + 1:-1]\n---&gt; 25     corr_set.append(currenttstep_array * nexttstep_array)\n     27 print(corr_set)\n     28 print(nexttstep_array.shape, currenttstep_array.shape)\n\nKeyboardInterrupt: </pre> In\u00a0[13]: Copied! <pre>from scipy.constants import R  # noqa: WPS347\nfrom scipy.integrate import cumulative_trapezoid\n\nN, length_data =  forceset.force_.shape\ndelta_force_array2 = np.zeros((N, length_data))\n\nRT = R * 300 / 1e3\n# average over all trajectories in each time step\nforce_mean = np.mean(forceset.force_, axis=0)\nprint(force_mean.shape)\n\n# calculate $\\delta f(t) = f(t) - \\left&lt; f (t) \\right&gt;_N$\nfor t in range(length_data):\n    delta_force_array2[:, t] = forceset.force_[:, t] - force_mean[t]\n\ndelta_force_array = forceestimator.delta_force_array\n\n# for better visulaization smooth the data with gaussian filter\nfrom scipy.ndimage import gaussian_filter1d\nsigma = 2\ndelta_force_array = gaussian_filter1d(delta_force_array, sigma=sigma, axis=1)\nprint(np.sum(delta_force_array - delta_force_array2))\n</pre> from scipy.constants import R  # noqa: WPS347 from scipy.integrate import cumulative_trapezoid  N, length_data =  forceset.force_.shape delta_force_array2 = np.zeros((N, length_data))  RT = R * 300 / 1e3 # average over all trajectories in each time step force_mean = np.mean(forceset.force_, axis=0) print(force_mean.shape)  # calculate $\\delta f(t) = f(t) - \\left&lt; f (t) \\right&gt;_N$ for t in range(length_data):     delta_force_array2[:, t] = forceset.force_[:, t] - force_mean[t]  delta_force_array = forceestimator.delta_force_array  # for better visulaization smooth the data with gaussian filter from scipy.ndimage import gaussian_filter1d sigma = 2 delta_force_array = gaussian_filter1d(delta_force_array, sigma=sigma, axis=1) print(np.sum(delta_force_array - delta_force_array2))  <pre>(20001,)\n-5.411493475548923e-11\n</pre> In\u00a0[14]: Copied! <pre># create a mock delta_force_array with sinoud functions:\ndelta_force_array = np.array([\n    np.sin(np.linspace(0, 2 * np.pi, length_data) + phase)\n    for phase in np.linspace(0, 2 * np.pi, N)\n])\n\nprint(delta_force_array.shape)\n\n\nimport matplotlib.pyplot as plt\nx = forceestimator.position_\nfig, ax = plt.subplots()\nfor n in range(10):\n    ax.plot(delta_force_array[n], label=f'ndx {n}')\n\nplt.show()\n</pre> # create a mock delta_force_array with sinoud functions: delta_force_array = np.array([     np.sin(np.linspace(0, 2 * np.pi, length_data) + phase)     for phase in np.linspace(0, 2 * np.pi, N) ])  print(delta_force_array.shape)   import matplotlib.pyplot as plt x = forceestimator.position_ fig, ax = plt.subplots() for n in range(10):     ax.plot(delta_force_array[n], label=f'ndx {n}')  plt.show() <pre>(18, 20001)\n</pre> In\u00a0[15]: Copied! <pre>ndx = 0\nshifted_array = np.roll(delta_force_array, -ndx, axis=1)\nplt.plot(shifted_array[0], label='shifted')\n# Pad with zeros where the shift goes out of bounds\nshifted_array[:, -ndx:] = 0\nplt.plot(shifted_array[0], label='padded')\nplt.show()\n</pre>  ndx = 0 shifted_array = np.roll(delta_force_array, -ndx, axis=1) plt.plot(shifted_array[0], label='shifted') # Pad with zeros where the shift goes out of bounds shifted_array[:, -ndx:] = 0 plt.plot(shifted_array[0], label='padded') plt.show()  In\u00a0[20]: Copied! <pre>def _kernel_at_ndx(delta_force_array, ndx):\n    # this is how the correltaion is implemented in Steffens dcTMD script\n    # the correlation is evaluated a ficed point in time\n    delta_force_point = delta_force_array[:, ndx]\n    force_correlation_at_ndx = (delta_force_array.T * delta_force_point).T\n    return np.mean(force_correlation_at_ndx, axis=0)\n\n\ndef _memory_kernel(\n    delta_force_array,\n    index=None,\n    ndx_resolution=None\n):\n    # Calculate correlation for each trajectory and each time step\n    # implement \\delta f(t) * delta f(t+dt)\n    N, length_data = delta_force_array.shape\n\n    if isinstance(index, int):\n        index = [index]\n    if index is not None and ndx_resolution is not None:\n        raise ValueError('Only index or ndx_resolution can be given.')\n    elif ndx_resolution is not None:\n        print('create index with ndx_resolution')\n        index = np.arange(\n            ndx_resolution,\n            length_data-1,\n            ndx_resolution,\n            dtype=int\n        )\n    elif np.any(np.array(index) &gt;= length_data):\n        raise ValueError('Index values must be less than length of data.')\n    elif np.any(np.array(index) &lt; 0):\n        raise ValueError('Index values must be non-negative.')\n    elif not isinstance(index, (list, np.ndarray)):\n        raise TypeError('Index must be an integer, list, or numpy array.')\n    \n    correlation_set = np.zeros((len(index), length_data))\n    for i, ndx in enumerate(index):\n        # Create a shifted version of delta_force_array for the given ndx\n        #shifted_array = np.roll(delta_force_array, -ndx, axis=1)\n\n        # Pad with zeros where the shift goes out of bounds\n        #shifted_array[:, -ndx:] = 0 \n\n        # Compute the correlation using NumPy's element-wise multiplication\n        correlation_set[i] = _kernel_at_ndx(delta_force_array, ndx)\n    return index, correlation_set\n\nindex, correlation_set = _memory_kernel(delta_force_array, ndx_resolution=1000)\n</pre> def _kernel_at_ndx(delta_force_array, ndx):     # this is how the correltaion is implemented in Steffens dcTMD script     # the correlation is evaluated a ficed point in time     delta_force_point = delta_force_array[:, ndx]     force_correlation_at_ndx = (delta_force_array.T * delta_force_point).T     return np.mean(force_correlation_at_ndx, axis=0)   def _memory_kernel(     delta_force_array,     index=None,     ndx_resolution=None ):     # Calculate correlation for each trajectory and each time step     # implement \\delta f(t) * delta f(t+dt)     N, length_data = delta_force_array.shape      if isinstance(index, int):         index = [index]     if index is not None and ndx_resolution is not None:         raise ValueError('Only index or ndx_resolution can be given.')     elif ndx_resolution is not None:         print('create index with ndx_resolution')         index = np.arange(             ndx_resolution,             length_data-1,             ndx_resolution,             dtype=int         )     elif np.any(np.array(index) &gt;= length_data):         raise ValueError('Index values must be less than length of data.')     elif np.any(np.array(index) &lt; 0):         raise ValueError('Index values must be non-negative.')     elif not isinstance(index, (list, np.ndarray)):         raise TypeError('Index must be an integer, list, or numpy array.')          correlation_set = np.zeros((len(index), length_data))     for i, ndx in enumerate(index):         # Create a shifted version of delta_force_array for the given ndx         #shifted_array = np.roll(delta_force_array, -ndx, axis=1)          # Pad with zeros where the shift goes out of bounds         #shifted_array[:, -ndx:] = 0           # Compute the correlation using NumPy's element-wise multiplication         correlation_set[i] = _kernel_at_ndx(delta_force_array, ndx)     return index, correlation_set  index, correlation_set = _memory_kernel(delta_force_array, ndx_resolution=1000)   <pre>create index with ndx_resolution\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n(18, 20001)\n</pre> In\u00a0[21]: Copied! <pre>correlation_set.shape\n</pre> correlation_set.shape Out[21]: <pre>(19, 20001)</pre> In\u00a0[25]: Copied! <pre>fig, ax = plt.subplots()\nfor (c, n) in zip(correlation_set, index):\n    plt.plot(c, label=f'x={forceset.position_[n]:.2f}')\nplt.legend()\nplt.show()\n</pre> fig, ax = plt.subplots() for (c, n) in zip(correlation_set, index):     plt.plot(c, label=f'x={forceset.position_[n]:.2f}') plt.legend() plt.show()  In\u00a0[33]: Copied! <pre># create a 3D plot with the lag time on the x axis\ndef forceforce_correlation_3dplot(index, correlation_set, position=None):\n    \"\"\"\n    Create a 3D plot of the force-force correlation function.\n    Parameters\n    ----------\n    index :\n        Indices at which the correlation is calculated.\n    correlation_set :\n        shape: (len(index), length_data)\n        NaN are set to zero\n    \"\"\"\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    ax.set_xlabel(r'$t$')\n    ax.set_ylabel(r'lag time $\\tau$')\n    ax.set_zlabel(r'$\\rangle\\delta f(t)\\delta f(\\tau)\\langle_N$')\n    for i, ndx in enumerate(index):\n        x = np.where(correlation_set[i]==0, np.nan, correlation_set[i])\n        y = np.arange(len(x))\n        if position is not None:\n            z = position[ndx]\n            ax.set_ylabel(r'$x$ [nm]')\n        else:\n            z = ndx\n        ax.plot(y, x, zs=z, zdir='y', label=f'lag {ndx}')\n    \n    ax.set_ylim(ax.get_ylim()[::-1])  # Reverse the y-axis limits\n        \n    #plt.legend()\n    plt.tight_layout()\n    plt.show()\n\nforceforce_correlation_3dplot(index, correlation_set, position=forceset.position_)\n\nforceforce_correlation_3dplot(index, correlation_set)\n</pre> # create a 3D plot with the lag time on the x axis def forceforce_correlation_3dplot(index, correlation_set, position=None):     \"\"\"     Create a 3D plot of the force-force correlation function.     Parameters     ----------     index :         Indices at which the correlation is calculated.     correlation_set :         shape: (len(index), length_data)         NaN are set to zero     \"\"\"     fig = plt.figure()     ax = fig.add_subplot(projection='3d')     ax.set_xlabel(r'$t$')     ax.set_ylabel(r'lag time $\\tau$')     ax.set_zlabel(r'$\\rangle\\delta f(t)\\delta f(\\tau)\\langle_N$')     for i, ndx in enumerate(index):         x = np.where(correlation_set[i]==0, np.nan, correlation_set[i])         y = np.arange(len(x))         if position is not None:             z = position[ndx]             ax.set_ylabel(r'$x$ [nm]')         else:             z = ndx         ax.plot(y, x, zs=z, zdir='y', label=f'lag {ndx}')          ax.set_ylim(ax.get_ylim()[::-1])  # Reverse the y-axis limits              #plt.legend()     plt.tight_layout()     plt.show()  forceforce_correlation_3dplot(index, correlation_set, position=forceset.position_)  forceforce_correlation_3dplot(index, correlation_set) In\u00a0[\u00a0]: Copied! <pre># visualize ACF\n# create a plot 1D plot for each index\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nfor i, ndx in enumerate(index):\n    ax.plot(autocorr_set[i], label=f'lag {ndx}')\n\nax.legend()\nplt.show()\n\n# create a 3D plot with the lag time on the x axis\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\nfor i, ndx in enumerate(index):\n    x = np.where(autocorr_set[i]==0, np.nan, autocorr_set[i])\n    y = np.arange(len(x))\n    z = ndx\n    ax.plot(y, x, zs=z, zdir='y', label=f'lag {ndx}')\n\nax.set_ylim(ax.get_ylim()[::-1])  # Reverse the y-axis limits\n\nax.set_xlabel(r'$t$')\nax.set_ylabel(r'lag time $\\tau$')\nax.set_zlabel('ACF')\n\nplt.legend()\nplt.show()\n</pre> # visualize ACF # create a plot 1D plot for each index  import matplotlib.pyplot as plt  fig, ax = plt.subplots() for i, ndx in enumerate(index):     ax.plot(autocorr_set[i], label=f'lag {ndx}')  ax.legend() plt.show()  # create a 3D plot with the lag time on the x axis fig = plt.figure() ax = fig.add_subplot(projection='3d') for i, ndx in enumerate(index):     x = np.where(autocorr_set[i]==0, np.nan, autocorr_set[i])     y = np.arange(len(x))     z = ndx     ax.plot(y, x, zs=z, zdir='y', label=f'lag {ndx}')  ax.set_ylim(ax.get_ylim()[::-1])  # Reverse the y-axis limits  ax.set_xlabel(r'$t$') ax.set_ylabel(r'lag time $\\tau$') ax.set_zlabel('ACF')  plt.legend() plt.show()  In\u00a0[56]: Copied! <pre># * autocorrelation function evaluation:\n#     * calculate $\\left&lt; \\delta f_c(t) \\delta f_c(t') \\right&gt;$ for $t$ at ndx\n\nN, length_data = delta_force_array.shape\ncorr_set1 = np.zeros((N,length_data))\ncorr_set2 = np.zeros((N,length_data))\nautocorr_set = np.zeros(length_data)\n\nresolution = 10\n\n\n\n\nindex = np.linspace(\n    resolution,\n    length_data-1,\n    resolution,\n    dtype=int\n)\n\n\nindex = [1, 1000, 10000]\n\ncorr_set1 = np.zeros((len(index),N,length_data))\ncorr_set2 = np.zeros((len(index),N,length_data))\nautocorr_set = np.zeros((len(index),length_data))\n\n\n\n\n\ndef _calc_acf(delta_force_array, ndx):\n    # Create a shifted version of delta_force_array for the given ndx\n    shifted_array = np.roll(delta_force_array, -ndx, axis=1)\n    # Pad with zeros where the shift goes out of bounds\n    shifted_array[:, -ndx:] = 0\n    # return the correlation using NumPy's element-wise multiplication\n    return delta_force_array * shifted_array\n\n\ndef _calc_correlation_set(delta_force_array, index=None, ndx_resolution=None):\n    # Calculate correlation for each trajectory and each time step\n    # implement \\delta f(t) * delta f(t+dt)\n    N, length_data = delta_force_array.shape\n    correlation_set = np.zeros((len(index), N, length_data))\n\n    if np.any(np.array(index) &gt;= length_data):\n        raise ValueError('Index values must be less than length of data.')\n    elif np.any(np.array(index) &lt; 0):\n        raise ValueError('Index values must be non-negative.')\n    # check if index is an np array or an integer\n    elif isinstance(index, int):\n        index = [index]\n    elif not isinstance(index, (list, np.ndarray)):\n        raise TypeError('Index must be an integer, list, or numpy array.')\n    # only index or ndx resolution can be given\n    elif len(index) &gt; 1 and ndx_resolution is not None:\n        raise ValueError('Only index or ndx_resolution can be given.')\n    elif ndx_resolution is not None:\n        index = np.linspace(\n            ndx_resolution,\n            length_data-1,\n            ndx_resolution,\n            dtype=int\n        )\n\n    for i, ndx in enumerate(index):\n        # Create a shifted version of delta_force_array for the given ndx\n        #shifted_array = np.roll(delta_force_array, -ndx, axis=1)\n\n        # Pad with zeros where the shift goes out of bounds\n        #shifted_array[:, -ndx:] = 0 \n\n        # Compute the correlation using NumPy's element-wise multiplication\n        correlation_set[i] = _calc_acf(delta_force_array, ndx)\n    return correlation_set\n\n# Calculate correlation for each trajectory and each time step\n# implement \\delta f(t) * delta f(t+dt) \nfig, ax = plt.subplots()\nfor i, ndx in enumerate(index):\n    # Create a shifted version of delta_force_array for the given ndx\n    shifted_array = np.roll(delta_force_array, -ndx, axis=1)\n    ax.plot(shifted_array[0], '--')\n    # Pad with zeros where the shift goes out of bounds\n    \n    shifted_array[:, -ndx:] = 0 \n    ax.plot(shifted_array[0], label=f'shifted ndx {ndx}')\n    # Compute the correlation using NumPy's element-wise multiplication\n    corr_set1[i] = delta_force_array * shifted_array\n\n    for n in range(N):\n        for j in range(length_data):\n            # Ensure we don't go out of bounds\n            if j + ndx &lt; length_data:\n                corr_set2[i, n, j] = delta_force_array[n, j] * delta_force_array[n, j + ndx]\n            else:\n                corr_set2[i, n, j] = 0  # Handle boundary by setting to 0 or another value\nplt.legend()\nplt.show()\n\ncorr_set1 = _calc_correlation_set(delta_force_array, index)\nprint(corr_set1.shape, corr_set2.shape)\n# plor correlation set for 10 trajectories and two lag times\nfig, ax = plt.subplots()\nfor n in range(2):\n    for lag in range(len(index)):\n        plt.plot(corr_set1[lag, n], label=f'corr_set1 lag {lag} ndx {n}')\n\n\nplt.legend()\nplt.show()\n\n# Example output\n#print(\"Correlation Set 1:\")\n#print(corr_set1)\n\n# calculate correlation for each trajectory and each time step\n# implement \\delta f(t) * delta f(t+dt) # how to do the boundaries\n\nif np.sum(corr_set1 - corr_set2) == 0:\n\n    print(\"Both methods give the same result.\")\nelse:\n    print(\"Methods give different results.\")\n    print(np.sum(corr_set1 - corr_set2))\n\n#for i in range(length_data):\n#    autocorr_set[i] = np.mean(corr_set1[:,i])\n#\n#autocorr_set2 = np.mean(corr_set2, axis=1)\n\nautocorr_set = np.mean(corr_set2, axis=1) / np.var(corr_set2, axis=1)\n\nautocorr_set.shape\n</pre> # * autocorrelation function evaluation: #     * calculate $\\left&lt; \\delta f_c(t) \\delta f_c(t') \\right&gt;$ for $t$ at ndx  N, length_data = delta_force_array.shape corr_set1 = np.zeros((N,length_data)) corr_set2 = np.zeros((N,length_data)) autocorr_set = np.zeros(length_data)  resolution = 10     index = np.linspace(     resolution,     length_data-1,     resolution,     dtype=int )   index = [1, 1000, 10000]  corr_set1 = np.zeros((len(index),N,length_data)) corr_set2 = np.zeros((len(index),N,length_data)) autocorr_set = np.zeros((len(index),length_data))      def _calc_acf(delta_force_array, ndx):     # Create a shifted version of delta_force_array for the given ndx     shifted_array = np.roll(delta_force_array, -ndx, axis=1)     # Pad with zeros where the shift goes out of bounds     shifted_array[:, -ndx:] = 0     # return the correlation using NumPy's element-wise multiplication     return delta_force_array * shifted_array   def _calc_correlation_set(delta_force_array, index=None, ndx_resolution=None):     # Calculate correlation for each trajectory and each time step     # implement \\delta f(t) * delta f(t+dt)     N, length_data = delta_force_array.shape     correlation_set = np.zeros((len(index), N, length_data))      if np.any(np.array(index) &gt;= length_data):         raise ValueError('Index values must be less than length of data.')     elif np.any(np.array(index) &lt; 0):         raise ValueError('Index values must be non-negative.')     # check if index is an np array or an integer     elif isinstance(index, int):         index = [index]     elif not isinstance(index, (list, np.ndarray)):         raise TypeError('Index must be an integer, list, or numpy array.')     # only index or ndx resolution can be given     elif len(index) &gt; 1 and ndx_resolution is not None:         raise ValueError('Only index or ndx_resolution can be given.')     elif ndx_resolution is not None:         index = np.linspace(             ndx_resolution,             length_data-1,             ndx_resolution,             dtype=int         )      for i, ndx in enumerate(index):         # Create a shifted version of delta_force_array for the given ndx         #shifted_array = np.roll(delta_force_array, -ndx, axis=1)          # Pad with zeros where the shift goes out of bounds         #shifted_array[:, -ndx:] = 0           # Compute the correlation using NumPy's element-wise multiplication         correlation_set[i] = _calc_acf(delta_force_array, ndx)     return correlation_set  # Calculate correlation for each trajectory and each time step # implement \\delta f(t) * delta f(t+dt)  fig, ax = plt.subplots() for i, ndx in enumerate(index):     # Create a shifted version of delta_force_array for the given ndx     shifted_array = np.roll(delta_force_array, -ndx, axis=1)     ax.plot(shifted_array[0], '--')     # Pad with zeros where the shift goes out of bounds          shifted_array[:, -ndx:] = 0      ax.plot(shifted_array[0], label=f'shifted ndx {ndx}')     # Compute the correlation using NumPy's element-wise multiplication     corr_set1[i] = delta_force_array * shifted_array      for n in range(N):         for j in range(length_data):             # Ensure we don't go out of bounds             if j + ndx &lt; length_data:                 corr_set2[i, n, j] = delta_force_array[n, j] * delta_force_array[n, j + ndx]             else:                 corr_set2[i, n, j] = 0  # Handle boundary by setting to 0 or another value plt.legend() plt.show()  corr_set1 = _calc_correlation_set(delta_force_array, index) print(corr_set1.shape, corr_set2.shape) # plor correlation set for 10 trajectories and two lag times fig, ax = plt.subplots() for n in range(2):     for lag in range(len(index)):         plt.plot(corr_set1[lag, n], label=f'corr_set1 lag {lag} ndx {n}')   plt.legend() plt.show()  # Example output #print(\"Correlation Set 1:\") #print(corr_set1)  # calculate correlation for each trajectory and each time step # implement \\delta f(t) * delta f(t+dt) # how to do the boundaries  if np.sum(corr_set1 - corr_set2) == 0:      print(\"Both methods give the same result.\") else:     print(\"Methods give different results.\")     print(np.sum(corr_set1 - corr_set2))  #for i in range(length_data): #    autocorr_set[i] = np.mean(corr_set1[:,i]) # #autocorr_set2 = np.mean(corr_set2, axis=1)  autocorr_set = np.mean(corr_set2, axis=1) / np.var(corr_set2, axis=1)  autocorr_set.shape  <pre>(3, 18, 20001) (3, 18, 20001)\n</pre> <pre>Both methods give the same result.\n</pre> <pre>/tmp/ipykernel_1242057/230722564.py:129: RuntimeWarning: invalid value encountered in divide\n  autocorr_set = np.mean(corr_set2, axis=1) / np.var(corr_set2, axis=1)\n</pre> Out[56]: <pre>(3, 20001)</pre> In\u00a0[55]: Copied! <pre># let's try with np.correlate\nprint(delta_force_array.shape)\nacf = np.correlate(delta_force_array[0], delta_force_array[0], mode='same')\nprint(acf)\nprint(acf.shape)\nfig,ax = plt.subplots()\nplt.plot(delta_force_array[0], label='data')\n#plt.plot(acf)\n\nfrom scipy import signal\ncorr = signal.correlate(delta_force_array[0], delta_force_array[0])\ncorr /= np.max(corr)\nlags = signal.correlation_lags(len(delta_force_array[0]), len(delta_force_array[0]))\nplt.plot(lags, corr)\n</pre> # let's try with np.correlate print(delta_force_array.shape) acf = np.correlate(delta_force_array[0], delta_force_array[0], mode='same') print(acf) print(acf.shape) fig,ax = plt.subplots() plt.plot(delta_force_array[0], label='data') #plt.plot(acf)  from scipy import signal corr = signal.correlate(delta_force_array[0], delta_force_array[0]) corr /= np.max(corr) lags = signal.correlation_lags(len(delta_force_array[0]), len(delta_force_array[0])) plt.plot(lags, corr)  <pre>(18, 20001)\n[-5000.         -4999.99975326 -4999.99901294 ... -4999.99901294\n -4999.99975326 -5000.        ]\n(20001,)\n</pre> Out[55]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f79e1caff90&gt;]</pre> In\u00a0[13]: Copied! <pre># visualize ACF\n# create a plot 1D plot for each index\n\nimport matplotlib.pyplot as plt\n\nfig, ax = plt.subplots()\nfor i, ndx in enumerate(index):\n    ax.plot(autocorr_set[i], label=f'lag {ndx}')\n\nax.legend()\nplt.show()\n\n# create a 3D plot with the lag time on the x axis\nfig = plt.figure()\nax = fig.add_subplot(projection='3d')\nfor i, ndx in enumerate(index):\n    x = np.where(autocorr_set[i]==0, np.nan, autocorr_set[i])\n    y = np.arange(len(x))\n    z = ndx\n    ax.plot(y, x, zs=z, zdir='y', label=f'lag {ndx}')\n\nax.set_ylim(ax.get_ylim()[::-1])  # Reverse the y-axis limits\n\nax.set_xlabel(r'$t$')\nax.set_ylabel(r'lag time $\\tau$')\nax.set_zlabel('ACF')\n\nplt.legend()\nplt.show()\n</pre> # visualize ACF # create a plot 1D plot for each index  import matplotlib.pyplot as plt  fig, ax = plt.subplots() for i, ndx in enumerate(index):     ax.plot(autocorr_set[i], label=f'lag {ndx}')  ax.legend() plt.show()  # create a 3D plot with the lag time on the x axis fig = plt.figure() ax = fig.add_subplot(projection='3d') for i, ndx in enumerate(index):     x = np.where(autocorr_set[i]==0, np.nan, autocorr_set[i])     y = np.arange(len(x))     z = ndx     ax.plot(y, x, zs=z, zdir='y', label=f'lag {ndx}')  ax.set_ylim(ax.get_ylim()[::-1])  # Reverse the y-axis limits  ax.set_xlabel(r'$t$') ax.set_ylabel(r'lag time $\\tau$') ax.set_zlabel('ACF')  plt.legend() plt.show()  In\u00a0[14]: Copied! <pre># plot dcTMD results\nfrom dcTMD.utils import plotting\n\nfig, axs = plotting.plot_dcTMD_results(forceestimator)\n\nplt.show()\n</pre> # plot dcTMD results from dcTMD.utils import plotting  fig, axs = plotting.plot_dcTMD_results(forceestimator)  plt.show() In\u00a0[15]: Copied! <pre># smooth friction and plot results\nforceestimator.smooth_friction(sigma=0.1)\n\n# if the friction is smoothed that value is automatically plotted\nfig, axs = plotting.plot_dcTMD_results(forceestimator)\nplt.show()\n\n# but one can also specify the friction\n#fig, axs = plotting.plot_dcTMD_results(\n#    forceestimator,\n#    friction=forceestimator.friction_\n#)\n</pre> # smooth friction and plot results forceestimator.smooth_friction(sigma=0.1)  # if the friction is smoothed that value is automatically plotted fig, axs = plotting.plot_dcTMD_results(forceestimator) plt.show()  # but one can also specify the friction #fig, axs = plotting.plot_dcTMD_results( #    forceestimator, #    friction=forceestimator.friction_ #)   <p>Using different smoothing windows and modes changes the results significantly. Because of the different boundary handling in the modes. mode='nearest' leads to an overestimation at the right hand boarder (end of the simulation), while mode='reflect' leads to a wash out of the boarder on the left hand side.</p> <p>Here, are some examples:</p> In\u00a0[16]: Copied! <pre>fig, axs = plt.subplots()\n\nx = forceestimator.position_\nplotting.plot_Gamma(x,\n                    forceestimator.friction_smooth_,\n                    axs,\n                    label='default (reflect) 0.1nm'\n                    )\n\n# using different smoothing windows and modes changes the results significantly\nsmooth_friction = dcTMD.utils.gaussfilter_friction(forceestimator.friction_,\n                                                   x,\n                                                   sigma=.01,\n                                                   mode='reflect',\n                                                   )\naxs.plot(x, smooth_friction, label='reflect .01nm')\nsmooth_friction = dcTMD.utils.gaussfilter_friction(forceestimator.friction_,\n                                                   x,\n                                                   sigma=.01, \n                                                   mode='nearest',\n                                                   )\naxs.plot(x, smooth_friction, label='nearest .01nm')\nsmooth_friction = dcTMD.utils.gaussfilter_friction(forceestimator.friction_,\n                                                   x,\n                                                   sigma=0.2,\n                                                   mode='reflect',\n                                                   )\n                                                   \naxs.plot(x, smooth_friction, label='reflect .2nm')\naxs.legend()\n\nplt.show()\n</pre> fig, axs = plt.subplots()  x = forceestimator.position_ plotting.plot_Gamma(x,                     forceestimator.friction_smooth_,                     axs,                     label='default (reflect) 0.1nm'                     )  # using different smoothing windows and modes changes the results significantly smooth_friction = dcTMD.utils.gaussfilter_friction(forceestimator.friction_,                                                    x,                                                    sigma=.01,                                                    mode='reflect',                                                    ) axs.plot(x, smooth_friction, label='reflect .01nm') smooth_friction = dcTMD.utils.gaussfilter_friction(forceestimator.friction_,                                                    x,                                                    sigma=.01,                                                     mode='nearest',                                                    ) axs.plot(x, smooth_friction, label='nearest .01nm') smooth_friction = dcTMD.utils.gaussfilter_friction(forceestimator.friction_,                                                    x,                                                    sigma=0.2,                                                    mode='reflect',                                                    )                                                     axs.plot(x, smooth_friction, label='reflect .2nm') axs.legend()  plt.show() In\u00a0[17]: Copied! <pre># save forceestimator instance\n# dcTMD.storing.save('my_forceestimator', forceestimator)\n\n# save data as .npz and .dat file\noutname = 'my_forceestimator_results'\ndcTMD.io.write_output(outname, forceestimator)\n\nresults = np.load(f'{outname}_N{len(forceestimator.names_)}_dG.npz')\n\nresults.files\n</pre> # save forceestimator instance # dcTMD.storing.save('my_forceestimator', forceestimator)  # save data as .npz and .dat file outname = 'my_forceestimator_results' dcTMD.io.write_output(outname, forceestimator)  results = np.load(f'{outname}_N{len(forceestimator.names_)}_dG.npz')  results.files <pre>save file my_forceestimator_results_N18.dat\nsave file my_forceestimator_results_N18.npz\n</pre> <pre>\n---------------------------------------------------------------------------\nFileNotFoundError                         Traceback (most recent call last)\nCell In[17], line 8\n      5 outname = 'my_forceestimator_results'\n      6 dcTMD.io.write_output(outname, forceestimator)\n----&gt; 8 results = np.load(f'{outname}_N{len(forceestimator.names_)}_dG.npz')\n     10 results.files\n\nFile ~/anaconda3/envs/dcTMD/lib/python3.11/site-packages/numpy/lib/npyio.py:427, in load(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\n    425     own_fid = False\n    426 else:\n--&gt; 427     fid = stack.enter_context(open(os_fspath(file), \"rb\"))\n    428     own_fid = True\n    430 # Code to distinguish from NumPy binary files and pickles.\n\nFileNotFoundError: [Errno 2] No such file or directory: 'my_forceestimator_results_N18_dG.npz'</pre>"},{"location":"tutorials/force_memorytest/#introduction","title":"Introduction\u00b6","text":"<p>Another option to directly analyze the constraint force time traces, is to calculate $\\Delta G$ on-the-fly starting from the friction estimate ${\\it{\\Gamma}}$ which is calculated from the force $f_c(t)$ auto correlation via:</p> <p>$$ \\begin{align} \\Gamma &amp;= \\beta \\int_{0}^{t} \\text{d}\\tau \\left&lt;\\delta f_c(t)\\delta f_c(t-\\tau)\\right&gt;_\\text{N},\\\\ \\Delta G(s) &amp;= - v_c\\int_{s_0}^{s} \\text{d}s' \\Gamma(s') + \\int_{s_0}^{s} \\text{d}s' \\left&lt;f_c(s')\\right&gt;_\\text{N} \\end{align} $$</p> <p>This approach is computionally more demanding, since the full resolution of the force time traces is needed to determine friction and free energy estimates. Therefore, we advise the use of the WorkEstimator class, which is computationally less demanding, since it does not require the full resolution of the force time traces.</p>"},{"location":"tutorials/force_memorytest/#workflow","title":"Workflow:\u00b6","text":""},{"location":"tutorials/force_memorytest/#0-load-packages-and-define-variables","title":"0. load packages and define variables\u00b6","text":""},{"location":"tutorials/force_memorytest/#i-create-forceset","title":"I. create forceset\u00b6","text":"<p>To calculate free energy and friction estimates a forceset containing all the force time traces is needed.</p> <ol> <li>an array containing the filenames is generated. This can be done via the function dcTMD.io.load_pullf() which takes either a glob pattern or a file containing the pullf file names as argument.</li> </ol>"},{"location":"tutorials/force_memorytest/#ii-check-normality-of-work-distribution","title":"II. check normality of work distribution\u00b6","text":"<p>One of the main conditions which need to be fulfilled for dcTMD is a normally distributed work.</p> <p>This can be checked via different methods. e.g. plotting the work time traces, normality checks at different x positions, Kolmogorov-Smirnov Test, Shapiro-Wilk Test, Anderson-Darling Test,</p> <p>CAUTION: if the work distribution is not normal you results are compromised. And a path separation is necessary. For the theory on path separation see...</p>"},{"location":"tutorials/force_memorytest/#iii-derive-estimates-from-forceset","title":"III. derive estimates from forceset\u00b6","text":"<ol> <li>create ForceEstimator instance</li> <li>fit ForceEstimator instance with previously created forceset</li> </ol>"},{"location":"tutorials/force_memorytest/#visualize-results","title":"Visualize results\u00b6","text":"<p>In the package a couple of simple plot functions to get an overview of the results are implemented. e.g. plot_dcTMD_results()</p>"},{"location":"tutorials/force_memorytest/#smooth-friction-estimate","title":"Smooth friction estimate\u00b6","text":"<p>Finally, the friction estimate needs to be smoothed. This can be done via dcTMD.utils.smoothing.gaussfilter_friction() or dcTMD.WorkEstimator.smooth_friction(sigma, mode) sigma is the standard deviation of gaussian kernel in nm the mode parameter determines how the input array is extended beyond its boundaries.</p> <p>Caution: this can lead to long computations using large datasets and a big smoothing window.</p>"},{"location":"tutorials/force_memorytest/#iv-save-and-load-results","title":"IV. Save and load results\u00b6","text":""},{"location":"tutorials/theory/","title":"Targeted MD Simulations","text":"<p>For accelerated sampling of rare events, biased simulation methods have been developed. One particular method is targeted MD developed Schlitter et al. 1994. Here, a constraint is applied to a subset of atoms to move it towards a target conformation along a predescribed one-dimensional path in conformational space with constant velocity \\(v_c\\) from \\(s_0 (t=0)\\) to \\(s (t=t_f)\\)  along the pulling coordinate \\(s(t)=s_0+v_{c}t\\). The corresponding constraint function is</p> \\[  \\Phi(s(t)) = \\left( s(t) -(s_0 + v_0 t) \\right) = 0. \\] <p>The necessary constraint force \\(f_c\\), </p> \\[  f_c = \\lambda \\frac{\\mathrm{d} \\Phi(s(t))}{\\mathrm{d}s} = \\lambda \\] <p>added through a Lagrangian-multiplier \u03bb to the equation of motion, is stored to compute the work \\(W(s)=\\int_{s_0}^{s} f_c(s')\\; ds' \\geq\\Delta G\\) needed to move the atom, or subset of atoms, along the pulling coordinate.</p>"},{"location":"tutorials/theory/#jarzynskis-equality","title":"Jarzynski's Equality","text":"<p>An approach to estimate \u2206G for finite switching times was proposed by Jarzynski. It is possible to calculate the free energy directly from a thermostatted system in equilibrium that is driven away from equilibrium (e.g. in non-equilibrium pulling trajectories) along a pulling coordinate \\(s(t)\\) via</p> \\[ \\tag{1} e^{-\\beta\\Delta G(s)} = \\left&lt; e^{-\\beta W(s)} \\right&gt;_\\text{N}. \\] <p>Here \\(\\Delta G\\) denotes the Gibbs free energy, \\(\\left&lt; \\cdot  \\right&gt;_\\text{N}\\) denotes an ensemble average over independent pulling trajectories starting from an initial Boltzmann distribution. The original formulation of Eq. (1) is for an NVT ensemble predicting the Helmholtz free energy \\(\\Delta F\\) instead of \\(\\Delta G\\) and was later generalized for NPT ensembles (see Park et al. 2004). </p> <p>Equation (1) allows to directly calculate the free energy profile from biased simulations. However, the exponential average relies on sufficient sampling of the small values of the work distribution, which occur only rarely. Thus, in practice a large number of non-equilibrium trajectories is required, due to the slow and erratic convergence of the exponential average. This problem can be approached by a cumulant expansion:</p> \\[  \\Delta G(s) = \\left&lt; W(s) \\right&gt;_\\text{N} -\\frac{\\beta}{2}\\left&lt;\\delta W(s)^2\\right&gt;_\\text{N} + h.o.t.  \\tag{2} \\] <p>with \\(\\delta W(s) = W(s) -\\left&lt; W(s) \\right&gt;_\\text{N}\\).  The expansion can (only) be truncated at second order if the work distribution is Gaussian. This allows to formulate the dissipated work </p> \\[  W_{\\text{diss}}(s) = \\frac{\\beta}{2}\\left&lt; \\delta W(s)^2 \\right&gt;_\\text{N} \\] <p>in terms of the variance of the work.</p>"},{"location":"tutorials/theory/#dissipation-corrected-tmd","title":"Dissipation-Corrected TMD","text":"<p>A method developed by Wolf and Stock combines Langevin dynamics with the second order cumulant expansion given in Eq. (2). It evaluates \\(\\Delta G(s)\\) as well as a non-equilibrium friction coefficient \\(\\Gamma_\\text{N}\\) directly from TMD trajectories and is called dissipation-corrected TMD (dcTMD).</p> <p>As stated before, in TMD simulations a constraint force \\(f_c\\) is applied to the system. We assume that \\(f_c\\) does not change the Langevin fields \\(f\\), \\(\\Gamma\\), and \\(K\\) and make the ansatz that \\(f_c\\) can be simply included as an additive term in the memory free Langevin equation. This yields:</p> \\[  m \\ddot{s}(t) = - \\frac{\\text{d}G}{\\text{d}s} - \\Gamma(s)\\dot{s} + K(s)\\xi(t) + f_c(t). \\tag{3} \\] <p>To keep the velocity constant, \\(f_c(t)\\) needs to counter al occurring forces, thus</p> \\[  m \\ddot{s}(t)=0. \\] <p>This, however, only holds if the following requirements on the constraint force \\(f_c\\) are fulfilled: first, \\(v_c\\) is kept constant against the drag of the friction \\(\\Gamma(s)\\) and the acceleration due to the free energy gradient; second, \\(f_c\\) counterbalances the effect of the stochastic force \\(K(s)\\xi(t).\\)</p> <p>The first requirement is fulfilled if \\(v_c\\) is slow compared to the bath fluctuations. Then the pulling can be considered as a slow adiabatic change and the system is virtually in equilibrium at every point along \\(s\\). </p> <p>The second requirement is harder to satisfy, since \\(f_c\\) and the bath fluctuations necessarily occur in the same time scales. When considering an ensemble of TMD trajectories instead of a single trajectory the stochastic term cancels out by definition. Thus, performing an ensemble average of Eq. (3) over a set of trajectories one obtains:</p> \\[     \\frac{\\text{d}G}{\\text{d}s} = -\\Gamma(s)v_c + \\left&lt;\\delta f_c(s)\\right&gt;_\\text{N} \\] <p>by making use of \\(\\left&lt; \\xi \\right&gt;_\\text{N}=0\\) and \\(\\left&lt; \\dot{s} \\right&gt;_\\text{N}=v_c\\). Integrating on both sides from the initial state \\(s_0\\) to final state \\(s\\) gives:</p> \\[ \\begin{align}     \\Delta G(s) &amp;= - v_c\\int_{s_0}^{s} \\text{d}s' \\Gamma(s') + \\int_{s_0}^{s} \\text{d}s' \\left&lt;f_c(s')\\right&gt;_\\text{N} \\\\                 &amp;=  - W_\\mathrm{diss}(s) + \\left&lt;W(s)\\right&gt;_\\text{N}  \\end{align}  \\tag{4} \\] <p>where the first term describes the dissipated work of the process in terms of the friction \\(\\Gamma\\) and the second term corresponds to the average external work carried out on the system.</p> <p>With this, the dissipated work</p> \\[ \\begin{align}     W_\\text{diss} &amp;= \\frac{\\beta}{2} \\left&lt;\\left(\\int_{s_0}^{s} \\delta f_c (s) \\text{d}s\\right)^2\\right&gt;_\\text{N}\\\\     &amp;= \\beta \\int_{s_0}^{s} \\text{d}s_2 \\int_{s_0}^{s_2} \\text{d}s_1 \\left&lt;\\delta f_c (s_2) \\delta f_c (s_1)\\right&gt;_\\text{N},\\\\ \\end{align} \\] <p>with the force \\(\\delta f_c = f_c - \\left&lt;f_c\\right&gt;\\), can be  compared with Eq. (4), suggesting that the NEQ friction term \\(\\Gamma\\) can be expressed by</p> \\[ \\begin{align}     \\Gamma &amp;= \\frac{\\beta}{v_c} \\int_{s_0}^{s} \\text{d}s_1 \\left&lt;\\delta f_c (s) \\delta f_c (s_1)\\right&gt;_\\text{N} \\\\     &amp;= \\beta \\int_{0}^{t} \\text{d}\\tau \\left&lt;\\delta f_c(t)\\delta f_c(t-\\tau)\\right&gt;_\\text{N}, \\end{align} \\tag{5} \\] <p>where a substitution of variables was performed using \\(s_1 = s_0 + v_c t'\\) and \\(\\tau = t - t'\\). Thus, a non-equilibrium friction correction is obtained </p> <ol> <li> <p>under the assumption of a Gaussian work distribution, which determines the friction arising from a set of TMD simulations</p> </li> <li> <p>pulled with constant mean velocity \\(v_c\\) along a reaction coordinate \\(s\\).</p> </li> </ol> <p>Equation (5) has a similar form to the well known friction expression in equilibrium</p> \\[     \\Gamma(s)_{\\text{EQ}} = \\beta \\int_{0}^{\\infty} \\left&lt;\\delta f_c(t)\\delta f_c(0)\\right&gt;_{\\text{EQ},s} \\text{d}t ~. \\] <p>For further reading on langevin equations see, e.g., Zwanzig 2001</p>"},{"location":"tutorials/theory/#classes-calculating-the-dctmd-quantities","title":"Classes calculating the dcTMD quantities","text":"<p>There are two ways to calculate the dcTMD quantities \\(\\Delta G\\) and \\(\\Gamma\\). </p>"},{"location":"tutorials/theory/#workestimator","title":"WorkEstimator","text":"<p>One way to analyze non-equilibrium force time traces from constraint pulling simulations is via Eq. (2). The expansion can be truncated at second order if the work distribution is Gaussian. So the free energy and friction estimates are calculated form work time traces via:</p> \\[ \\begin{align} \\Delta G(s) &amp;=  \\left&lt; W(s) \\right&gt;_\\text{N} -\\frac{\\beta}{2}\\left&lt;\\delta W(s)^2\\right&gt;_\\text{N} \\\\             &amp;=  \\left&lt;W(s)\\right&gt;_\\text{N} - W_\\text{diss}(s),\\\\ \\Gamma &amp;= \\frac{1}{v_c}\\frac{dW_\\text{diss}(s)}{ds} \\end{align} \\] <p>This approach is implemented in the <code>WorkEstimator</code> class and computationally more efficient than calculating the force auto-correlation function (which is implemented in the <code>ForceEstimator</code> class), because the class works with the work data via the integration of the force time traces. This allows to reduce the resolution significantly while gaining the same results.</p> <p>Therefore, we recommend to use this approach for large datasets. </p>"},{"location":"tutorials/theory/#forceestimator","title":"ForceEstimator","text":"<p>Another option to analyze non-equilibrium force time traces from constraint pulling simulations is by starting from the friction estimate via the force \\(f_c(t)\\) auto correlation:</p> \\[ \\begin{align} \\Gamma &amp;= \\beta \\int_{0}^{t} \\text{d}\\tau \\left&lt;\\delta f_c(t)\\delta f_c(t-\\tau)\\right&gt;_\\text{N},\\\\ \\Delta G(s) &amp;= - v_c\\int_{s_0}^{s} \\text{d}s' \\Gamma(s') + \\int_{s_0}^{s} \\text{d}s' \\left&lt;f_c(s')\\right&gt;_\\text{N} \\end{align} \\] <p>This approach is implemented in the <code>ForceEstimator</code> class and is computationally more demanding, since the full resolution of the force time traces is needed to determine friction and free energy estimates.</p>"},{"location":"tutorials/theoryMP/","title":"Targeted Molecular Dynamics","text":"<p>In order to study the dynamics of biomolecular processes by computer simulation, biased simulation methods have been developed that can accelerate the sampling of otherwise rare events. One such method is Targeted Molecular Dynamics (TMD) developed by Schlitter et al. 1994. In the specific implementation of TMD of this software package, a constraint is applied on the distance \\(x\\) between two subsets of atoms, moving them with constant velocity \\(v\\) from an initial state \\((x)\\) along the pulling coordinate towards a target conformation. This constraint,</p> \\[ \\Phi(x,t) =  x-(x_0 + v t)  = 0 \\, , \\] <p>modifies the equation of motion of the \\(K\\) atoms \\(\\mathbf{r}=(\\mathbf{r}_1,\\dots,\\mathbf{r}_K)\\) bound by the potential \\(U(\\mathbf{r})\\) by an additional constraint force term</p> \\[  m_i \\ddot{\\mathbf{r}}_i = - \\frac{\\partial U}{\\partial \\mathbf{r}} + f \\frac{\\partial \\Phi}{\\partial \\mathbf{r}} \\; , \\] <p>that is, the constraint force \\(f\\) on \\(s\\) is given by the Lagrange multiplier which in practice is calculated via the SHAKE algorithm (Ryckaert et al. 1977). The constraint forces are then used to compute the work</p> \\[ W(x)=\\int_{x_0}^{x}  \\mathrm{d} x'  \\; f(x') \\] <p>done to move the atom, or subset of atoms, along the pulling coordinate. Note that in the follwing we use the notations \\(f(x) \\equiv f(t(x))\\) interchangeable. </p>"},{"location":"tutorials/theoryMP/#jarzynskis-equality","title":"Jarzynski's Equality","text":"<p>In order to obtain equilibrium estimates, such as the free energy profile \\(\\Delta G\\) along the pulling coordinate \\(s\\), from the non-equilibrium simulations described above, we use the method proposed by Jarzynski 2004. While for finite pulling times, the average work \\(\\left&lt;W(x)\\right&gt;\\) is always higher that \\(\\Delta G = G(x)-G(x_0)\\), it is also possible to give an exact relation between the work and free energy, namely</p> \\[ \\begin{align} \\mathrm{e}^{-\\beta\\Delta G(x)} = \\left&lt; \\mathrm{e}^{-\\beta W(x)} \\right&gt;.  \\end{align} \\] <p>\\(\\left&lt; A  \\right&gt;\\) denotes an ensemble average of some function of the atoms positions \\(\\mathbf{r}\\) and momenta \\(\\mathbf{p}\\) over independent pulling trajectories starting from an initial Boltzmann distribution at fixed \\(s\\), i.e.,</p> \\[ \\begin{align*}     \\left&lt; A  \\right&gt; &amp;= \\frac{1}{\\int  \\mathrm{d} \\mathbf{r}_0  \\mathrm{d} \\mathbf{p}_0 \\,  \\mathrm{e}^{-\\beta H(\\mathbf{r}_0,\\mathbf{p}_0,0)}} \\int  \\mathrm{d} \\mathbf{r}_0  \\mathrm{d} \\mathbf{p}_0 \\, A(\\mathbf{r}_0,\\mathbf{p}_0,t) \\; \\mathrm{e}^{-\\beta H(\\mathbf{r}_0,\\mathbf{p}_0,0)}\\\\     &amp;\\approx \\frac{1}{\\mathtt{N}} \\sum_{\\mathtt{i}=1}^{\\mathtt{N}} A_\\mathtt{i} \\; , \\end{align*}  \\] <p>where \\(\\beta^{-1} = \\mathrm{k}_\\mathrm{B} T\\) is the inverse temperature and \\(H\\) the time-dependent Hamiltonian. \\(\\Delta G\\) denotes the Gibbs free energy. While the original formulation of Eq. (1) was proved for an NVT ensemble predicting the Helmholtz free energy \\(\\Delta F\\), it was later generalized for NPT ensembles (see Park et al. 2004). </p> <p>For a finite sample of \\(\\mathtt{N}\\) pulling trajectories, the bottom equation, a sample average, can be used. The exponential average, however, highly relies on a sufficient sampling of the small values of the work distribution, which occur only rarely. Thus, in practice a large \\(\\mathtt{N}\\) of non-equilibrium trajectories is required due to the slow convergence of the otherwise biased exponential average. This problem can be approached by a cumulant expansion:</p> \\[ \\begin{align} \\Delta G(x) = \\left&lt; W(x) \\right&gt; -\\frac{\\beta}{2}\\left&lt;\\delta W(x)^2\\right&gt; + \\dots \\end{align}  \\] <p>with \\(\\delta W = W -\\left&lt; W\\right&gt;\\). The expansion can be truncated at second order if the work distribution is Gaussian. In this case, the average dissipated work \\(W_{\\text{diss}}\\) is given entirely by the variance, i.e.,</p> \\[  \\left&lt;W_{\\text{diss}}(x)\\right&gt; = \\frac{\\beta}{2}\\left&lt; \\delta W(x)^2 \\right&gt; \\; . \\]"},{"location":"tutorials/theoryMP/#dissipation-corrected-tmd","title":"Dissipation-Corrected TMD","text":"<p>A method developed by Wolf, Stock 2018 called dissipation-corrected TMD (dcTMD) combines Langevin dynamics (see, e.g., Zwanzig 2001) with the second order cumulant expansion given in Eq. (2). It evaluates \\(\\Delta G\\) as well as a non-equilibrium friction coefficient \\({\\it{\\Gamma}}\\) directly from TMD simulations.</p> <p>Here, the memory-free Langevin equation models the dynamics projected to a small set of coordinates, here the motion of the distance \\(s\\), in terms of the mean force \\(\\frac{\\partial G}{\\partial x}\\), friction \\({\\it{\\Gamma}}\\) and fluctuations \\(\\xi\\), as well as the applied constraint force, as</p> \\[   \\begin{align} m \\ddot{x}= - \\frac{\\partial G}{\\partial x} - {\\it{\\Gamma}}(x)\\,\\dot{x} + \\xi(t) + f(t) \\quad ( = 0 ). \\end{align} \\] <p>\\(m\\) is the reduced mass of the two atom subsets. This approach assumes that \\(f_c\\) does not change the Langevin fields \\(G\\), \\({\\it{\\Gamma}}\\), and the noise \\(\\xi\\) and makes the ansatz, that \\(f\\) can be simply included as an additive term. </p> <p>When considering an ensemble of TMD trajectories instead of a single one, the stochastic term in Eq. (3) cancels out, \\(\\left&lt; \\xi \\right&gt;=0\\). Together with \\(\\dot{x}=v\\), integrating on both sides from the initial state \\(x_0\\) to final state \\(s\\) gives</p> \\[ \\begin{align}     \\Delta G(x) &amp;= \\int_{x_0}^{x}  \\text{d}x' \\left&lt;f(x')\\right&gt; - v \\int_{x_0}^{x}  \\text{d}x' \\; {\\it{\\Gamma}}(x')   \\end{align} \\] <p>where the first term corresponds to the average external work done on the system and the second term describes the dissipated work of the process in terms of the friction \\({\\it{\\Gamma}}\\). Evaluating the latter,</p> \\[ \\begin{align*}     \\left&lt;W_\\text{diss}\\right&gt; &amp;= \\frac{\\beta}{2} \\left&lt;\\left(\\int_{x_0}^{x} \\mathrm{d}x^\\prime \\delta f(x') \\right)^2\\right&gt;\\\\     &amp;= \\beta \\int_{x_0}^{x}  \\text{d}x^\\prime \\int_{x_0}^{x^\\prime}  \\text{d}x^{\\prime\\prime} \\left&lt;\\delta f(x^{\\prime\\prime}) \\delta f (x^{\\prime})\\right&gt; \\; ,\\\\ \\end{align*} \\] <p>provides a connection between the dissipated work and the friction,</p> \\[ \\begin{align}  {\\it{\\Gamma}}(x) &amp;= \\frac{1}{v}\\frac{\\mathrm{d} W_\\text{diss}}{\\mathrm{d} x} \\\\ &amp;= \\beta \\int_{0}^{t(x)} \\text{d}\\tau \\left&lt;\\delta f(t(x))\\delta f(\\tau)\\right&gt;  \\; , \\end{align} \\] <p>assuming a Gaussian work distribution.</p>"},{"location":"tutorials/theoryMP/#what-next","title":"What next?","text":"<p>create pulling trajectories with GROMACS</p> <p>calculating dcTMD quantities via work</p> <p>calculating dcTMD quantities via force</p>"},{"location":"tutorials/work/","title":"dcTMD via Work","text":"In\u00a0[1]: Copied! <pre># load packages\nimport numpy as np\nimport dcTMD\nfrom dcTMD.storing import WorkSet\nfrom dcTMD.dcTMD import WorkEstimator\n</pre> # load packages import numpy as np import dcTMD from dcTMD.storing import WorkSet from dcTMD.dcTMD import WorkEstimator In\u00a0[2]: Copied! <pre># define variables\nvelocity = 0.001\nres = 1\nverbose = True\ntemperature = 300\n</pre> # define variables velocity = 0.001 res = 1 verbose = True temperature = 300  In\u00a0[3]: Copied! <pre>pullf_files = '../../tests/testdata/pullf_filenames.dat'\npullf_files = '../../tests/testdata/*pullf.xvg'\nfilenames = dcTMD.io.load_pullf(pullf_files)\n\nfilenames\n</pre> pullf_files = '../../tests/testdata/pullf_filenames.dat' pullf_files = '../../tests/testdata/*pullf.xvg' filenames = dcTMD.io.load_pullf(pullf_files)  filenames  <pre>file ../../tests/testdata/*pullf.xvg not found. using glob.glob(../../tests/testdata/*pullf.xvg)\n</pre> Out[3]: <pre>['../../tests/testdata/t_middle_32_pullf.xvg',\n '../../tests/testdata/t_middle_28_pullf.xvg',\n '../../tests/testdata/t_middle_09_pullf.xvg',\n '../../tests/testdata/t_middle_25_pullf.xvg',\n '../../tests/testdata/t_middle_03_pullf.xvg',\n '../../tests/testdata/t_middle_04_pullf.xvg',\n '../../tests/testdata/t_middle_17_pullf.xvg',\n '../../tests/testdata/t_middle_01_pullf.xvg',\n '../../tests/testdata/t_middle_30_pullf.xvg',\n '../../tests/testdata/t_middle_21_pullf.xvg',\n '../../tests/testdata/t_middle_05_pullf.xvg',\n '../../tests/testdata/t_middle_29_pullf.xvg',\n '../../tests/testdata/t_middle_31_pullf.xvg',\n '../../tests/testdata/t_middle_19_pullf.xvg',\n '../../tests/testdata/t_middle_16_pullf.xvg',\n '../../tests/testdata/t_middle_26_pullf.xvg',\n '../../tests/testdata/t_middle_24_pullf.xvg',\n '../../tests/testdata/t_middle_34_pullf.xvg']</pre> <ol> <li>the workset is created by creating a WorkSet instance which is fitted with the filenames.</li> </ol> <p>The resolution parameter controls the striding of the data set. The reduction is performed after integration the force time traces. For long trajectories e.g. 35,000,000 frames it is recommended to use a resolution &gt; 1000 to not exceed common hardware limits.</p> In\u00a0[4]: Copied! <pre># create WorkSet instance\nworkset = WorkSet(\n    velocity=velocity,\n    resolution=res,\n    verbose=False,\n)\nworkset\n</pre> # create WorkSet instance workset = WorkSet(     velocity=velocity,     resolution=res,     verbose=False, ) workset  Out[4]: <pre>WorkSet(velocity=0.001)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.WorkSetiNot fitted Parameters velocity\u00a0 0.001 resolution\u00a0 1 verbose\u00a0 False In\u00a0[5]: Copied! <pre># fit/fill workset\nworkset.fit(filenames)\n# save workset\n#dcTMD.storing.save('my_workset', workset)\n</pre> # fit/fill workset workset.fit(filenames) # save workset #dcTMD.storing.save('my_workset', workset)   <pre>Loading &amp; integrating force files: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 18/18 [00:00&lt;00:00, 172.52it/s]\n</pre> Out[5]: <pre>WorkSet(velocity=0.001)</pre>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.WorkSetiFitted Parameters velocity\u00a0 0.001 resolution\u00a0 1 verbose\u00a0 False In\u00a0[6]: Copied! <pre>print(vars(workset))\n</pre> print(vars(workset)) <pre>{'velocity': 0.001, 'resolution': 1, 'verbose': False, 'X': ['../../tests/testdata/t_middle_32_pullf.xvg', '../../tests/testdata/t_middle_28_pullf.xvg', '../../tests/testdata/t_middle_09_pullf.xvg', '../../tests/testdata/t_middle_25_pullf.xvg', '../../tests/testdata/t_middle_03_pullf.xvg', '../../tests/testdata/t_middle_04_pullf.xvg', '../../tests/testdata/t_middle_17_pullf.xvg', '../../tests/testdata/t_middle_01_pullf.xvg', '../../tests/testdata/t_middle_30_pullf.xvg', '../../tests/testdata/t_middle_21_pullf.xvg', '../../tests/testdata/t_middle_05_pullf.xvg', '../../tests/testdata/t_middle_29_pullf.xvg', '../../tests/testdata/t_middle_31_pullf.xvg', '../../tests/testdata/t_middle_19_pullf.xvg', '../../tests/testdata/t_middle_16_pullf.xvg', '../../tests/testdata/t_middle_26_pullf.xvg', '../../tests/testdata/t_middle_24_pullf.xvg', '../../tests/testdata/t_middle_34_pullf.xvg'], 'time_': array([0.0000e+00, 1.0000e-01, 2.0000e-01, ..., 1.9998e+03, 1.9999e+03,\n       2.0000e+03], shape=(20001,)), 'work_': array([[ 0.00000000e+00,  1.03698915e-01,  1.24836915e-01, ...,\n         8.45118712e+01,  8.44347098e+01,  8.44165457e+01],\n       [ 0.00000000e+00,  1.34806000e-01,  1.20022800e-01, ...,\n         1.20631809e+02,  1.20778302e+02,  1.20820898e+02],\n       [ 0.00000000e+00,  1.02239350e-01,  2.94933350e-01, ...,\n         6.20146975e+01,  6.19869450e+01,  6.19078267e+01],\n       ...,\n       [ 0.00000000e+00,  3.10525000e-02, -1.52357750e-01, ...,\n         1.13153649e+02,  1.13248700e+02,  1.13344454e+02],\n       [ 0.00000000e+00, -3.25262500e-02, -3.90827500e-02, ...,\n         7.01226252e+01,  7.02282898e+01,  7.02547903e+01],\n       [ 0.00000000e+00,  6.30896000e-02,  5.76634000e-02, ...,\n         5.74830869e+01,  5.75868897e+01,  5.74908294e+01]],\n      shape=(18, 20001)), 'names_': array(['t_middle_32_pullf.xvg', 't_middle_28_pullf.xvg',\n       't_middle_09_pullf.xvg', 't_middle_25_pullf.xvg',\n       't_middle_03_pullf.xvg', 't_middle_04_pullf.xvg',\n       't_middle_17_pullf.xvg', 't_middle_01_pullf.xvg',\n       't_middle_30_pullf.xvg', 't_middle_21_pullf.xvg',\n       't_middle_05_pullf.xvg', 't_middle_29_pullf.xvg',\n       't_middle_31_pullf.xvg', 't_middle_19_pullf.xvg',\n       't_middle_16_pullf.xvg', 't_middle_26_pullf.xvg',\n       't_middle_24_pullf.xvg', 't_middle_34_pullf.xvg'], dtype='&lt;U32'), 'position_': array([0.0000e+00, 1.0000e-04, 2.0000e-04, ..., 1.9998e+00, 1.9999e+00,\n       2.0000e+00], shape=(20001,))}\n</pre> In\u00a0[7]: Copied! <pre># plot workset\nimport matplotlib.pyplot as plt\nfrom dcTMD.utils import plotting\n\nfig, ax = plt.subplots()\nplotting.plot_worklines(workset, ax)\nplt.show()\n</pre> # plot workset import matplotlib.pyplot as plt from dcTMD.utils import plotting  fig, ax = plt.subplots() plotting.plot_worklines(workset, ax) plt.show() In\u00a0[8]: Copied! <pre>from scipy.stats import probplot\n\ndef plot_worknormalitychecks(\n    workset,\n    index,\n    x=None,\n    worklinecolor='#777',\n    colors=None,\n    figsize=(6, 2),\n    axs=None,\n    res=10,\n):\n    \"\"\"Plots the work values of trajectories individually.\n\n    This function generates a plot with three subplots:\n    1. Line plots of the work values for all trajectories.\n    2. Work value histograms for the indices given `index`.\n    3. As well as normality plot (Q-Q plot) for the work values the indices given `index`..\n\n    Args:\n        workset: workset object\n        index (list of int): Indices of the positions. These indices\n            are used to extract specific columns from `workset.work_` for\n            histogram and normality plots.\n        x (array-like, optional): The x-axis positions for the work values. If\n            not provided, `workset.position_` is used.\n        worklinecolor (str, optional): Color of the work line plot. Default is\n            '#777'.\n        colors (list of str, optional):\n            Colors for the histogram and normality\n            plots. If not provided, the `Dark2` colormap is used.\n        figsize (tuple, optional):\n            Size of the figure. Default is (6, 2).\n        axs (list of matplotlib.axes.Axes, optional):\n            Axes for the subplots. If\n            not provided, new axes are created.\n        res (int, optional): Resolution for the work line plot. Default is 10.\n\n    Returns:\n        list of matplotlib.axes.Axes: The axes containing the subplots.\n\n    Example:\n        &gt;&gt;&gt; plot_worknormalitychecks(\n        ...     workset=my_workset,\n        ...     index=[0, 5, 10],\n        ... )\n        &gt;&gt;&gt; plt.show()\n\n    \"\"\"\n    if axs is None:\n        print('No axs given. Create figure.')\n        fig, axs = plt.subplots(\n            ncols=3,\n            nrows=1,\n            figsize=figsize,\n        )\n    if x is None:\n        x = workset.position_\n    plotting.plot_worklines(workset, axs[0], x=x, res=res, color=worklinecolor)\n\n    if not colors:\n        cmap = plt.get_cmap('Dark2')\n        colors = cmap.colors\n\n    for j, idx in enumerate(index):\n        work = workset.work_[:, idx].ravel()\n        axs[1].set_title(r'Histogram at $x$')\n        plotting.plot_histo_normaldist(work, axs[1], colors[j])\n        axs[0].axvline(\n            x[idx],\n            color=colors[j],\n            zorder=3,\n            label=rf'$x={x[idx]:.2f}$',\n        )\n\n        probplot(work, plot=axs[2], fit=True)\n        axs[2].get_lines()[j * 2].set_color(colors[j])  # noqa: WPS221\n        axs[2].set_title('Normality plot')\n\n    axs[0].legend()\n    return axs\n</pre> from scipy.stats import probplot  def plot_worknormalitychecks(     workset,     index,     x=None,     worklinecolor='#777',     colors=None,     figsize=(6, 2),     axs=None,     res=10, ):     \"\"\"Plots the work values of trajectories individually.      This function generates a plot with three subplots:     1. Line plots of the work values for all trajectories.     2. Work value histograms for the indices given `index`.     3. As well as normality plot (Q-Q plot) for the work values the indices given `index`..      Args:         workset: workset object         index (list of int): Indices of the positions. These indices             are used to extract specific columns from `workset.work_` for             histogram and normality plots.         x (array-like, optional): The x-axis positions for the work values. If             not provided, `workset.position_` is used.         worklinecolor (str, optional): Color of the work line plot. Default is             '#777'.         colors (list of str, optional):             Colors for the histogram and normality             plots. If not provided, the `Dark2` colormap is used.         figsize (tuple, optional):             Size of the figure. Default is (6, 2).         axs (list of matplotlib.axes.Axes, optional):             Axes for the subplots. If             not provided, new axes are created.         res (int, optional): Resolution for the work line plot. Default is 10.      Returns:         list of matplotlib.axes.Axes: The axes containing the subplots.      Example:         &gt;&gt;&gt; plot_worknormalitychecks(         ...     workset=my_workset,         ...     index=[0, 5, 10],         ... )         &gt;&gt;&gt; plt.show()      \"\"\"     if axs is None:         print('No axs given. Create figure.')         fig, axs = plt.subplots(             ncols=3,             nrows=1,             figsize=figsize,         )     if x is None:         x = workset.position_     plotting.plot_worklines(workset, axs[0], x=x, res=res, color=worklinecolor)      if not colors:         cmap = plt.get_cmap('Dark2')         colors = cmap.colors      for j, idx in enumerate(index):         work = workset.work_[:, idx].ravel()         axs[1].set_title(r'Histogram at $x$')         plotting.plot_histo_normaldist(work, axs[1], colors[j])         axs[0].axvline(             x[idx],             color=colors[j],             zorder=3,             label=rf'$x={x[idx]:.2f}$',         )          probplot(work, plot=axs[2], fit=True)         axs[2].get_lines()[j * 2].set_color(colors[j])  # noqa: WPS221         axs[2].set_title('Normality plot')      axs[0].legend()     return axs In\u00a0[9]: Copied! <pre># check if work distribution follows a normal distribution\nfrom scipy.stats import kstest, shapiro, anderson\nfrom dcTMD.utils import plotting\n\nindex = [5000, 15000]\nx = workset.position_\n\nplot_worknormalitychecks(workset, index)\n\nfor i, p in enumerate(index):\n    # Shapiro-Wilk Test\n    shapiro_test = shapiro(workset.work_[:,p])\n    print(f'shapiro wilkins results at x={x[p]} is {shapiro_test}')\n    # Anderson-Darling Test\n    # If the test statsitics is larger than the critical value of a given\n    # significance_level in percent, the null hypothesis that the work\n    # is normally distributed has to be rejected.\n    anderson_test = anderson(workset.work_[:,p], 'norm')\n    print(f'anderson darling results at x={x[p]} is {anderson_test}.')\n    # Kolmogorov-Smirnov Test (requires centering and scaling of input data)\n    kstest_test = kstest(\n        (workset.work_[:,p]-np.mean(workset.work_[:,p]))/np.std(workset.work_[:,p]),\n        'norm'\n    )\n    print(f'Kolmogorov-Smirnov results at x={x[p]} is {kstest_test}')\n</pre> # check if work distribution follows a normal distribution from scipy.stats import kstest, shapiro, anderson from dcTMD.utils import plotting  index = [5000, 15000] x = workset.position_  plot_worknormalitychecks(workset, index)  for i, p in enumerate(index):     # Shapiro-Wilk Test     shapiro_test = shapiro(workset.work_[:,p])     print(f'shapiro wilkins results at x={x[p]} is {shapiro_test}')     # Anderson-Darling Test     # If the test statsitics is larger than the critical value of a given     # significance_level in percent, the null hypothesis that the work     # is normally distributed has to be rejected.     anderson_test = anderson(workset.work_[:,p], 'norm')     print(f'anderson darling results at x={x[p]} is {anderson_test}.')     # Kolmogorov-Smirnov Test (requires centering and scaling of input data)     kstest_test = kstest(         (workset.work_[:,p]-np.mean(workset.work_[:,p]))/np.std(workset.work_[:,p]),         'norm'     )     print(f'Kolmogorov-Smirnov results at x={x[p]} is {kstest_test}') <pre>No axs given. Create figure.\nshapiro wilkins results at x=0.5 is ShapiroResult(statistic=np.float64(0.9809889406089324), pvalue=np.float64(0.95963623434336))\nanderson darling results at x=0.5 is AndersonResult(statistic=np.float64(0.1889729620402001), critical_values=array([0.503, 0.573, 0.687, 0.802, 0.954]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]), fit_result=  params: FitParams(loc=np.float64(67.28161594817962), scale=np.float64(12.135336573012399))\n success: True\n message: '`anderson` successfully fit the distribution to the data.').\nKolmogorov-Smirnov results at x=0.5 is KstestResult(statistic=np.float64(0.12229979875552988), pvalue=np.float64(0.9209557348362518), statistic_location=np.float64(-1.013218181258686), statistic_sign=np.int8(1))\nshapiro wilkins results at x=1.5 is ShapiroResult(statistic=np.float64(0.9350144421408519), pvalue=np.float64(0.23768137296093406))\nanderson darling results at x=1.5 is AndersonResult(statistic=np.float64(0.38109849215264546), critical_values=array([0.503, 0.573, 0.687, 0.802, 0.954]), significance_level=array([15. , 10. ,  5. ,  2.5,  1. ]), fit_result=  params: FitParams(loc=np.float64(92.54892049414025), scale=np.float64(19.147779388352493))\n success: True\n message: '`anderson` successfully fit the distribution to the data.').\nKolmogorov-Smirnov results at x=1.5 is KstestResult(statistic=np.float64(0.14917443864214242), pvalue=np.float64(0.7646028245726427), statistic_location=np.float64(0.5380536480357736), statistic_sign=np.int8(-1))\n</pre> In\u00a0[10]: Copied! <pre># create WorkEstimator instance\nworkestimator = WorkEstimator(temperature)\n# fit existing workset\n# or load an existing workset\n# workset = dcTMD.storing.load(my_workset)\nworkestimator.fit(workset)\nvars(workestimator)\n</pre> # create WorkEstimator instance workestimator = WorkEstimator(temperature) # fit existing workset # or load an existing workset # workset = dcTMD.storing.load(my_workset) workestimator.fit(workset) vars(workestimator) Out[10]: <pre>{'temperature': 300,\n 'verbose': False,\n 'work_set': WorkSet(velocity=0.001),\n 'position_': array([0.0000e+00, 1.0000e-04, 2.0000e-04, ..., 1.9998e+00, 1.9999e+00,\n        2.0000e+00], shape=(20001,)),\n 'names_': array(['t_middle_32_pullf.xvg', 't_middle_28_pullf.xvg',\n        't_middle_09_pullf.xvg', 't_middle_25_pullf.xvg',\n        't_middle_03_pullf.xvg', 't_middle_04_pullf.xvg',\n        't_middle_17_pullf.xvg', 't_middle_01_pullf.xvg',\n        't_middle_30_pullf.xvg', 't_middle_21_pullf.xvg',\n        't_middle_05_pullf.xvg', 't_middle_29_pullf.xvg',\n        't_middle_31_pullf.xvg', 't_middle_19_pullf.xvg',\n        't_middle_16_pullf.xvg', 't_middle_26_pullf.xvg',\n        't_middle_24_pullf.xvg', 't_middle_34_pullf.xvg'], dtype='&lt;U32'),\n 'W_mean_': array([0.00000000e+00, 4.41837458e-02, 4.44572742e-02, ...,\n        9.33136501e+01, 9.32887153e+01, 9.32516402e+01], shape=(20001,)),\n 'W_diss_': array([0.00000000e+00, 1.16301148e-03, 5.56596643e-03, ...,\n        1.03329006e+02, 1.03220317e+02, 1.03098234e+02], shape=(20001,)),\n 'dG_': array([  0.        ,   0.04302073,   0.03889131, ..., -10.01535586,\n         -9.93160192,  -9.84659417], shape=(20001,)),\n 'friction_': array([       0.        ,    11630.11484133,    44029.54944818, ...,\n          750667.95818287, -1086887.96420751, -1220828.47757056],\n       shape=(20001,))}</pre> In\u00a0[11]: Copied! <pre># plot dcTMD results\nfrom dcTMD.utils import plotting\n\n# plot free energy estimate\nfig, ax = plt.subplots()\nplotting.plot_dG(x, workestimator.dG_, ax, label='some system')\nplt.legend()\nplt.show()\n\n# plot dcTMD results\nfig, axs = plotting.plot_dcTMD_results(workestimator)\nplt.show()\n</pre> # plot dcTMD results from dcTMD.utils import plotting  # plot free energy estimate fig, ax = plt.subplots() plotting.plot_dG(x, workestimator.dG_, ax, label='some system') plt.legend() plt.show()  # plot dcTMD results fig, axs = plotting.plot_dcTMD_results(workestimator) plt.show() In\u00a0[12]: Copied! <pre># smooth friction and plot results\nworkestimator.smooth_friction(sigma=0.1)\n\n# if the friction is smoothed that value is automatically plotted\nfig, axs = plotting.plot_dcTMD_results(workestimator)\nplt.show()\n\n# but one can also specify the friction\n#fig, axs = plotting.plot_dcTMD_results(\n#    workestimator,\n#    friction=workestimator.friction_\n#)\n</pre> # smooth friction and plot results workestimator.smooth_friction(sigma=0.1)  # if the friction is smoothed that value is automatically plotted fig, axs = plotting.plot_dcTMD_results(workestimator) plt.show()  # but one can also specify the friction #fig, axs = plotting.plot_dcTMD_results( #    workestimator, #    friction=workestimator.friction_ #) <p>Using different smoothing windows and modes changes the results significantly. Because of the different boundary handling in the modes, <code>mode='nearest'</code> leads to an overestimation at the right hand border (end of the simulation), while <code>mode='reflect'</code> leads to a washing out of the boarder on the left hand side.</p> <p>Here are some examples:</p> In\u00a0[13]: Copied! <pre>fig, axs = plt.subplots()\n\nx = workestimator.position_\nplotting.plot_Gamma(\n    x,\n    workestimator.friction_smooth_,\n    axs,\n    label='default (reflect) 0.1nm'\n)\n\n# using different smoothing windows and modes changes the results significantly\nsmooth_friction = dcTMD.utils.gaussfilter_friction(\n    workestimator.friction_,\n    x,\n    sigma=.01,\n    mode='reflect',\n)\naxs.plot(x, smooth_friction, label='reflect .01nm')\nsmooth_friction = dcTMD.utils.gaussfilter_friction(\n    workestimator.friction_,\n    x,\n    sigma=.01, \n    mode='nearest',\n)\naxs.plot(x, smooth_friction, label='nearest .01nm')\nsmooth_friction = dcTMD.utils.gaussfilter_friction(\n    workestimator.friction_,\n    x,\n    sigma=0.2,\n    mode='reflect',\n)\n                                                   \naxs.plot(x, smooth_friction, label='reflect .2nm')\naxs.legend()\n\nplt.show()\n</pre> fig, axs = plt.subplots()  x = workestimator.position_ plotting.plot_Gamma(     x,     workestimator.friction_smooth_,     axs,     label='default (reflect) 0.1nm' )  # using different smoothing windows and modes changes the results significantly smooth_friction = dcTMD.utils.gaussfilter_friction(     workestimator.friction_,     x,     sigma=.01,     mode='reflect', ) axs.plot(x, smooth_friction, label='reflect .01nm') smooth_friction = dcTMD.utils.gaussfilter_friction(     workestimator.friction_,     x,     sigma=.01,      mode='nearest', ) axs.plot(x, smooth_friction, label='nearest .01nm') smooth_friction = dcTMD.utils.gaussfilter_friction(     workestimator.friction_,     x,     sigma=0.2,     mode='reflect', )                                                     axs.plot(x, smooth_friction, label='reflect .2nm') axs.legend()  plt.show() In\u00a0[14]: Copied! <pre>n_resamples = 1000\n\n# bootstrapping error in mode std\nmode = 'std'\nworkestimator.estimate_free_energy_errors(n_resamples, mode)\n\nfig, ax = plt.subplots()\nplotting.plot_dG_werrors(workestimator, ax)\nplt.show()\n</pre>  n_resamples = 1000  # bootstrapping error in mode std mode = 'std' workestimator.estimate_free_energy_errors(n_resamples, mode)  fig, ax = plt.subplots() plotting.plot_dG_werrors(workestimator, ax) plt.show() <pre>Bootstrapping progress: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:01&lt;00:00, 775.11it/s]\n</pre> In\u00a0[15]: Copied! <pre># bootstrapping error in with confidence interval \n# this gives a lower and upperbound estimate\nconfidence_interval = 0.9\nmode = confidence_interval\nworkestimator.estimate_free_energy_errors(n_resamples, mode)\n\nfig, ax = plt.subplots()\nplotting.plot_dG_werrors(workestimator, ax)\nplt.show()\n</pre> # bootstrapping error in with confidence interval  # this gives a lower and upperbound estimate confidence_interval = 0.9 mode = confidence_interval workestimator.estimate_free_energy_errors(n_resamples, mode)  fig, ax = plt.subplots() plotting.plot_dG_werrors(workestimator, ax) plt.show()  <pre>Bootstrapping progress: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 1000/1000 [00:01&lt;00:00, 586.88it/s]\n</pre> In\u00a0[16]: Copied! <pre># save workestimator instance\ndcTMD.storing.save('my_workestimator', workestimator)\n\n# save data as .npz and .dat file\noutname = 'my_workestimator_results'\ndcTMD.io.write_output(outname, workestimator)\n\n# if you want to save data as .dat file only:\ndcTMD.io.write_output(outname, workestimator, filetype='.dat')\n</pre> # save workestimator instance dcTMD.storing.save('my_workestimator', workestimator)  # save data as .npz and .dat file outname = 'my_workestimator_results' dcTMD.io.write_output(outname, workestimator)  # if you want to save data as .dat file only: dcTMD.io.write_output(outname, workestimator, filetype='.dat') <pre>save file my_workestimator_results_N18.dat\nsave file my_workestimator_results_N18.npz\nsave file my_workestimator_results_N18.dat\n</pre> In\u00a0[17]: Copied! <pre># load results\nresults = dcTMD.io.load_output(f'{outname}_N{len(workestimator.names_)}.npz')\n#results = dcTMD.io.load_output(f'{outname}_N{len(workestimator.names_)}.dat')\n\nprint(results.keys())\n\n# results is a dictionary-like object\n# access e.g. the free energy estimate\n\nresults['dG']\n</pre> # load results results = dcTMD.io.load_output(f'{outname}_N{len(workestimator.names_)}.npz') #results = dcTMD.io.load_output(f'{outname}_N{len(workestimator.names_)}.dat')  print(results.keys())  # results is a dictionary-like object # access e.g. the free energy estimate  results['dG'] <pre>Loaded data from my_workestimator_results_N18.npz\ndict_keys(['x', 'Wmean', 'Wdiss', 'dG', 'Gamma', 's_W_mean', 's_W_diss', 's_dG', 'Gamma_smooth'])\n</pre> Out[17]: <pre>array([  0.        ,   0.04302073,   0.03889131, ..., -10.01535586,\n        -9.93160192,  -9.84659417], shape=(20001,))</pre>"},{"location":"tutorials/work/#introduction","title":"Introduction\u00b6","text":"<p>One way to analyze non-equilibrium force time traces from constraint pulling simulations is by calculating the work first and then estimating the free energy  $\\Delta G$, via:</p> <p>$$ \\begin{align} \\Delta G(x) &amp;=  \\left&lt; W(x) \\right&gt;_\\text{N} -\\frac{\\beta}{2}\\left&lt;\\delta W(x)^2\\right&gt;_\\text{N} \\\\ \t\t\t&amp;=  \\left&lt;W(x)\\right&gt;_\\text{N} - W_\\text{diss}(x) \\end{align} $$</p> <p>with $\\delta W(x) = W(x) -\\left&lt; W(x) \\right&gt;_\\text{N}$. The expression is true if the work distribution is Gaussian. This allows to formulate the friction estimate:</p> <p>$$\\Gamma(x) = \\frac{1}{v_c}\\frac{d~W_\\text{diss}(x)}{dx}$$</p> <p>This approach is implemented in the WorkEstimator class and computationally more efficient than calculating the force autocorrelation function (which is implemented in the ForceEstimator class), because the class works with the work data via the integration of the force time traces. This allows to reduce the resolution significantly while getting the same results.</p> <p>Therefore, we recommend to use this approach for large datasets.</p>"},{"location":"tutorials/work/#workflow","title":"Workflow:\u00b6","text":""},{"location":"tutorials/work/#0-load-packages-and-define-variables","title":"0. load packages and define variables\u00b6","text":""},{"location":"tutorials/work/#i-create-a-work-set","title":"I. create a work set\u00b6","text":"<p>To calculate free energy and friction estimates a workset is needed. It contains the integrated force time traces.</p> <ol> <li>an array containing the filenames is generated. This can be done via the function dcTMD.io.load_pullf() which takes either a glob pattern or a file containing the pullf file names as argument.</li> </ol>"},{"location":"tutorials/work/#ii-check-normality-of-work-distribution","title":"II. check normality of work distribution\u00b6","text":"<p>One of the main conditions which need to be fulfilled for dcTMD is a normally distributed work.</p> <p>This can be checked via different methods, e.g., plotting the work time traces, normality checks at different $x$, Kolmogorov-Smirnov test, Shapiro-Wilk test, Anderson-Darling test.</p> <p>Caution: if the work distribution is not normal your results are compromised and a path separation is necessary.</p>"},{"location":"tutorials/work/#iii-derive-estimates-from-workset","title":"III. derive estimates from workset\u00b6","text":"<ol> <li>create WorkEstimator instance</li> <li>fit WorkEstimator instance with previously created workset</li> </ol>"},{"location":"tutorials/work/#visualize-results","title":"Visualize results\u00b6","text":"<p>A couple of simple plot functions to get an overview of the results are implemented.</p>"},{"location":"tutorials/work/#smooth-friction-estimate","title":"Smooth friction estimate\u00b6","text":"<p>Finally, the friction estimate needs to be smoothed. This can be done via <code>dcTMD.utils.smoothing.gaussfilter_friction()</code> or <code>dcTMD.WorkEstimator.smooth_friction(sigma, mode)</code>.</p> <p><code>sigma</code> is the standard deviation of gaussian kernel in nm, <code>mode</code> determines how the input array is extended input array is extended when the filter overlaps a border, as used by <code>scipy.ndimage.gaussian_filter()</code>.</p> <p>Caution: this can lead to long computation times when using large datasets and/or big smoothing windows.</p>"},{"location":"tutorials/work/#iv-error-estimation","title":"IV. Error estimation\u00b6","text":"<p>The error estimation of the results is implemented via bootstrapping:</p>"},{"location":"tutorials/work/#v-save-and-load-results","title":"V. Save and load results\u00b6","text":""}]}